{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla Policy Gradients for CartPole and Pong\n",
    "\n",
    "In this notebook, you will implement a Vanilla Policy Gradient algorithm to train an agent to play CartPole (and Pong later, if desired). This uses the OpenAI gym library. Make sure you can install and run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Some setup.\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from agents.policy_gradients import *\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0,8.0)\n",
    "plt.rcParams['image.interpolation'] = 'linear'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "def rel_error(x,y):\n",
    "    \"\"\" Returns relative error. \"\"\"\n",
    "    return np.max( np.abs(x-y) / np.maximum(1e-8,np.abs(x)+np.abs(y)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discounted Rewards\n",
    "\n",
    "With policy gradients, we need rewards to scale the gradient terms appropriately. Implement the method `discount_rewards` and test your implementation using the following cell. For some games, such as CartPole, we can sum the rewards by considering all of the subsequent rewards for a given episode. For Pong, however, the rewards should be reset to 0 after any player scores.\n",
    "\n",
    "You will need to take care of both cases (set by the `do_reset` parameter). Do this even if you do not plan to test with Pong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.32314280378e-09\n",
      "2.75945079139e-09\n"
     ]
    }
   ],
   "source": [
    "test = np.array([0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,-1,0,0,0,0,0,0,0,-1], np.float)\n",
    "output_1 = [-0.70017483, -0.70724731, -0.71439122, -0.72160729, -0.72889625, -0.73625884,\n",
    "            -0.7436958,  -0.75120788, -0.75879584, -0.76646044, -0.77420247, -1.7921237,\n",
    "            -1.81022596, -1.82851107, -1.84698088, -1.86563725, -1.88448208, -1.90351725,\n",
    "            -1.92274469, -0.93206535, -0.94148015, -0.95099005, -0.96059601, -0.970299,\n",
    "            -0.9801,     -0.99,       -1.        ]\n",
    "output_2 = [ 0.90438208,  0.91351725,  0.92274469,  0.93206535,  0.94148015,  0.95099005,\n",
    "             0.96059601,  0.970299,    0.9801,      0.99,        1.,         -0.93206535,\n",
    "            -0.94148015, -0.95099005, -0.96059601, -0.970299,   -0.9801,    -0.99,     -1.,\n",
    "            -0.93206535, -0.94148015, -0.95099005, -0.96059601, -0.970299,  -0.9801, -0.99, -1.]\n",
    "\n",
    "PG = PolicyGradient()\n",
    "rewards_1 = PG.discount_rewards(test, do_reset=False)\n",
    "rewards_2 = PG.discount_rewards(test, do_reset=True)\n",
    "\n",
    "# Should be around 1e-9\n",
    "print(rel_error(output_1, rewards_1))\n",
    "print(rel_error(output_2, rewards_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policy Gradients for CartPole\n",
    "\n",
    "There are three places in the code to fill:\n",
    "\n",
    "1. The method `policy_backward`, which will compute the gradients.\n",
    "2. In the `train` method, you need to write the gradient for the final output layer (i.e., the last gradient in the overall computational graph) and store that in a list to be used at the end of the episode.\n",
    "3. Also in the `train` method, you need to utilize the discounted rewards you wrote and integrate it into the computation of the gradient. In addition, you need to keep the overall `grad_buffer` up to date.\n",
    "\n",
    "After you complete these, you should be able to train your agent on CartPole (and Pong, if desired).\n",
    "\n",
    "To get full credit for this portion run CartPole with `max_episodes=400`, and report the final running reward, as well as a plot of all the running reward values. (The cell after the training call should do these two automatically.) You should aim to get a final running_reward of **at least 200.00**, and the plot for the running_rewards should show a clear upward trend, though it may sometimes decrease if there are games that last abnormally long. For reference, our implementation usually achieves running rewards of 500-5000 after 400 episodes. From our experience, the performance varies a lot with CartPole; we have gotten scores as high as a million, so save any output that meets the 200-score requirement.\n",
    "\n",
    "Some additional comments:\n",
    "\n",
    "1. You do not need to change the default hyperparameters provided, such as `learning_rate`. If you need to change one of them to get the minimum performance -- or if you think there's a compelling reason to do so -- explain your changes in a new text/Markdown cell.\n",
    "\n",
    "2. Please keep `print_every=2` (or some other reasonable value) so that we can spot-check the rewards and running rewards per episode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-22 18:25:58,162] Making new env: CartPole-v0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep. 10 done, reward: 10.0, running_reward: 14.2666, time (sec): 0.0222\n",
      "Ep. 20 done, reward: 17.0, running_reward: 15.6676, time (sec): 0.0336\n",
      "Ep. 30 done, reward: 37.0, running_reward: 17.9718, time (sec): 0.0483\n",
      "Ep. 40 done, reward: 63.0, running_reward: 20.1782, time (sec): 0.0624\n",
      "Ep. 50 done, reward: 177.0, running_reward: 25.0617, time (sec): 0.0858\n",
      "Ep. 60 done, reward: 35.0, running_reward: 27.1244, time (sec): 0.1016\n",
      "Ep. 70 done, reward: 18.0, running_reward: 28.6971, time (sec): 0.1165\n",
      "Ep. 80 done, reward: 51.0, running_reward: 31.9848, time (sec): 0.1377\n",
      "Ep. 90 done, reward: 42.0, running_reward: 34.8049, time (sec): 0.1580\n",
      "Ep. 100 done, reward: 66.0, running_reward: 37.6504, time (sec): 0.1806\n",
      "Ep. 110 done, reward: 47.0, running_reward: 41.2748, time (sec): 0.2065\n",
      "Ep. 120 done, reward: 46.0, running_reward: 42.3606, time (sec): 0.2238\n",
      "Ep. 130 done, reward: 41.0, running_reward: 43.6668, time (sec): 0.2439\n",
      "Ep. 140 done, reward: 41.0, running_reward: 47.4440, time (sec): 0.2715\n",
      "Ep. 150 done, reward: 142.0, running_reward: 54.3956, time (sec): 0.3094\n",
      "Ep. 160 done, reward: 151.0, running_reward: 62.9416, time (sec): 0.3581\n",
      "Ep. 170 done, reward: 56.0, running_reward: 65.8648, time (sec): 0.3916\n",
      "Ep. 180 done, reward: 77.0, running_reward: 69.2054, time (sec): 0.4255\n",
      "Ep. 190 done, reward: 94.0, running_reward: 81.1538, time (sec): 0.4941\n",
      "Ep. 200 done, reward: 277.0, running_reward: 94.1886, time (sec): 0.5626\n",
      "Ep. 210 done, reward: 54.0, running_reward: 103.3582, time (sec): 0.6261\n",
      "Ep. 220 done, reward: 219.0, running_reward: 110.5105, time (sec): 0.6827\n",
      "Ep. 230 done, reward: 95.0, running_reward: 116.8428, time (sec): 0.7424\n",
      "Ep. 240 done, reward: 41.0, running_reward: 120.1479, time (sec): 0.7908\n",
      "Ep. 250 done, reward: 85.0, running_reward: 142.3481, time (sec): 0.9032\n",
      "Ep. 260 done, reward: 622.0, running_reward: 165.4839, time (sec): 1.0220\n",
      "Ep. 270 done, reward: 118.0, running_reward: 184.7901, time (sec): 1.1416\n",
      "Ep. 280 done, reward: 384.0, running_reward: 193.3281, time (sec): 1.2272\n",
      "Ep. 290 done, reward: 314.0, running_reward: 199.3828, time (sec): 1.3088\n",
      "Ep. 300 done, reward: 295.0, running_reward: 203.3441, time (sec): 1.3868\n",
      "Ep. 310 done, reward: 371.0, running_reward: 214.9077, time (sec): 1.4921\n",
      "Ep. 320 done, reward: 123.0, running_reward: 214.5567, time (sec): 1.5580\n",
      "Ep. 330 done, reward: 340.0, running_reward: 225.9250, time (sec): 1.6664\n",
      "Ep. 340 done, reward: 172.0, running_reward: 224.5536, time (sec): 1.7362\n",
      "Ep. 350 done, reward: 369.0, running_reward: 230.4242, time (sec): 1.8243\n",
      "Ep. 360 done, reward: 372.0, running_reward: 260.8209, time (sec): 2.0050\n",
      "Ep. 370 done, reward: 470.0, running_reward: 262.0363, time (sec): 2.0940\n",
      "Ep. 380 done, reward: 110.0, running_reward: 341.0695, time (sec): 2.4291\n",
      "Ep. 390 done, reward: 2609.0, running_reward: 394.2170, time (sec): 2.7037\n",
      "Ep. 400 done, reward: 846.0, running_reward: 401.8744, time (sec): 2.8468\n",
      "Whew! All done with 400 episodes!\n"
     ]
    }
   ],
   "source": [
    "# Train an agent to play CartPole.\n",
    "# PG = PolicyGradient(D=80*80, H=30, learning_rate=0.01)\n",
    "# PG.train(environment=\"Pong-v0\", max_episodes=400, print_every=10)\n",
    "PG = PolicyGradient(D=4, H=30, learning_rate=0.01)\n",
    "PG.train(environment=\"CartPole-v0\", max_episodes=400, print_every=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final CartPole running reward: 401.8743707\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x1110c88d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA10AAAK9CAYAAADfSAZpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQ5ckSZIklZGhS5IkSZLK6P8Dzo2zCXedvxIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10ceb5350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print final running_reward and plot the results.\n",
    "print(\"Final CartPole running reward: {}\".format(PG.running_rewards[-1]))\n",
    "plt.figure()\n",
    "plt.plot(PG.running_rewards)\n",
    "plt.title(\"Running Rewards for CartPole\")\n",
    "plt.xlabel(\"Training Episodes\")\n",
    "plt.ylabel(\"Scores\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most computers should be able to run larger, image-based environments like Pong. Although it will take much longer, especially on older machines, so this step is optional. To run Pong, do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-22 18:26:01,474] Making new env: Pong-v0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep. 2 done, reward: -21.0, running_reward: -21.0000, time (sec): 2.7527\n",
      "Ep. 4 done, reward: -18.0, running_reward: -20.9601, time (sec): 7.0219\n",
      "Ep. 6 done, reward: -20.0, running_reward: -20.9410, time (sec): 10.7201\n",
      "Ep. 8 done, reward: -20.0, running_reward: -20.9322, time (sec): 14.6417\n",
      "Ep. 10 done, reward: -21.0, running_reward: -20.9137, time (sec): 17.7479\n",
      "Ep. 12 done, reward: -21.0, running_reward: -20.9055, time (sec): 20.7927\n",
      "Ep. 14 done, reward: -21.0, running_reward: -20.8975, time (sec): 24.1002\n",
      "Ep. 16 done, reward: -21.0, running_reward: -20.8897, time (sec): 27.3718\n",
      "Ep. 18 done, reward: -21.0, running_reward: -20.8919, time (sec): 30.4076\n",
      "Ep. 20 done, reward: -21.0, running_reward: -20.8841, time (sec): 33.9950\n",
      "Ep. 22 done, reward: -20.0, running_reward: -20.8764, time (sec): 37.1896\n",
      "Ep. 24 done, reward: -21.0, running_reward: -20.8789, time (sec): 40.9515\n",
      "Ep. 26 done, reward: -18.0, running_reward: -20.8513, time (sec): 45.0346\n",
      "Ep. 28 done, reward: -21.0, running_reward: -20.8542, time (sec): 47.8877\n",
      "Ep. 30 done, reward: -21.0, running_reward: -20.8472, time (sec): 51.5829\n",
      "Ep. 32 done, reward: -21.0, running_reward: -20.8503, time (sec): 55.0499\n",
      "Ep. 34 done, reward: -20.0, running_reward: -20.8433, time (sec): 58.4181\n",
      "Ep. 36 done, reward: -21.0, running_reward: -20.8464, time (sec): 61.9769\n",
      "Ep. 38 done, reward: -20.0, running_reward: -20.8394, time (sec): 65.8804\n",
      "Ep. 40 done, reward: -20.0, running_reward: -20.8128, time (sec): 70.6441\n",
      "Ep. 42 done, reward: -21.0, running_reward: -20.8166, time (sec): 73.5583\n",
      "Ep. 44 done, reward: -21.0, running_reward: -20.8103, time (sec): 76.9966\n",
      "Ep. 46 done, reward: -21.0, running_reward: -20.8042, time (sec): 81.3136\n",
      "Ep. 48 done, reward: -20.0, running_reward: -20.7981, time (sec): 85.0460\n",
      "Ep. 50 done, reward: -21.0, running_reward: -20.8021, time (sec): 89.0359\n",
      "Ep. 52 done, reward: -20.0, running_reward: -20.7861, time (sec): 92.7376\n",
      "Ep. 54 done, reward: -19.0, running_reward: -20.7506, time (sec): 97.5500\n",
      "Ep. 56 done, reward: -21.0, running_reward: -20.7457, time (sec): 100.6963\n",
      "Ep. 58 done, reward: -21.0, running_reward: -20.7408, time (sec): 104.4320\n",
      "Ep. 60 done, reward: -20.0, running_reward: -20.7261, time (sec): 108.8629\n",
      "Ep. 62 done, reward: -21.0, running_reward: -20.7315, time (sec): 112.1026\n",
      "Ep. 64 done, reward: -21.0, running_reward: -20.7072, time (sec): 116.4611\n",
      "Ep. 66 done, reward: -21.0, running_reward: -20.7130, time (sec): 119.7576\n",
      "Ep. 68 done, reward: -20.0, running_reward: -20.6790, time (sec): 123.8601\n",
      "Ep. 70 done, reward: -20.0, running_reward: -20.6655, time (sec): 128.7558\n",
      "Ep. 72 done, reward: -20.0, running_reward: -20.6621, time (sec): 132.1719\n",
      "Ep. 74 done, reward: -18.0, running_reward: -20.6389, time (sec): 136.1944\n",
      "Ep. 76 done, reward: -21.0, running_reward: -20.6362, time (sec): 140.1680\n",
      "Ep. 78 done, reward: -21.0, running_reward: -20.6434, time (sec): 144.8676\n",
      "Ep. 80 done, reward: -19.0, running_reward: -20.6107, time (sec): 150.1216\n",
      "Ep. 82 done, reward: -21.0, running_reward: -20.5887, time (sec): 154.5481\n",
      "Ep. 84 done, reward: -20.0, running_reward: -20.5770, time (sec): 158.3986\n",
      "Ep. 86 done, reward: -20.0, running_reward: -20.5655, time (sec): 162.1796\n",
      "Ep. 88 done, reward: -20.0, running_reward: -20.5543, time (sec): 165.5526\n",
      "Ep. 90 done, reward: -21.0, running_reward: -20.5434, time (sec): 170.2122\n",
      "Ep. 92 done, reward: -21.0, running_reward: -20.5326, time (sec): 174.2968\n",
      "Ep. 94 done, reward: -19.0, running_reward: -20.5219, time (sec): 178.3540\n",
      "Ep. 96 done, reward: -20.0, running_reward: -20.5017, time (sec): 182.3021\n",
      "Ep. 98 done, reward: -20.0, running_reward: -20.5016, time (sec): 186.1442\n",
      "Ep. 100 done, reward: -21.0, running_reward: -20.5016, time (sec): 190.3217\n",
      "Ep. 102 done, reward: -21.0, running_reward: -20.5115, time (sec): 193.8441\n",
      "Ep. 104 done, reward: -18.0, running_reward: -20.4813, time (sec): 198.4593\n",
      "Ep. 106 done, reward: -20.0, running_reward: -20.4718, time (sec): 202.4614\n",
      "Ep. 108 done, reward: -21.0, running_reward: -20.4823, time (sec): 206.0411\n",
      "Ep. 110 done, reward: -21.0, running_reward: -20.4827, time (sec): 210.0412\n",
      "Ep. 112 done, reward: -21.0, running_reward: -20.4633, time (sec): 213.9232\n",
      "Ep. 114 done, reward: -20.0, running_reward: -20.4441, time (sec): 217.8917\n",
      "Ep. 116 done, reward: -19.0, running_reward: -20.4253, time (sec): 222.1695\n",
      "Ep. 118 done, reward: -21.0, running_reward: -20.4268, time (sec): 226.3726\n",
      "Ep. 120 done, reward: -21.0, running_reward: -20.4383, time (sec): 229.6370\n",
      "Ep. 122 done, reward: -20.0, running_reward: -20.4394, time (sec): 233.0683\n",
      "Ep. 124 done, reward: -19.0, running_reward: -20.4207, time (sec): 237.1365\n",
      "Ep. 126 done, reward: -21.0, running_reward: -20.4322, time (sec): 241.6222\n",
      "Ep. 128 done, reward: -19.0, running_reward: -20.4235, time (sec): 245.3521\n",
      "Ep. 130 done, reward: -21.0, running_reward: -20.4251, time (sec): 249.0823\n",
      "Ep. 132 done, reward: -21.0, running_reward: -20.4365, time (sec): 252.8753\n",
      "Ep. 134 done, reward: -19.0, running_reward: -20.4079, time (sec): 257.9816\n",
      "Ep. 136 done, reward: -20.0, running_reward: -20.4097, time (sec): 261.7816\n",
      "Ep. 138 done, reward: -21.0, running_reward: -20.4017, time (sec): 265.9714\n",
      "Ep. 140 done, reward: -19.0, running_reward: -20.3837, time (sec): 269.7058\n",
      "Ep. 142 done, reward: -16.0, running_reward: -20.3261, time (sec): 274.2442\n",
      "Ep. 144 done, reward: -21.0, running_reward: -20.3395, time (sec): 278.4143\n",
      "Ep. 146 done, reward: -20.0, running_reward: -20.3328, time (sec): 282.5012\n",
      "Ep. 148 done, reward: -21.0, running_reward: -20.3461, time (sec): 286.4146\n",
      "Ep. 150 done, reward: -20.0, running_reward: -20.3392, time (sec): 290.2156\n",
      "Ep. 152 done, reward: -20.0, running_reward: -20.3423, time (sec): 294.1746\n",
      "Ep. 154 done, reward: -21.0, running_reward: -20.3554, time (sec): 297.7180\n",
      "Ep. 156 done, reward: -21.0, running_reward: -20.3385, time (sec): 301.9084\n",
      "Ep. 158 done, reward: -19.0, running_reward: -20.3020, time (sec): 306.5484\n",
      "Ep. 160 done, reward: -21.0, running_reward: -20.3159, time (sec): 310.9604\n",
      "Ep. 162 done, reward: -21.0, running_reward: -20.3196, time (sec): 314.5739\n",
      "Ep. 164 done, reward: -21.0, running_reward: -20.3332, time (sec): 318.5048\n",
      "Ep. 166 done, reward: -19.0, running_reward: -20.3264, time (sec): 322.5384\n",
      "Ep. 168 done, reward: -19.0, running_reward: -20.2901, time (sec): 327.8659\n",
      "Ep. 170 done, reward: -19.0, running_reward: -20.2645, time (sec): 331.7047\n",
      "Ep. 172 done, reward: -20.0, running_reward: -20.2691, time (sec): 335.5679\n",
      "Ep. 174 done, reward: -21.0, running_reward: -20.2737, time (sec): 339.4550\n",
      "Ep. 176 done, reward: -19.0, running_reward: -20.2682, time (sec): 343.2739\n",
      "Ep. 178 done, reward: -21.0, running_reward: -20.2729, time (sec): 346.4888\n",
      "Ep. 180 done, reward: -20.0, running_reward: -20.2773, time (sec): 350.8646\n",
      "Ep. 182 done, reward: -19.0, running_reward: -20.2717, time (sec): 354.6633\n",
      "Ep. 184 done, reward: -20.0, running_reward: -20.2663, time (sec): 358.4962\n",
      "Ep. 186 done, reward: -21.0, running_reward: -20.2809, time (sec): 361.9090\n",
      "Ep. 188 done, reward: -20.0, running_reward: -20.2852, time (sec): 366.1184\n",
      "Ep. 190 done, reward: -20.0, running_reward: -20.2894, time (sec): 370.1254\n",
      "Ep. 192 done, reward: -18.0, running_reward: -20.2538, time (sec): 374.9344\n",
      "Ep. 194 done, reward: -19.0, running_reward: -20.2387, time (sec): 379.1609\n",
      "Ep. 196 done, reward: -18.0, running_reward: -20.2239, time (sec): 383.8595\n",
      "Ep. 198 done, reward: -20.0, running_reward: -20.2194, time (sec): 388.4448\n",
      "Ep. 200 done, reward: -21.0, running_reward: -20.2350, time (sec): 392.7750\n",
      "Ep. 202 done, reward: -19.0, running_reward: -20.2203, time (sec): 397.3732\n",
      "Ep. 204 done, reward: -21.0, running_reward: -20.2160, time (sec): 401.5183\n",
      "Ep. 206 done, reward: -20.0, running_reward: -20.2216, time (sec): 405.7039\n",
      "Ep. 208 done, reward: -20.0, running_reward: -20.2172, time (sec): 411.5262\n",
      "Ep. 210 done, reward: -19.0, running_reward: -20.2128, time (sec): 416.6197\n",
      "Ep. 212 done, reward: -19.0, running_reward: -20.2084, time (sec): 421.5184\n",
      "Ep. 214 done, reward: -21.0, running_reward: -20.1945, time (sec): 425.4676\n",
      "Ep. 216 done, reward: -19.0, running_reward: -20.1707, time (sec): 430.1971\n",
      "Ep. 218 done, reward: -20.0, running_reward: -20.1673, time (sec): 434.1807\n",
      "Ep. 220 done, reward: -20.0, running_reward: -20.1640, time (sec): 438.8097\n",
      "Ep. 222 done, reward: -21.0, running_reward: -20.1806, time (sec): 442.4267\n",
      "Ep. 224 done, reward: -21.0, running_reward: -20.1870, time (sec): 446.2069\n",
      "Ep. 226 done, reward: -19.0, running_reward: -20.1733, time (sec): 451.4789\n",
      "Ep. 228 done, reward: -20.0, running_reward: -20.1798, time (sec): 455.7136\n",
      "Ep. 230 done, reward: -20.0, running_reward: -20.1762, time (sec): 460.2828\n",
      "Ep. 232 done, reward: -21.0, running_reward: -20.1926, time (sec): 463.7878\n",
      "Ep. 234 done, reward: -20.0, running_reward: -20.1986, time (sec): 468.0915\n",
      "Ep. 236 done, reward: -21.0, running_reward: -20.2146, time (sec): 471.9125\n",
      "Ep. 238 done, reward: -21.0, running_reward: -20.2203, time (sec): 476.1957\n",
      "Ep. 240 done, reward: -19.0, running_reward: -20.1861, time (sec): 480.5804\n",
      "Ep. 242 done, reward: -21.0, running_reward: -20.1726, time (sec): 485.3225\n",
      "Ep. 244 done, reward: -21.0, running_reward: -20.1891, time (sec): 489.0573\n",
      "Ep. 246 done, reward: -21.0, running_reward: -20.2052, time (sec): 492.9760\n",
      "Ep. 248 done, reward: -18.0, running_reward: -20.1811, time (sec): 497.2347\n",
      "Ep. 250 done, reward: -21.0, running_reward: -20.1974, time (sec): 501.0296\n",
      "Ep. 252 done, reward: -21.0, running_reward: -20.2035, time (sec): 505.5545\n",
      "Ep. 254 done, reward: -20.0, running_reward: -20.1797, time (sec): 510.0458\n",
      "Ep. 256 done, reward: -21.0, running_reward: -20.1960, time (sec): 514.1018\n",
      "Ep. 258 done, reward: -20.0, running_reward: -20.1921, time (sec): 518.7720\n",
      "Ep. 260 done, reward: -18.0, running_reward: -20.1782, time (sec): 523.0377\n",
      "Ep. 262 done, reward: -20.0, running_reward: -20.1746, time (sec): 527.3114\n",
      "Ep. 264 done, reward: -20.0, running_reward: -20.1612, time (sec): 531.5893\n",
      "Ep. 266 done, reward: -21.0, running_reward: -20.1779, time (sec): 535.3354\n",
      "Ep. 268 done, reward: -20.0, running_reward: -20.1843, time (sec): 539.3170\n",
      "Ep. 270 done, reward: -21.0, running_reward: -20.1906, time (sec): 543.9238\n",
      "Ep. 272 done, reward: -21.0, running_reward: -20.1968, time (sec): 547.9982\n",
      "Ep. 274 done, reward: -21.0, running_reward: -20.1831, time (sec): 551.6586\n",
      "Ep. 276 done, reward: -21.0, running_reward: -20.1994, time (sec): 556.4235\n",
      "Ep. 278 done, reward: -20.0, running_reward: -20.2053, time (sec): 560.9316\n",
      "Ep. 280 done, reward: -21.0, running_reward: -20.2112, time (sec): 565.2242\n",
      "Ep. 282 done, reward: -20.0, running_reward: -20.2070, time (sec): 568.8802\n",
      "Ep. 284 done, reward: -21.0, running_reward: -20.2228, time (sec): 572.6673\n",
      "Ep. 286 done, reward: -21.0, running_reward: -20.2185, time (sec): 576.1834\n",
      "Ep. 288 done, reward: -20.0, running_reward: -20.2141, time (sec): 580.2100\n",
      "Ep. 290 done, reward: -19.0, running_reward: -20.1999, time (sec): 585.1042\n",
      "Ep. 292 done, reward: -19.0, running_reward: -20.1958, time (sec): 589.4667\n",
      "Ep. 294 done, reward: -21.0, running_reward: -20.2019, time (sec): 593.2133\n",
      "Ep. 296 done, reward: -21.0, running_reward: -20.2079, time (sec): 597.5447\n",
      "Ep. 298 done, reward: -21.0, running_reward: -20.2137, time (sec): 601.9519\n",
      "Ep. 300 done, reward: -18.0, running_reward: -20.1994, time (sec): 607.1232\n",
      "Ep. 302 done, reward: -21.0, running_reward: -20.2054, time (sec): 610.5321\n",
      "Ep. 304 done, reward: -19.0, running_reward: -20.2012, time (sec): 614.3473\n",
      "Ep. 306 done, reward: -20.0, running_reward: -20.1873, time (sec): 618.3133\n",
      "Ep. 308 done, reward: -20.0, running_reward: -20.1935, time (sec): 622.9872\n",
      "Ep. 310 done, reward: -20.0, running_reward: -20.1896, time (sec): 627.2259\n",
      "Ep. 312 done, reward: -19.0, running_reward: -20.1858, time (sec): 631.3941\n",
      "Ep. 314 done, reward: -19.0, running_reward: -20.1820, time (sec): 635.9672\n",
      "Ep. 316 done, reward: -16.0, running_reward: -20.1284, time (sec): 641.0378\n",
      "Ep. 318 done, reward: -21.0, running_reward: -20.1359, time (sec): 644.8786\n",
      "Ep. 320 done, reward: -19.0, running_reward: -20.1133, time (sec): 649.9336\n",
      "Ep. 322 done, reward: -20.0, running_reward: -20.0912, time (sec): 654.4984\n",
      "Ep. 324 done, reward: -18.0, running_reward: -20.0793, time (sec): 658.4110\n",
      "Ep. 326 done, reward: -21.0, running_reward: -20.0877, time (sec): 662.6004\n",
      "Ep. 328 done, reward: -20.0, running_reward: -20.0860, time (sec): 666.3399\n",
      "Ep. 330 done, reward: -21.0, running_reward: -20.1042, time (sec): 670.3722\n",
      "Ep. 332 done, reward: -18.0, running_reward: -20.0722, time (sec): 675.0149\n",
      "Ep. 334 done, reward: -19.0, running_reward: -20.0707, time (sec): 679.0484\n",
      "Ep. 336 done, reward: -19.0, running_reward: -20.0692, time (sec): 682.9627\n",
      "Ep. 338 done, reward: -20.0, running_reward: -20.0777, time (sec): 688.0035\n",
      "Ep. 340 done, reward: -20.0, running_reward: -20.0662, time (sec): 693.1297\n",
      "Ep. 342 done, reward: -21.0, running_reward: -20.0749, time (sec): 697.3491\n",
      "Ep. 344 done, reward: -20.0, running_reward: -20.0833, time (sec): 701.6355\n",
      "Ep. 346 done, reward: -21.0, running_reward: -20.0917, time (sec): 706.1489\n",
      "Ep. 348 done, reward: -19.0, running_reward: -20.0699, time (sec): 710.9532\n",
      "Ep. 350 done, reward: -20.0, running_reward: -20.0488, time (sec): 716.3473\n",
      "Ep. 352 done, reward: -21.0, running_reward: -20.0380, time (sec): 720.2462\n",
      "Ep. 354 done, reward: -18.0, running_reward: -20.0172, time (sec): 725.1434\n",
      "Ep. 356 done, reward: -21.0, running_reward: -20.0368, time (sec): 728.8354\n",
      "Ep. 358 done, reward: -19.0, running_reward: -20.0261, time (sec): 733.0289\n",
      "Ep. 360 done, reward: -20.0, running_reward: -20.0057, time (sec): 738.2056\n",
      "Ep. 362 done, reward: -18.0, running_reward: -19.9856, time (sec): 742.8455\n",
      "Ep. 364 done, reward: -20.0, running_reward: -19.9958, time (sec): 747.0380\n",
      "Ep. 366 done, reward: -21.0, running_reward: -19.9960, time (sec): 751.4846\n",
      "Ep. 368 done, reward: -16.0, running_reward: -19.9660, time (sec): 756.9833\n",
      "Ep. 370 done, reward: -21.0, running_reward: -19.9271, time (sec): 762.7543\n",
      "Ep. 372 done, reward: -21.0, running_reward: -19.9485, time (sec): 767.5303\n",
      "Ep. 374 done, reward: -20.0, running_reward: -19.9297, time (sec): 772.4575\n",
      "Ep. 376 done, reward: -19.0, running_reward: -19.9013, time (sec): 777.5204\n",
      "Ep. 378 done, reward: -19.0, running_reward: -19.8834, time (sec): 782.4346\n",
      "Ep. 380 done, reward: -20.0, running_reward: -19.8758, time (sec): 787.1021\n",
      "Ep. 382 done, reward: -19.0, running_reward: -19.8584, time (sec): 792.5011\n",
      "Ep. 384 done, reward: -20.0, running_reward: -19.8513, time (sec): 797.0333\n",
      "Ep. 386 done, reward: -19.0, running_reward: -19.8443, time (sec): 802.2598\n",
      "Ep. 388 done, reward: -20.0, running_reward: -19.8474, time (sec): 807.0803\n",
      "Ep. 390 done, reward: -21.0, running_reward: -19.8703, time (sec): 811.5053\n",
      "Ep. 392 done, reward: -21.0, running_reward: -19.8928, time (sec): 816.3738\n",
      "Ep. 394 done, reward: -18.0, running_reward: -19.8749, time (sec): 821.9578\n",
      "Ep. 396 done, reward: -21.0, running_reward: -19.8775, time (sec): 826.5330\n",
      "Ep. 398 done, reward: -21.0, running_reward: -19.8998, time (sec): 831.1804\n",
      "Ep. 400 done, reward: -20.0, running_reward: -19.8919, time (sec): 836.4691\n",
      "Ep. 402 done, reward: -20.0, running_reward: -19.8842, time (sec): 840.7971\n",
      "Ep. 404 done, reward: -16.0, running_reward: -19.8267, time (sec): 845.7266\n",
      "Ep. 406 done, reward: -18.0, running_reward: -19.8002, time (sec): 850.2670\n",
      "Ep. 408 done, reward: -21.0, running_reward: -19.8241, time (sec): 853.9994\n",
      "Ep. 410 done, reward: -18.0, running_reward: -19.7977, time (sec): 859.5184\n",
      "Ep. 412 done, reward: -19.0, running_reward: -19.8016, time (sec): 863.9883\n",
      "Ep. 414 done, reward: -16.0, running_reward: -19.7656, time (sec): 869.3529\n",
      "Ep. 416 done, reward: -19.0, running_reward: -19.7602, time (sec): 873.9515\n",
      "Ep. 418 done, reward: -20.0, running_reward: -19.7650, time (sec): 877.9903\n",
      "Ep. 420 done, reward: -19.0, running_reward: -19.7597, time (sec): 882.7108\n",
      "Ep. 422 done, reward: -21.0, running_reward: -19.7646, time (sec): 887.6073\n",
      "Ep. 424 done, reward: -21.0, running_reward: -19.7793, time (sec): 892.4345\n",
      "Ep. 426 done, reward: -15.0, running_reward: -19.7238, time (sec): 898.5899\n",
      "Ep. 428 done, reward: -20.0, running_reward: -19.7293, time (sec): 903.4718\n",
      "Ep. 430 done, reward: -21.0, running_reward: -19.7347, time (sec): 908.4636\n",
      "Ep. 432 done, reward: -21.0, running_reward: -19.7302, time (sec): 913.0976\n",
      "Ep. 434 done, reward: -18.0, running_reward: -19.7156, time (sec): 918.3090\n",
      "Ep. 436 done, reward: -19.0, running_reward: -19.7211, time (sec): 923.2855\n",
      "Ep. 438 done, reward: -17.0, running_reward: -19.7066, time (sec): 928.2577\n",
      "Ep. 440 done, reward: -21.0, running_reward: -19.7224, time (sec): 932.7870\n",
      "Ep. 442 done, reward: -19.0, running_reward: -19.7180, time (sec): 938.3916\n",
      "Ep. 444 done, reward: -19.0, running_reward: -19.7235, time (sec): 943.3426\n",
      "Ep. 446 done, reward: -20.0, running_reward: -19.7191, time (sec): 947.6862\n",
      "Ep. 448 done, reward: -17.0, running_reward: -19.6650, time (sec): 953.3260\n",
      "Ep. 450 done, reward: -21.0, running_reward: -19.6618, time (sec): 958.6937\n",
      "Ep. 452 done, reward: -21.0, running_reward: -19.6885, time (sec): 963.3989\n",
      "Ep. 454 done, reward: -20.0, running_reward: -19.6848, time (sec): 968.1950\n",
      "Ep. 456 done, reward: -15.0, running_reward: -19.6311, time (sec): 974.4573\n",
      "Ep. 458 done, reward: -20.0, running_reward: -19.6088, time (sec): 980.0467\n",
      "Ep. 460 done, reward: -19.0, running_reward: -19.5769, time (sec): 986.0028\n",
      "Ep. 462 done, reward: -19.0, running_reward: -19.5555, time (sec): 990.7563\n",
      "Ep. 464 done, reward: -18.0, running_reward: -19.5443, time (sec): 995.6952\n",
      "Ep. 466 done, reward: -21.0, running_reward: -19.5634, time (sec): 1001.0329\n",
      "Ep. 468 done, reward: -18.0, running_reward: -19.5224, time (sec): 1008.2359\n",
      "Ep. 470 done, reward: -21.0, running_reward: -19.5023, time (sec): 1014.1630\n",
      "Ep. 472 done, reward: -18.0, running_reward: -19.5021, time (sec): 1019.2900\n",
      "Ep. 474 done, reward: -19.0, running_reward: -19.5119, time (sec): 1024.8190\n",
      "Ep. 476 done, reward: -21.0, running_reward: -19.5217, time (sec): 1030.0896\n",
      "Ep. 478 done, reward: -19.0, running_reward: -19.5014, time (sec): 1035.6050\n",
      "Ep. 480 done, reward: -21.0, running_reward: -19.5214, time (sec): 1039.8636\n",
      "Ep. 482 done, reward: -16.0, running_reward: -19.4810, time (sec): 1045.5339\n",
      "Ep. 484 done, reward: -19.0, running_reward: -19.4318, time (sec): 1051.2918\n",
      "Ep. 486 done, reward: -19.0, running_reward: -19.4331, time (sec): 1056.7374\n",
      "Ep. 488 done, reward: -19.0, running_reward: -19.4146, time (sec): 1063.0490\n",
      "Ep. 490 done, reward: -18.0, running_reward: -19.3963, time (sec): 1068.8255\n",
      "Ep. 492 done, reward: -18.0, running_reward: -19.3884, time (sec): 1074.2572\n",
      "Ep. 494 done, reward: -21.0, running_reward: -19.4006, time (sec): 1080.2874\n",
      "Ep. 496 done, reward: -19.0, running_reward: -19.4026, time (sec): 1085.6757\n",
      "Ep. 498 done, reward: -20.0, running_reward: -19.4243, time (sec): 1090.9869\n",
      "Ep. 500 done, reward: -21.0, running_reward: -19.4458, time (sec): 1096.4020\n",
      "Ep. 502 done, reward: -20.0, running_reward: -19.4568, time (sec): 1101.2297\n",
      "Ep. 504 done, reward: -21.0, running_reward: -19.4875, time (sec): 1106.6056\n",
      "Ep. 506 done, reward: -21.0, running_reward: -19.4978, time (sec): 1111.3815\n",
      "Ep. 508 done, reward: -19.0, running_reward: -19.4879, time (sec): 1116.0343\n",
      "Ep. 510 done, reward: -21.0, running_reward: -19.4982, time (sec): 1121.4956\n",
      "Ep. 512 done, reward: -20.0, running_reward: -19.5181, time (sec): 1126.8786\n",
      "Ep. 514 done, reward: -19.0, running_reward: -19.5276, time (sec): 1132.1750\n",
      "Ep. 516 done, reward: -18.0, running_reward: -19.5071, time (sec): 1138.4488\n",
      "Ep. 518 done, reward: -20.0, running_reward: -19.5268, time (sec): 1143.2872\n",
      "Ep. 520 done, reward: -16.0, running_reward: -19.4764, time (sec): 1148.6171\n",
      "Ep. 522 done, reward: -19.0, running_reward: -19.4669, time (sec): 1153.6627\n",
      "Ep. 524 done, reward: -21.0, running_reward: -19.4578, time (sec): 1159.1841\n",
      "Ep. 526 done, reward: -19.0, running_reward: -19.4388, time (sec): 1164.4060\n",
      "Ep. 528 done, reward: -21.0, running_reward: -19.4699, time (sec): 1168.5451\n",
      "Ep. 530 done, reward: -21.0, running_reward: -19.5004, time (sec): 1173.4553\n",
      "Ep. 532 done, reward: -21.0, running_reward: -19.5104, time (sec): 1179.4386\n",
      "Ep. 534 done, reward: -15.0, running_reward: -19.4503, time (sec): 1185.1446\n",
      "Ep. 536 done, reward: -20.0, running_reward: -19.4514, time (sec): 1189.8824\n",
      "Ep. 538 done, reward: -20.0, running_reward: -19.4425, time (sec): 1195.2818\n",
      "Ep. 540 done, reward: -19.0, running_reward: -19.4436, time (sec): 1200.9209\n",
      "Ep. 542 done, reward: -19.0, running_reward: -19.4150, time (sec): 1206.5788\n",
      "Ep. 544 done, reward: -19.0, running_reward: -19.4067, time (sec): 1211.3808\n",
      "Ep. 546 done, reward: -19.0, running_reward: -19.4085, time (sec): 1216.0895\n",
      "Ep. 548 done, reward: -19.0, running_reward: -19.3608, time (sec): 1223.2885\n",
      "Ep. 550 done, reward: -21.0, running_reward: -19.3835, time (sec): 1228.5206\n",
      "Ep. 552 done, reward: -21.0, running_reward: -19.3959, time (sec): 1233.9273\n",
      "Ep. 554 done, reward: -19.0, running_reward: -19.3682, time (sec): 1238.6339\n",
      "Ep. 556 done, reward: -21.0, running_reward: -19.3809, time (sec): 1244.0533\n",
      "Ep. 558 done, reward: -21.0, running_reward: -19.4032, time (sec): 1249.4458\n",
      "Ep. 560 done, reward: -21.0, running_reward: -19.4350, time (sec): 1254.8410\n",
      "Ep. 562 done, reward: -21.0, running_reward: -19.4463, time (sec): 1259.8636\n",
      "Ep. 564 done, reward: -17.0, running_reward: -19.4075, time (sec): 1265.9854\n",
      "Ep. 566 done, reward: -20.0, running_reward: -19.4292, time (sec): 1271.5216\n",
      "Ep. 568 done, reward: -21.0, running_reward: -19.4407, time (sec): 1276.7395\n",
      "Ep. 570 done, reward: -17.0, running_reward: -19.4119, time (sec): 1282.7181\n",
      "Ep. 572 done, reward: -19.0, running_reward: -19.4235, time (sec): 1288.2480\n",
      "Ep. 574 done, reward: -21.0, running_reward: -19.4252, time (sec): 1294.5715\n",
      "Ep. 576 done, reward: -20.0, running_reward: -19.4069, time (sec): 1300.8077\n",
      "Ep. 578 done, reward: -18.0, running_reward: -19.3888, time (sec): 1305.6612\n",
      "Ep. 580 done, reward: -21.0, running_reward: -19.4110, time (sec): 1310.7171\n",
      "Ep. 582 done, reward: -19.0, running_reward: -19.4028, time (sec): 1316.2211\n",
      "Ep. 584 done, reward: -20.0, running_reward: -19.4048, time (sec): 1321.2821\n",
      "Ep. 586 done, reward: -21.0, running_reward: -19.4266, time (sec): 1327.1709\n",
      "Ep. 588 done, reward: -17.0, running_reward: -19.3981, time (sec): 1334.4487\n",
      "Ep. 590 done, reward: -19.0, running_reward: -19.4100, time (sec): 1340.8071\n",
      "Ep. 592 done, reward: -20.0, running_reward: -19.4119, time (sec): 1345.5617\n",
      "Ep. 594 done, reward: -21.0, running_reward: -19.4435, time (sec): 1351.3087\n",
      "Ep. 596 done, reward: -19.0, running_reward: -19.4445, time (sec): 1356.5263\n",
      "Ep. 598 done, reward: -20.0, running_reward: -19.4259, time (sec): 1361.0840\n",
      "Ep. 600 done, reward: -20.0, running_reward: -19.4274, time (sec): 1366.3798\n",
      "Ep. 602 done, reward: -16.0, running_reward: -19.3691, time (sec): 1373.2933\n",
      "Ep. 604 done, reward: -17.0, running_reward: -19.3616, time (sec): 1378.2987\n",
      "Ep. 606 done, reward: -20.0, running_reward: -19.3248, time (sec): 1384.8633\n",
      "Ep. 608 done, reward: -20.0, running_reward: -19.3481, time (sec): 1390.8084\n",
      "Ep. 610 done, reward: -18.0, running_reward: -19.3114, time (sec): 1397.5889\n",
      "Ep. 612 done, reward: -15.0, running_reward: -19.2652, time (sec): 1404.7462\n",
      "Ep. 614 done, reward: -21.0, running_reward: -19.2898, time (sec): 1410.4028\n",
      "Ep. 616 done, reward: -20.0, running_reward: -19.2940, time (sec): 1416.4249\n",
      "Ep. 618 done, reward: -18.0, running_reward: -19.2782, time (sec): 1422.2196\n",
      "Ep. 620 done, reward: -21.0, running_reward: -19.3125, time (sec): 1427.0673\n",
      "Ep. 622 done, reward: -19.0, running_reward: -19.3161, time (sec): 1433.3064\n",
      "Ep. 624 done, reward: -18.0, running_reward: -19.3097, time (sec): 1438.2152\n",
      "Ep. 626 done, reward: -20.0, running_reward: -19.3037, time (sec): 1443.6893\n",
      "Ep. 628 done, reward: -18.0, running_reward: -19.2975, time (sec): 1449.2338\n",
      "Ep. 630 done, reward: -18.0, running_reward: -19.3014, time (sec): 1454.8671\n",
      "Ep. 632 done, reward: -19.0, running_reward: -19.2954, time (sec): 1461.2088\n",
      "Ep. 634 done, reward: -15.0, running_reward: -19.2396, time (sec): 1468.4782\n",
      "Ep. 636 done, reward: -19.0, running_reward: -19.2250, time (sec): 1474.7404\n",
      "Ep. 638 done, reward: -20.0, running_reward: -19.2404, time (sec): 1480.3770\n",
      "Ep. 640 done, reward: -19.0, running_reward: -19.2257, time (sec): 1486.6015\n",
      "Ep. 642 done, reward: -21.0, running_reward: -19.2313, time (sec): 1493.7615\n",
      "Ep. 644 done, reward: -19.0, running_reward: -19.2069, time (sec): 1499.7915\n",
      "Ep. 646 done, reward: -19.0, running_reward: -19.1830, time (sec): 1504.8412\n",
      "Ep. 648 done, reward: -20.0, running_reward: -19.1894, time (sec): 1511.2854\n",
      "Ep. 650 done, reward: -21.0, running_reward: -19.2155, time (sec): 1516.7394\n",
      "Ep. 652 done, reward: -20.0, running_reward: -19.1816, time (sec): 1521.8465\n",
      "Ep. 654 done, reward: -17.0, running_reward: -19.1778, time (sec): 1528.2323\n",
      "Ep. 656 done, reward: -17.0, running_reward: -19.1443, time (sec): 1535.0215\n",
      "Ep. 658 done, reward: -21.0, running_reward: -19.1417, time (sec): 1540.8925\n",
      "Ep. 660 done, reward: -19.0, running_reward: -19.1389, time (sec): 1547.2806\n",
      "Ep. 662 done, reward: -18.0, running_reward: -19.1459, time (sec): 1552.6945\n",
      "Ep. 664 done, reward: -19.0, running_reward: -19.1430, time (sec): 1557.7668\n",
      "Ep. 666 done, reward: -16.0, running_reward: -19.1299, time (sec): 1564.2348\n",
      "Ep. 668 done, reward: -18.0, running_reward: -19.1273, time (sec): 1570.9530\n",
      "Ep. 670 done, reward: -17.0, running_reward: -19.0948, time (sec): 1577.6798\n",
      "Ep. 672 done, reward: -19.0, running_reward: -19.1028, time (sec): 1584.2343\n",
      "Ep. 674 done, reward: -16.0, running_reward: -19.0609, time (sec): 1590.8483\n",
      "Ep. 676 done, reward: -20.0, running_reward: -19.0598, time (sec): 1596.9464\n",
      "Ep. 678 done, reward: -21.0, running_reward: -19.0786, time (sec): 1603.2258\n",
      "Ep. 680 done, reward: -19.0, running_reward: -19.0869, time (sec): 1610.4297\n",
      "Ep. 682 done, reward: -19.0, running_reward: -19.0753, time (sec): 1617.0548\n",
      "Ep. 684 done, reward: -19.0, running_reward: -19.0936, time (sec): 1623.8104\n",
      "Ep. 686 done, reward: -15.0, running_reward: -19.0418, time (sec): 1629.8844\n",
      "Ep. 688 done, reward: -21.0, running_reward: -19.0214, time (sec): 1636.3033\n",
      "Ep. 690 done, reward: -19.0, running_reward: -19.0111, time (sec): 1642.8926\n",
      "Ep. 692 done, reward: -20.0, running_reward: -19.0407, time (sec): 1649.6713\n",
      "Ep. 694 done, reward: -21.0, running_reward: -19.0796, time (sec): 1655.9999\n",
      "Ep. 696 done, reward: -18.0, running_reward: -19.0879, time (sec): 1661.3586\n",
      "Ep. 698 done, reward: -19.0, running_reward: -19.0762, time (sec): 1667.2343\n",
      "Ep. 700 done, reward: -20.0, running_reward: -19.0847, time (sec): 1673.2672\n",
      "Ep. 702 done, reward: -19.0, running_reward: -19.0731, time (sec): 1678.9542\n",
      "Ep. 704 done, reward: -20.0, running_reward: -19.0718, time (sec): 1684.9298\n",
      "Ep. 706 done, reward: -19.0, running_reward: -19.0703, time (sec): 1691.6183\n",
      "Ep. 708 done, reward: -16.0, running_reward: -19.0191, time (sec): 1698.7939\n",
      "Ep. 710 done, reward: -17.0, running_reward: -18.9591, time (sec): 1706.3965\n",
      "Ep. 712 done, reward: -17.0, running_reward: -18.9202, time (sec): 1714.0111\n",
      "Ep. 714 done, reward: -18.0, running_reward: -18.9316, time (sec): 1720.3164\n",
      "Ep. 716 done, reward: -19.0, running_reward: -18.9329, time (sec): 1727.0189\n",
      "Ep. 718 done, reward: -16.0, running_reward: -18.8745, time (sec): 1733.9241\n",
      "Ep. 720 done, reward: -17.0, running_reward: -18.8669, time (sec): 1739.7486\n",
      "Ep. 722 done, reward: -19.0, running_reward: -18.8597, time (sec): 1746.6639\n",
      "Ep. 724 done, reward: -17.0, running_reward: -18.7930, time (sec): 1754.7503\n",
      "Ep. 726 done, reward: -19.0, running_reward: -18.7773, time (sec): 1760.7365\n",
      "Ep. 728 done, reward: -19.0, running_reward: -18.7916, time (sec): 1767.3227\n",
      "Ep. 730 done, reward: -19.0, running_reward: -18.7760, time (sec): 1775.1340\n",
      "Ep. 732 done, reward: -17.0, running_reward: -18.7604, time (sec): 1781.5367\n",
      "Ep. 734 done, reward: -16.0, running_reward: -18.7352, time (sec): 1788.4102\n",
      "Ep. 736 done, reward: -20.0, running_reward: -18.7505, time (sec): 1794.1948\n",
      "Ep. 738 done, reward: -19.0, running_reward: -18.7653, time (sec): 1800.8284\n",
      "Ep. 740 done, reward: -19.0, running_reward: -18.7502, time (sec): 1808.0134\n",
      "Ep. 742 done, reward: -17.0, running_reward: -18.7352, time (sec): 1814.7505\n",
      "Ep. 744 done, reward: -19.0, running_reward: -18.7108, time (sec): 1820.8238\n",
      "Ep. 746 done, reward: -18.0, running_reward: -18.7065, time (sec): 1828.4621\n",
      "Ep. 748 done, reward: -19.0, running_reward: -18.7123, time (sec): 1835.2951\n",
      "Ep. 750 done, reward: -20.0, running_reward: -18.7479, time (sec): 1841.7826\n",
      "Ep. 752 done, reward: -20.0, running_reward: -18.7629, time (sec): 1847.6935\n",
      "Ep. 754 done, reward: -21.0, running_reward: -18.7876, time (sec): 1854.0809\n",
      "Ep. 756 done, reward: -18.0, running_reward: -18.7818, time (sec): 1861.2223\n",
      "Ep. 758 done, reward: -17.0, running_reward: -18.7761, time (sec): 1868.5083\n",
      "Ep. 760 done, reward: -19.0, running_reward: -18.7904, time (sec): 1875.3901\n",
      "Ep. 762 done, reward: -19.0, running_reward: -18.8144, time (sec): 1881.1332\n",
      "Ep. 764 done, reward: -21.0, running_reward: -18.8480, time (sec): 1885.9205\n",
      "Ep. 766 done, reward: -19.0, running_reward: -18.8708, time (sec): 1891.7217\n",
      "Ep. 768 done, reward: -19.0, running_reward: -18.8734, time (sec): 1897.2327\n",
      "Ep. 770 done, reward: -20.0, running_reward: -18.8760, time (sec): 1905.0531\n",
      "Ep. 772 done, reward: -21.0, running_reward: -18.8787, time (sec): 1911.5112\n",
      "Ep. 774 done, reward: -19.0, running_reward: -18.8217, time (sec): 1918.4003\n",
      "Ep. 776 done, reward: -21.0, running_reward: -18.8353, time (sec): 1925.3321\n",
      "Ep. 778 done, reward: -17.0, running_reward: -18.8186, time (sec): 1933.1160\n",
      "Ep. 780 done, reward: -19.0, running_reward: -18.8123, time (sec): 1939.7291\n",
      "Ep. 782 done, reward: -20.0, running_reward: -18.8360, time (sec): 1945.8716\n",
      "Ep. 784 done, reward: -19.0, running_reward: -18.7996, time (sec): 1953.2783\n",
      "Ep. 786 done, reward: -19.0, running_reward: -18.8135, time (sec): 1960.5912\n",
      "Ep. 788 done, reward: -16.0, running_reward: -18.7872, time (sec): 1966.8201\n",
      "Ep. 790 done, reward: -18.0, running_reward: -18.7518, time (sec): 1973.7300\n",
      "Ep. 792 done, reward: -18.0, running_reward: -18.7665, time (sec): 1979.5586\n",
      "Ep. 794 done, reward: -21.0, running_reward: -18.7911, time (sec): 1985.8944\n",
      "Ep. 796 done, reward: -20.0, running_reward: -18.7558, time (sec): 1992.3377\n",
      "Ep. 798 done, reward: -20.0, running_reward: -18.7806, time (sec): 1999.2550\n",
      "Ep. 800 done, reward: -18.0, running_reward: -18.7848, time (sec): 2004.8038\n",
      "Ep. 802 done, reward: -20.0, running_reward: -18.7892, time (sec): 2013.2206\n",
      "Ep. 804 done, reward: -17.0, running_reward: -18.7536, time (sec): 2020.1368\n",
      "Ep. 806 done, reward: -18.0, running_reward: -18.7683, time (sec): 2026.3129\n",
      "Ep. 808 done, reward: -17.0, running_reward: -18.7232, time (sec): 2033.8062\n",
      "Ep. 810 done, reward: -20.0, running_reward: -18.7585, time (sec): 2040.1904\n",
      "Ep. 812 done, reward: -15.0, running_reward: -18.6837, time (sec): 2047.5263\n",
      "Ep. 814 done, reward: -16.0, running_reward: -18.6303, time (sec): 2055.5726\n",
      "Ep. 816 done, reward: -19.0, running_reward: -18.6377, time (sec): 2061.7790\n",
      "Ep. 818 done, reward: -17.0, running_reward: -18.6348, time (sec): 2067.3762\n",
      "Ep. 820 done, reward: -16.0, running_reward: -18.6022, time (sec): 2075.6250\n",
      "Ep. 822 done, reward: -19.0, running_reward: -18.6299, time (sec): 2083.3116\n",
      "Ep. 824 done, reward: -18.0, running_reward: -18.6074, time (sec): 2090.2602\n",
      "Ep. 826 done, reward: -20.0, running_reward: -18.6055, time (sec): 2097.7192\n",
      "Ep. 828 done, reward: -20.0, running_reward: -18.6035, time (sec): 2103.5722\n",
      "Ep. 830 done, reward: -19.0, running_reward: -18.6015, time (sec): 2109.9989\n",
      "Ep. 832 done, reward: -19.0, running_reward: -18.6094, time (sec): 2117.3638\n",
      "Ep. 834 done, reward: -19.0, running_reward: -18.5974, time (sec): 2123.8492\n",
      "Ep. 836 done, reward: -21.0, running_reward: -18.6056, time (sec): 2130.9839\n",
      "Ep. 838 done, reward: -20.0, running_reward: -18.6136, time (sec): 2138.4161\n",
      "Ep. 840 done, reward: -16.0, running_reward: -18.5516, time (sec): 2146.5571\n",
      "Ep. 842 done, reward: -20.0, running_reward: -18.5607, time (sec): 2153.4938\n",
      "Ep. 844 done, reward: -20.0, running_reward: -18.5695, time (sec): 2160.8472\n",
      "Ep. 846 done, reward: -16.0, running_reward: -18.5283, time (sec): 2169.4846\n",
      "Ep. 848 done, reward: -18.0, running_reward: -18.5376, time (sec): 2175.2893\n",
      "Ep. 850 done, reward: -21.0, running_reward: -18.5866, time (sec): 2181.2930\n",
      "Ep. 852 done, reward: -17.0, running_reward: -18.5946, time (sec): 2188.5547\n",
      "Ep. 854 done, reward: -18.0, running_reward: -18.5927, time (sec): 2196.0918\n",
      "Ep. 856 done, reward: -16.0, running_reward: -18.5807, time (sec): 2202.6156\n",
      "Ep. 858 done, reward: -19.0, running_reward: -18.5494, time (sec): 2210.3435\n",
      "Ep. 860 done, reward: -13.0, running_reward: -18.4984, time (sec): 2217.4026\n",
      "Ep. 862 done, reward: -19.0, running_reward: -18.4787, time (sec): 2225.4137\n",
      "Ep. 864 done, reward: -19.0, running_reward: -18.4890, time (sec): 2232.7383\n",
      "Ep. 866 done, reward: -21.0, running_reward: -18.5192, time (sec): 2239.2009\n",
      "Ep. 868 done, reward: -19.0, running_reward: -18.5288, time (sec): 2246.2731\n",
      "Ep. 870 done, reward: -19.0, running_reward: -18.5481, time (sec): 2251.5238\n",
      "Ep. 872 done, reward: -20.0, running_reward: -18.5769, time (sec): 2258.6841\n",
      "Ep. 874 done, reward: -19.0, running_reward: -18.5854, time (sec): 2266.4257\n",
      "Ep. 876 done, reward: -21.0, running_reward: -18.5641, time (sec): 2274.7499\n",
      "Ep. 878 done, reward: -20.0, running_reward: -18.5927, time (sec): 2281.1777\n",
      "Ep. 880 done, reward: -18.0, running_reward: -18.5611, time (sec): 2289.0541\n",
      "Ep. 882 done, reward: -19.0, running_reward: -18.5401, time (sec): 2296.2768\n",
      "Ep. 884 done, reward: -19.0, running_reward: -18.5493, time (sec): 2303.6318\n",
      "Ep. 886 done, reward: -17.0, running_reward: -18.5383, time (sec): 2311.8339\n",
      "Ep. 888 done, reward: -19.0, running_reward: -18.5474, time (sec): 2318.2923\n",
      "Ep. 890 done, reward: -19.0, running_reward: -18.5168, time (sec): 2325.9214\n",
      "Ep. 892 done, reward: -21.0, running_reward: -18.5465, time (sec): 2333.0296\n",
      "Ep. 894 done, reward: -19.0, running_reward: -18.5258, time (sec): 2341.0299\n",
      "Ep. 896 done, reward: -20.0, running_reward: -18.5353, time (sec): 2348.2071\n",
      "Ep. 898 done, reward: -14.0, running_reward: -18.4748, time (sec): 2355.3242\n",
      "Ep. 900 done, reward: -18.0, running_reward: -18.4752, time (sec): 2363.5039\n",
      "Ep. 902 done, reward: -17.0, running_reward: -18.4657, time (sec): 2370.9173\n",
      "Ep. 904 done, reward: -18.0, running_reward: -18.4366, time (sec): 2378.6610\n",
      "Ep. 906 done, reward: -17.0, running_reward: -18.4080, time (sec): 2385.7097\n",
      "Ep. 908 done, reward: -18.0, running_reward: -18.3999, time (sec): 2393.1073\n",
      "Ep. 910 done, reward: -19.0, running_reward: -18.4217, time (sec): 2400.2657\n",
      "Ep. 912 done, reward: -18.0, running_reward: -18.3638, time (sec): 2408.2904\n",
      "Ep. 914 done, reward: -16.0, running_reward: -18.3663, time (sec): 2415.5525\n",
      "Ep. 916 done, reward: -21.0, running_reward: -18.3791, time (sec): 2422.5319\n",
      "Ep. 918 done, reward: -19.0, running_reward: -18.3717, time (sec): 2430.0690\n",
      "Ep. 920 done, reward: -15.0, running_reward: -18.3343, time (sec): 2437.9040\n",
      "Ep. 922 done, reward: -20.0, running_reward: -18.3377, time (sec): 2446.1721\n",
      "Ep. 924 done, reward: -19.0, running_reward: -18.3410, time (sec): 2453.2083\n",
      "Ep. 926 done, reward: -17.0, running_reward: -18.3341, time (sec): 2461.1210\n",
      "Ep. 928 done, reward: -20.0, running_reward: -18.3673, time (sec): 2468.0578\n",
      "Ep. 930 done, reward: -19.0, running_reward: -18.3799, time (sec): 2475.6207\n",
      "Ep. 932 done, reward: -18.0, running_reward: -18.4020, time (sec): 2482.9939\n",
      "Ep. 934 done, reward: -20.0, running_reward: -18.4338, time (sec): 2489.4001\n",
      "Ep. 936 done, reward: -19.0, running_reward: -18.4451, time (sec): 2495.3568\n",
      "Ep. 938 done, reward: -21.0, running_reward: -18.4365, time (sec): 2502.5551\n",
      "Ep. 940 done, reward: -18.0, running_reward: -18.4179, time (sec): 2509.6522\n",
      "Ep. 942 done, reward: -16.0, running_reward: -18.3995, time (sec): 2518.3515\n",
      "Ep. 944 done, reward: -19.0, running_reward: -18.3917, time (sec): 2524.2418\n",
      "Ep. 946 done, reward: -17.0, running_reward: -18.4036, time (sec): 2531.4093\n",
      "Ep. 948 done, reward: -20.0, running_reward: -18.3561, time (sec): 2539.1206\n",
      "Ep. 950 done, reward: -17.0, running_reward: -18.3390, time (sec): 2547.2091\n",
      "Ep. 952 done, reward: -17.0, running_reward: -18.2827, time (sec): 2555.1682\n",
      "Ep. 954 done, reward: -18.0, running_reward: -18.2870, time (sec): 2561.2088\n",
      "Ep. 956 done, reward: -19.0, running_reward: -18.3012, time (sec): 2569.0980\n",
      "Ep. 958 done, reward: -16.0, running_reward: -18.2950, time (sec): 2577.4928\n",
      "Ep. 960 done, reward: -20.0, running_reward: -18.2992, time (sec): 2584.6366\n",
      "Ep. 962 done, reward: -19.0, running_reward: -18.3032, time (sec): 2592.9373\n",
      "Ep. 964 done, reward: -18.0, running_reward: -18.2972, time (sec): 2599.7395\n",
      "Ep. 966 done, reward: -20.0, running_reward: -18.3212, time (sec): 2606.2870\n",
      "Ep. 968 done, reward: -19.0, running_reward: -18.3248, time (sec): 2613.0924\n",
      "Ep. 970 done, reward: -19.0, running_reward: -18.3382, time (sec): 2619.7699\n",
      "Ep. 972 done, reward: -18.0, running_reward: -18.3315, time (sec): 2626.0520\n",
      "Ep. 974 done, reward: -16.0, running_reward: -18.3148, time (sec): 2634.0551\n",
      "Ep. 976 done, reward: -15.0, running_reward: -18.3082, time (sec): 2641.9297\n",
      "Ep. 978 done, reward: -18.0, running_reward: -18.3120, time (sec): 2649.4306\n",
      "Ep. 980 done, reward: -19.0, running_reward: -18.3257, time (sec): 2657.0861\n",
      "Ep. 982 done, reward: -18.0, running_reward: -18.3192, time (sec): 2664.5060\n",
      "Ep. 984 done, reward: -16.0, running_reward: -18.3028, time (sec): 2671.0498\n",
      "Ep. 986 done, reward: -16.0, running_reward: -18.2965, time (sec): 2678.0023\n",
      "Ep. 988 done, reward: -17.0, running_reward: -18.2608, time (sec): 2686.8196\n",
      "Ep. 990 done, reward: -20.0, running_reward: -18.2658, time (sec): 2694.6705\n",
      "Ep. 992 done, reward: -19.0, running_reward: -18.2705, time (sec): 2701.5548\n",
      "Ep. 994 done, reward: -17.0, running_reward: -18.2749, time (sec): 2708.8566\n",
      "Ep. 996 done, reward: -16.0, running_reward: -18.2593, time (sec): 2716.3686\n",
      "Ep. 998 done, reward: -16.0, running_reward: -18.2242, time (sec): 2725.0143\n",
      "Ep. 1000 done, reward: -19.0, running_reward: -18.2298, time (sec): 2733.1312\n",
      "Ep. 1002 done, reward: -18.0, running_reward: -18.1955, time (sec): 2742.1920\n",
      "Ep. 1004 done, reward: -21.0, running_reward: -18.1919, time (sec): 2749.4089\n",
      "Ep. 1006 done, reward: -11.0, running_reward: -18.1181, time (sec): 2758.4861\n",
      "Ep. 1008 done, reward: -19.0, running_reward: -18.1159, time (sec): 2765.3821\n",
      "Ep. 1010 done, reward: -16.0, running_reward: -18.0836, time (sec): 2773.3673\n",
      "Ep. 1012 done, reward: -18.0, running_reward: -18.0919, time (sec): 2779.9559\n",
      "Ep. 1014 done, reward: -16.0, running_reward: -18.0602, time (sec): 2788.5346\n",
      "Ep. 1016 done, reward: -18.0, running_reward: -18.0689, time (sec): 2795.9138\n",
      "Ep. 1018 done, reward: -18.0, running_reward: -18.0477, time (sec): 2803.6814\n",
      "Ep. 1020 done, reward: -18.0, running_reward: -18.0566, time (sec): 2810.7579\n",
      "Ep. 1022 done, reward: -14.0, running_reward: -18.0254, time (sec): 2819.4875\n",
      "Ep. 1024 done, reward: -14.0, running_reward: -17.9849, time (sec): 2827.9307\n",
      "Ep. 1026 done, reward: -13.0, running_reward: -17.9352, time (sec): 2836.6907\n",
      "Ep. 1028 done, reward: -19.0, running_reward: -17.9465, time (sec): 2844.0037\n",
      "Ep. 1030 done, reward: -18.0, running_reward: -17.9377, time (sec): 2851.9598\n",
      "Ep. 1032 done, reward: -19.0, running_reward: -17.9588, time (sec): 2860.9028\n",
      "Ep. 1034 done, reward: -19.0, running_reward: -17.9894, time (sec): 2868.4766\n",
      "Ep. 1036 done, reward: -16.0, running_reward: -17.9795, time (sec): 2876.6110\n",
      "Ep. 1038 done, reward: -21.0, running_reward: -17.9901, time (sec): 2885.0347\n",
      "Ep. 1040 done, reward: -16.0, running_reward: -17.9703, time (sec): 2893.8514\n",
      "Ep. 1042 done, reward: -19.0, running_reward: -17.9710, time (sec): 2901.5237\n",
      "Ep. 1044 done, reward: -17.0, running_reward: -17.9517, time (sec): 2910.6817\n",
      "Ep. 1046 done, reward: -20.0, running_reward: -17.9430, time (sec): 2918.5275\n",
      "Ep. 1048 done, reward: -15.0, running_reward: -17.9240, time (sec): 2925.4746\n",
      "Ep. 1050 done, reward: -17.0, running_reward: -17.9056, time (sec): 2933.2744\n",
      "Ep. 1052 done, reward: -21.0, running_reward: -17.9177, time (sec): 2941.8803\n",
      "Ep. 1054 done, reward: -20.0, running_reward: -17.9690, time (sec): 2949.6371\n",
      "Ep. 1056 done, reward: -19.0, running_reward: -18.0093, time (sec): 2956.5589\n",
      "Ep. 1058 done, reward: -14.0, running_reward: -17.9494, time (sec): 2965.4231\n",
      "Ep. 1060 done, reward: -15.0, running_reward: -17.9501, time (sec): 2973.1145\n",
      "Ep. 1062 done, reward: -19.0, running_reward: -17.9710, time (sec): 2981.5891\n",
      "Ep. 1064 done, reward: -17.0, running_reward: -17.9318, time (sec): 2990.1912\n",
      "Ep. 1066 done, reward: -14.0, running_reward: -17.9031, time (sec): 2998.5060\n",
      "Ep. 1068 done, reward: -15.0, running_reward: -17.8750, time (sec): 3006.9797\n",
      "Ep. 1070 done, reward: -19.0, running_reward: -17.8875, time (sec): 3014.3339\n",
      "Ep. 1072 done, reward: -20.0, running_reward: -17.9097, time (sec): 3022.2266\n",
      "Ep. 1074 done, reward: -19.0, running_reward: -17.8918, time (sec): 3029.7617\n",
      "Ep. 1076 done, reward: -19.0, running_reward: -17.8941, time (sec): 3037.6287\n",
      "Ep. 1078 done, reward: -17.0, running_reward: -17.8961, time (sec): 3045.5159\n",
      "Ep. 1080 done, reward: -17.0, running_reward: -17.8684, time (sec): 3054.2174\n",
      "Ep. 1082 done, reward: -11.0, running_reward: -17.7713, time (sec): 3065.0122\n",
      "Ep. 1084 done, reward: -17.0, running_reward: -17.7955, time (sec): 3073.3694\n",
      "Ep. 1086 done, reward: -20.0, running_reward: -17.7998, time (sec): 3082.5343\n",
      "Ep. 1088 done, reward: -19.0, running_reward: -17.8138, time (sec): 3090.3335\n",
      "Ep. 1090 done, reward: -18.0, running_reward: -17.8076, time (sec): 3099.6502\n",
      "Ep. 1092 done, reward: -19.0, running_reward: -17.8511, time (sec): 3106.7294\n",
      "Ep. 1094 done, reward: -17.0, running_reward: -17.8342, time (sec): 3114.8031\n",
      "Ep. 1096 done, reward: -13.0, running_reward: -17.7776, time (sec): 3123.7162\n",
      "Ep. 1098 done, reward: -19.0, running_reward: -17.8019, time (sec): 3132.4319\n",
      "Ep. 1100 done, reward: -15.0, running_reward: -17.7660, time (sec): 3141.9843\n",
      "Ep. 1102 done, reward: -15.0, running_reward: -17.7505, time (sec): 3150.6737\n",
      "Ep. 1104 done, reward: -13.0, running_reward: -17.6758, time (sec): 3161.2615\n",
      "Ep. 1106 done, reward: -18.0, running_reward: -17.6624, time (sec): 3170.0398\n",
      "Ep. 1108 done, reward: -19.0, running_reward: -17.6692, time (sec): 3179.1439\n",
      "Ep. 1110 done, reward: -16.0, running_reward: -17.6657, time (sec): 3187.4211\n",
      "Ep. 1112 done, reward: -19.0, running_reward: -17.6725, time (sec): 3195.5207\n",
      "Ep. 1114 done, reward: -16.0, running_reward: -17.6491, time (sec): 3203.6843\n",
      "Ep. 1116 done, reward: -21.0, running_reward: -17.6564, time (sec): 3213.4539\n",
      "Ep. 1118 done, reward: -19.0, running_reward: -17.6336, time (sec): 3223.3492\n",
      "Ep. 1120 done, reward: -18.0, running_reward: -17.6013, time (sec): 3232.4990\n",
      "Ep. 1122 done, reward: -18.0, running_reward: -17.5894, time (sec): 3240.2389\n",
      "Ep. 1124 done, reward: -17.0, running_reward: -17.5777, time (sec): 3249.4495\n",
      "Ep. 1126 done, reward: -21.0, running_reward: -17.6260, time (sec): 3256.9643\n",
      "Ep. 1128 done, reward: -16.0, running_reward: -17.6234, time (sec): 3265.8924\n",
      "Ep. 1130 done, reward: -21.0, running_reward: -17.6312, time (sec): 3273.2935\n",
      "Ep. 1132 done, reward: -16.0, running_reward: -17.6086, time (sec): 3281.3086\n",
      "Ep. 1134 done, reward: -15.0, running_reward: -17.5369, time (sec): 3290.7516\n",
      "Ep. 1136 done, reward: -18.0, running_reward: -17.5461, time (sec): 3299.4730\n",
      "Ep. 1138 done, reward: -16.0, running_reward: -17.5450, time (sec): 3308.5728\n",
      "Ep. 1140 done, reward: -17.0, running_reward: -17.4451, time (sec): 3318.8444\n",
      "Ep. 1142 done, reward: -17.0, running_reward: -17.3966, time (sec): 3327.6143\n",
      "Ep. 1144 done, reward: -10.0, running_reward: -17.2494, time (sec): 3339.2680\n",
      "Ep. 1146 done, reward: -17.0, running_reward: -17.2643, time (sec): 3345.7317\n",
      "Ep. 1148 done, reward: -20.0, running_reward: -17.2890, time (sec): 3353.7311\n",
      "Ep. 1150 done, reward: -15.0, running_reward: -17.2831, time (sec): 3364.2727\n",
      "Ep. 1152 done, reward: -18.0, running_reward: -17.2973, time (sec): 3372.4932\n",
      "Ep. 1154 done, reward: -20.0, running_reward: -17.3214, time (sec): 3381.7202\n",
      "Ep. 1156 done, reward: -17.0, running_reward: -17.2952, time (sec): 3391.2747\n",
      "Ep. 1158 done, reward: -15.0, running_reward: -17.2693, time (sec): 3401.0833\n",
      "Ep. 1160 done, reward: -16.0, running_reward: -17.2540, time (sec): 3411.1783\n",
      "Ep. 1162 done, reward: -21.0, running_reward: -17.3087, time (sec): 3419.6030\n",
      "Ep. 1164 done, reward: -11.0, running_reward: -17.2624, time (sec): 3428.6547\n",
      "Ep. 1166 done, reward: -20.0, running_reward: -17.3070, time (sec): 3437.2814\n",
      "Ep. 1168 done, reward: -18.0, running_reward: -17.3307, time (sec): 3445.9290\n",
      "Ep. 1170 done, reward: -16.0, running_reward: -17.2943, time (sec): 3455.2068\n",
      "Ep. 1172 done, reward: -15.0, running_reward: -17.2783, time (sec): 3463.9535\n",
      "Ep. 1174 done, reward: -10.0, running_reward: -17.2325, time (sec): 3474.6620\n",
      "Ep. 1176 done, reward: -17.0, running_reward: -17.2477, time (sec): 3482.8312\n",
      "Ep. 1178 done, reward: -19.0, running_reward: -17.3023, time (sec): 3491.2000\n",
      "Ep. 1180 done, reward: -17.0, running_reward: -17.2864, time (sec): 3501.4312\n",
      "Ep. 1182 done, reward: -20.0, running_reward: -17.2909, time (sec): 3510.2766\n",
      "Ep. 1184 done, reward: -17.0, running_reward: -17.2653, time (sec): 3519.7520\n",
      "Ep. 1186 done, reward: -16.0, running_reward: -17.2500, time (sec): 3527.4610\n",
      "Ep. 1188 done, reward: -15.0, running_reward: -17.2152, time (sec): 3535.4171\n",
      "Ep. 1190 done, reward: -14.0, running_reward: -17.1908, time (sec): 3544.8938\n",
      "Ep. 1192 done, reward: -18.0, running_reward: -17.2267, time (sec): 3552.1799\n",
      "Ep. 1194 done, reward: -17.0, running_reward: -17.2222, time (sec): 3561.8914\n",
      "Ep. 1196 done, reward: -17.0, running_reward: -17.2079, time (sec): 3571.1675\n",
      "Ep. 1198 done, reward: -19.0, running_reward: -17.2237, time (sec): 3579.9428\n",
      "Ep. 1200 done, reward: -19.0, running_reward: -17.2096, time (sec): 3589.5889\n",
      "Ep. 1202 done, reward: -14.0, running_reward: -17.1655, time (sec): 3598.8014\n",
      "Ep. 1204 done, reward: -19.0, running_reward: -17.1129, time (sec): 3608.4846\n",
      "Ep. 1206 done, reward: -17.0, running_reward: -17.1206, time (sec): 3617.2809\n",
      "Ep. 1208 done, reward: -13.0, running_reward: -17.0881, time (sec): 3626.3348\n",
      "Ep. 1210 done, reward: -20.0, running_reward: -17.1163, time (sec): 3634.8096\n",
      "Ep. 1212 done, reward: -20.0, running_reward: -17.1242, time (sec): 3643.8829\n",
      "Ep. 1214 done, reward: -16.0, running_reward: -17.1315, time (sec): 3653.3535\n",
      "Ep. 1216 done, reward: -21.0, running_reward: -17.1887, time (sec): 3661.6195\n",
      "Ep. 1218 done, reward: -17.0, running_reward: -17.1849, time (sec): 3669.7726\n",
      "Ep. 1220 done, reward: -15.0, running_reward: -17.1613, time (sec): 3680.2842\n",
      "Ep. 1222 done, reward: -17.0, running_reward: -17.1779, time (sec): 3690.0337\n",
      "Ep. 1224 done, reward: -19.0, running_reward: -17.1844, time (sec): 3699.0007\n",
      "Ep. 1226 done, reward: -17.0, running_reward: -17.1708, time (sec): 3708.3457\n",
      "Ep. 1228 done, reward: -17.0, running_reward: -17.1971, time (sec): 3719.1739\n",
      "Ep. 1230 done, reward: -20.0, running_reward: -17.2232, time (sec): 3726.4874\n",
      "Ep. 1232 done, reward: -16.0, running_reward: -17.2286, time (sec): 3735.8007\n",
      "Ep. 1234 done, reward: -14.0, running_reward: -17.1940, time (sec): 3745.7619\n",
      "Ep. 1236 done, reward: -21.0, running_reward: -17.2203, time (sec): 3755.6819\n",
      "Ep. 1238 done, reward: -17.0, running_reward: -17.2357, time (sec): 3765.4851\n",
      "Ep. 1240 done, reward: -18.0, running_reward: -17.2608, time (sec): 3773.7133\n",
      "Ep. 1242 done, reward: -19.0, running_reward: -17.2657, time (sec): 3782.1924\n",
      "Ep. 1244 done, reward: -20.0, running_reward: -17.2904, time (sec): 3788.6371\n",
      "Ep. 1246 done, reward: -20.0, running_reward: -17.3047, time (sec): 3796.9055\n",
      "Ep. 1248 done, reward: -20.0, running_reward: -17.3485, time (sec): 3804.2592\n",
      "Ep. 1250 done, reward: -19.0, running_reward: -17.3318, time (sec): 3814.6810\n",
      "Ep. 1252 done, reward: -18.0, running_reward: -17.3451, time (sec): 3823.8918\n",
      "Ep. 1254 done, reward: -17.0, running_reward: -17.3185, time (sec): 3832.7911\n",
      "Ep. 1256 done, reward: -21.0, running_reward: -17.3719, time (sec): 3841.1767\n",
      "Ep. 1258 done, reward: -16.0, running_reward: -17.3446, time (sec): 3849.5360\n",
      "Ep. 1260 done, reward: -17.0, running_reward: -17.2784, time (sec): 3859.0521\n",
      "Ep. 1262 done, reward: -19.0, running_reward: -17.3126, time (sec): 3867.4940\n",
      "Ep. 1264 done, reward: -18.0, running_reward: -17.3362, time (sec): 3875.9377\n",
      "Ep. 1266 done, reward: -18.0, running_reward: -17.3692, time (sec): 3883.5465\n",
      "Ep. 1268 done, reward: -15.0, running_reward: -17.3419, time (sec): 3893.7869\n",
      "Ep. 1270 done, reward: -15.0, running_reward: -17.2854, time (sec): 3903.3636\n",
      "Ep. 1272 done, reward: -16.0, running_reward: -17.2400, time (sec): 3914.1037\n",
      "Ep. 1274 done, reward: -18.0, running_reward: -17.2254, time (sec): 3922.8175\n",
      "Ep. 1276 done, reward: -17.0, running_reward: -17.2011, time (sec): 3932.0888\n",
      "Ep. 1278 done, reward: -15.0, running_reward: -17.1870, time (sec): 3940.4728\n",
      "Ep. 1280 done, reward: -17.0, running_reward: -17.1635, time (sec): 3949.9737\n",
      "Ep. 1282 done, reward: -15.0, running_reward: -17.1403, time (sec): 3958.9187\n",
      "Ep. 1284 done, reward: -19.0, running_reward: -17.1377, time (sec): 3969.1217\n",
      "Ep. 1286 done, reward: -11.0, running_reward: -17.0650, time (sec): 3979.7849\n",
      "Ep. 1288 done, reward: -16.0, running_reward: -17.0141, time (sec): 3989.8240\n",
      "Ep. 1290 done, reward: -20.0, running_reward: -17.0636, time (sec): 3998.0326\n",
      "Ep. 1292 done, reward: -15.0, running_reward: -17.0523, time (sec): 4006.4891\n",
      "Ep. 1294 done, reward: -19.0, running_reward: -17.0811, time (sec): 4015.0628\n",
      "Ep. 1296 done, reward: -18.0, running_reward: -17.0994, time (sec): 4024.7520\n",
      "Ep. 1298 done, reward: -21.0, running_reward: -17.1572, time (sec): 4033.9141\n",
      "Ep. 1300 done, reward: -18.0, running_reward: -17.1839, time (sec): 4043.2166\n",
      "Ep. 1302 done, reward: -16.0, running_reward: -17.1406, time (sec): 4052.3367\n",
      "Ep. 1304 done, reward: -20.0, running_reward: -17.1777, time (sec): 4061.2180\n",
      "Ep. 1306 done, reward: -8.0, running_reward: -17.1138, time (sec): 4071.9039\n",
      "Ep. 1308 done, reward: -19.0, running_reward: -17.1217, time (sec): 4079.8575\n",
      "Ep. 1310 done, reward: -18.0, running_reward: -17.1292, time (sec): 4088.5266\n",
      "Ep. 1312 done, reward: -19.0, running_reward: -17.0972, time (sec): 4098.5333\n",
      "Ep. 1314 done, reward: -15.0, running_reward: -17.0950, time (sec): 4106.9948\n",
      "Ep. 1316 done, reward: -17.0, running_reward: -17.0634, time (sec): 4116.3610\n",
      "Ep. 1318 done, reward: -19.0, running_reward: -17.0624, time (sec): 4125.5050\n",
      "Ep. 1320 done, reward: -19.0, running_reward: -17.0514, time (sec): 4134.3622\n",
      "Ep. 1322 done, reward: -20.0, running_reward: -17.1002, time (sec): 4143.6798\n",
      "Ep. 1324 done, reward: -14.0, running_reward: -17.0682, time (sec): 4152.1293\n",
      "Ep. 1326 done, reward: -17.0, running_reward: -17.0372, time (sec): 4162.5084\n",
      "Ep. 1328 done, reward: -17.0, running_reward: -17.0463, time (sec): 4170.6735\n",
      "Ep. 1330 done, reward: -17.0, running_reward: -17.0850, time (sec): 4179.5717\n",
      "Ep. 1332 done, reward: -16.0, running_reward: -17.1129, time (sec): 4187.8762\n",
      "Ep. 1334 done, reward: -17.0, running_reward: -17.1305, time (sec): 4196.2974\n",
      "Ep. 1336 done, reward: -15.0, running_reward: -17.1178, time (sec): 4206.8916\n",
      "Ep. 1338 done, reward: -14.0, running_reward: -17.0854, time (sec): 4215.9925\n",
      "Ep. 1340 done, reward: -13.0, running_reward: -17.0041, time (sec): 4226.8405\n",
      "Ep. 1342 done, reward: -16.0, running_reward: -16.9643, time (sec): 4237.0701\n",
      "Ep. 1344 done, reward: -15.0, running_reward: -16.9649, time (sec): 4247.8633\n",
      "Ep. 1346 done, reward: -18.0, running_reward: -16.9855, time (sec): 4257.3617\n",
      "Ep. 1348 done, reward: -17.0, running_reward: -16.9758, time (sec): 4266.2994\n",
      "Ep. 1350 done, reward: -18.0, running_reward: -16.9764, time (sec): 4275.8099\n",
      "Ep. 1352 done, reward: -15.0, running_reward: -16.9668, time (sec): 4285.3465\n",
      "Ep. 1354 done, reward: -16.0, running_reward: -16.9179, time (sec): 4296.4278\n",
      "Ep. 1356 done, reward: -18.0, running_reward: -16.9394, time (sec): 4304.1452\n",
      "Ep. 1358 done, reward: -18.0, running_reward: -16.9209, time (sec): 4314.4702\n",
      "Ep. 1360 done, reward: -19.0, running_reward: -16.9425, time (sec): 4323.6865\n",
      "Ep. 1362 done, reward: -17.0, running_reward: -16.9436, time (sec): 4333.2591\n",
      "Ep. 1364 done, reward: -15.0, running_reward: -16.9544, time (sec): 4342.4920\n",
      "Ep. 1366 done, reward: -19.0, running_reward: -16.9951, time (sec): 4351.3246\n",
      "Ep. 1368 done, reward: -18.0, running_reward: -16.9755, time (sec): 4359.8346\n",
      "Ep. 1370 done, reward: -21.0, running_reward: -17.0358, time (sec): 4366.5630\n",
      "Ep. 1372 done, reward: -14.0, running_reward: -17.0051, time (sec): 4378.4912\n",
      "Ep. 1374 done, reward: -16.0, running_reward: -16.9752, time (sec): 4389.6179\n",
      "Ep. 1376 done, reward: -15.0, running_reward: -16.9557, time (sec): 4397.8280\n",
      "Ep. 1378 done, reward: -16.0, running_reward: -16.9070, time (sec): 4409.1070\n",
      "Ep. 1380 done, reward: -21.0, running_reward: -16.9686, time (sec): 4418.5948\n",
      "Ep. 1382 done, reward: -13.0, running_reward: -16.9194, time (sec): 4427.9083\n",
      "Ep. 1384 done, reward: -17.0, running_reward: -16.9309, time (sec): 4436.3060\n",
      "Ep. 1386 done, reward: -16.0, running_reward: -16.8826, time (sec): 4447.6607\n",
      "Ep. 1388 done, reward: -11.0, running_reward: -16.8151, time (sec): 4459.4039\n",
      "Ep. 1390 done, reward: -18.0, running_reward: -16.8387, time (sec): 4469.2519\n",
      "Ep. 1392 done, reward: -21.0, running_reward: -16.8522, time (sec): 4478.4893\n",
      "Ep. 1394 done, reward: -19.0, running_reward: -16.8553, time (sec): 4488.2283\n",
      "Ep. 1396 done, reward: -19.0, running_reward: -16.8881, time (sec): 4497.0161\n",
      "Ep. 1398 done, reward: -15.0, running_reward: -16.8406, time (sec): 4506.8501\n",
      "Ep. 1400 done, reward: -20.0, running_reward: -16.8639, time (sec): 4515.6099\n",
      "Ep. 1402 done, reward: -18.0, running_reward: -16.9162, time (sec): 4524.7073\n",
      "Ep. 1404 done, reward: -14.0, running_reward: -16.8582, time (sec): 4537.4414\n",
      "Ep. 1406 done, reward: -19.0, running_reward: -16.8612, time (sec): 4547.8961\n",
      "Ep. 1408 done, reward: -17.0, running_reward: -16.8540, time (sec): 4557.4286\n",
      "Ep. 1410 done, reward: -17.0, running_reward: -16.8570, time (sec): 4566.9451\n",
      "Ep. 1412 done, reward: -17.0, running_reward: -16.8103, time (sec): 4578.0100\n",
      "Ep. 1414 done, reward: -18.0, running_reward: -16.7944, time (sec): 4586.5621\n",
      "Ep. 1416 done, reward: -15.0, running_reward: -16.7884, time (sec): 4595.9823\n",
      "Ep. 1418 done, reward: -19.0, running_reward: -16.8027, time (sec): 4605.3877\n",
      "Ep. 1420 done, reward: -17.0, running_reward: -16.8363, time (sec): 4615.2381\n",
      "Ep. 1422 done, reward: -19.0, running_reward: -16.8893, time (sec): 4624.5145\n",
      "Ep. 1424 done, reward: -16.0, running_reward: -16.8419, time (sec): 4634.9201\n",
      "Ep. 1426 done, reward: -15.0, running_reward: -16.7854, time (sec): 4647.9188\n",
      "Ep. 1428 done, reward: -14.0, running_reward: -16.7696, time (sec): 4658.1629\n",
      "Ep. 1430 done, reward: -11.0, running_reward: -16.7043, time (sec): 4668.5935\n",
      "Ep. 1432 done, reward: -19.0, running_reward: -16.7104, time (sec): 4678.5279\n",
      "Ep. 1434 done, reward: -20.0, running_reward: -16.7362, time (sec): 4689.0686\n",
      "Ep. 1436 done, reward: -13.0, running_reward: -16.6322, time (sec): 4701.1406\n",
      "Ep. 1438 done, reward: -19.0, running_reward: -16.6001, time (sec): 4711.0086\n",
      "Ep. 1440 done, reward: -20.0, running_reward: -16.6380, time (sec): 4719.9780\n",
      "Ep. 1442 done, reward: -14.0, running_reward: -16.6152, time (sec): 4731.2886\n",
      "Ep. 1444 done, reward: -5.0, running_reward: -16.4930, time (sec): 4744.9805\n",
      "Ep. 1446 done, reward: -18.0, running_reward: -16.4636, time (sec): 4758.1970\n",
      "Ep. 1448 done, reward: -16.0, running_reward: -16.4940, time (sec): 4767.2529\n",
      "Ep. 1450 done, reward: -17.0, running_reward: -16.5040, time (sec): 4776.6132\n",
      "Ep. 1452 done, reward: -18.0, running_reward: -16.5140, time (sec): 4786.3285\n",
      "Ep. 1454 done, reward: -17.0, running_reward: -16.5237, time (sec): 4795.2067\n",
      "Ep. 1456 done, reward: -13.0, running_reward: -16.4932, time (sec): 4806.6158\n",
      "Ep. 1458 done, reward: -17.0, running_reward: -16.5032, time (sec): 4816.9673\n",
      "Ep. 1460 done, reward: -16.0, running_reward: -16.5229, time (sec): 4828.3919\n",
      "Ep. 1462 done, reward: -13.0, running_reward: -16.4924, time (sec): 4838.1482\n",
      "Ep. 1464 done, reward: -21.0, running_reward: -16.5425, time (sec): 4847.9117\n",
      "Ep. 1466 done, reward: -9.0, running_reward: -16.4419, time (sec): 4860.8665\n",
      "Ep. 1468 done, reward: -15.0, running_reward: -16.3934, time (sec): 4871.6267\n",
      "Ep. 1470 done, reward: -14.0, running_reward: -16.3755, time (sec): 4881.7264\n",
      "Ep. 1472 done, reward: -18.0, running_reward: -16.3880, time (sec): 4892.5266\n",
      "Ep. 1474 done, reward: -19.0, running_reward: -16.3806, time (sec): 4902.6171\n",
      "Ep. 1476 done, reward: -20.0, running_reward: -16.3635, time (sec): 4913.5017\n",
      "Ep. 1478 done, reward: -19.0, running_reward: -16.3269, time (sec): 4924.7840\n",
      "Ep. 1480 done, reward: -15.0, running_reward: -16.2807, time (sec): 4934.9337\n",
      "Ep. 1482 done, reward: -17.0, running_reward: -16.2950, time (sec): 4944.8860\n",
      "Ep. 1484 done, reward: -7.0, running_reward: -16.2189, time (sec): 4956.2694\n",
      "Ep. 1486 done, reward: -16.0, running_reward: -16.2146, time (sec): 4966.7584\n",
      "Ep. 1488 done, reward: -14.0, running_reward: -16.1606, time (sec): 4978.1635\n",
      "Ep. 1490 done, reward: -13.0, running_reward: -16.1076, time (sec): 4989.3171\n",
      "Ep. 1492 done, reward: -13.0, running_reward: -16.0260, time (sec): 5000.2750\n",
      "Ep. 1494 done, reward: -10.0, running_reward: -15.9556, time (sec): 5011.9774\n",
      "Ep. 1496 done, reward: -13.0, running_reward: -15.9363, time (sec): 5021.4600\n",
      "Ep. 1498 done, reward: -16.0, running_reward: -15.9475, time (sec): 5032.6970\n",
      "Ep. 1500 done, reward: -15.0, running_reward: -15.8792, time (sec): 5044.9950\n",
      "Ep. 1502 done, reward: -9.0, running_reward: -15.8413, time (sec): 5056.2936\n",
      "Ep. 1504 done, reward: -16.0, running_reward: -15.8147, time (sec): 5065.9826\n",
      "Ep. 1506 done, reward: -19.0, running_reward: -15.7989, time (sec): 5077.6649\n",
      "Ep. 1508 done, reward: -16.0, running_reward: -15.8029, time (sec): 5088.2889\n",
      "Ep. 1510 done, reward: -18.0, running_reward: -15.8268, time (sec): 5097.6336\n",
      "Ep. 1512 done, reward: -16.0, running_reward: -15.8402, time (sec): 5106.9879\n",
      "Ep. 1514 done, reward: -15.0, running_reward: -15.8631, time (sec): 5116.8659\n",
      "Ep. 1516 done, reward: -19.0, running_reward: -15.9057, time (sec): 5126.0158\n",
      "Ep. 1518 done, reward: -17.0, running_reward: -15.9374, time (sec): 5135.9924\n",
      "Ep. 1520 done, reward: -19.0, running_reward: -15.9884, time (sec): 5145.6859\n",
      "Ep. 1522 done, reward: -17.0, running_reward: -15.9788, time (sec): 5155.2368\n",
      "Ep. 1524 done, reward: -17.0, running_reward: -15.9200, time (sec): 5165.7957\n",
      "Ep. 1526 done, reward: -14.0, running_reward: -15.8916, time (sec): 5177.7561\n",
      "Ep. 1528 done, reward: -16.0, running_reward: -15.9136, time (sec): 5189.1200\n",
      "Ep. 1530 done, reward: -11.0, running_reward: -15.8653, time (sec): 5200.9082\n",
      "Ep. 1532 done, reward: -13.0, running_reward: -15.8677, time (sec): 5213.1147\n",
      "Ep. 1534 done, reward: -11.0, running_reward: -15.8104, time (sec): 5225.6268\n",
      "Ep. 1536 done, reward: -15.0, running_reward: -15.8141, time (sec): 5235.4072\n",
      "Ep. 1538 done, reward: -17.0, running_reward: -15.8179, time (sec): 5246.4019\n",
      "Ep. 1540 done, reward: -19.0, running_reward: -15.8515, time (sec): 5255.2888\n",
      "Ep. 1542 done, reward: -19.0, running_reward: -15.8944, time (sec): 5265.3287\n",
      "Ep. 1544 done, reward: -14.0, running_reward: -15.8567, time (sec): 5275.7241\n",
      "Ep. 1546 done, reward: -14.0, running_reward: -15.8098, time (sec): 5286.4057\n",
      "Ep. 1548 done, reward: -20.0, running_reward: -15.8536, time (sec): 5295.4277\n",
      "Ep. 1550 done, reward: -18.0, running_reward: -15.8270, time (sec): 5306.7278\n",
      "Ep. 1552 done, reward: -16.0, running_reward: -15.8404, time (sec): 5318.1359\n",
      "Ep. 1554 done, reward: -18.0, running_reward: -15.8141, time (sec): 5329.0820\n",
      "Ep. 1556 done, reward: -15.0, running_reward: -15.8078, time (sec): 5341.4996\n",
      "Ep. 1558 done, reward: -14.0, running_reward: -15.7817, time (sec): 5353.4700\n",
      "Ep. 1560 done, reward: -13.0, running_reward: -15.7263, time (sec): 5365.7132\n",
      "Ep. 1562 done, reward: -14.0, running_reward: -15.6821, time (sec): 5378.2568\n",
      "Ep. 1564 done, reward: -17.0, running_reward: -15.6984, time (sec): 5389.5278\n",
      "Ep. 1566 done, reward: -17.0, running_reward: -15.6649, time (sec): 5399.6105\n",
      "Ep. 1568 done, reward: -19.0, running_reward: -15.6917, time (sec): 5409.3001\n",
      "Ep. 1570 done, reward: -11.0, running_reward: -15.6775, time (sec): 5420.4533\n",
      "Ep. 1572 done, reward: -15.0, running_reward: -15.6442, time (sec): 5431.6962\n",
      "Ep. 1574 done, reward: -13.0, running_reward: -15.5322, time (sec): 5444.7066\n",
      "Ep. 1576 done, reward: -14.0, running_reward: -15.5413, time (sec): 5455.0044\n",
      "Ep. 1578 done, reward: -18.0, running_reward: -15.5506, time (sec): 5465.6683\n",
      "Ep. 1580 done, reward: -19.0, running_reward: -15.5005, time (sec): 5477.0768\n",
      "Ep. 1582 done, reward: -13.0, running_reward: -15.4903, time (sec): 5487.4615\n",
      "Ep. 1584 done, reward: -14.0, running_reward: -15.4508, time (sec): 5499.3813\n",
      "Ep. 1586 done, reward: -20.0, running_reward: -15.5314, time (sec): 5508.7864\n",
      "Ep. 1588 done, reward: -17.0, running_reward: -15.5408, time (sec): 5519.0042\n",
      "Ep. 1590 done, reward: -17.0, running_reward: -15.5897, time (sec): 5528.7659\n",
      "Ep. 1592 done, reward: -14.0, running_reward: -15.5679, time (sec): 5539.5785\n",
      "Ep. 1594 done, reward: -21.0, running_reward: -15.5968, time (sec): 5548.7360\n",
      "Ep. 1596 done, reward: -14.0, running_reward: -15.5155, time (sec): 5560.6037\n",
      "Ep. 1598 done, reward: -14.0, running_reward: -15.4953, time (sec): 5571.2006\n",
      "Ep. 1600 done, reward: -14.0, running_reward: -15.4457, time (sec): 5584.1006\n",
      "Ep. 1602 done, reward: -7.0, running_reward: -15.3569, time (sec): 5597.3572\n",
      "Ep. 1604 done, reward: -7.0, running_reward: -15.2995, time (sec): 5607.5953\n",
      "Ep. 1606 done, reward: -17.0, running_reward: -15.2937, time (sec): 5617.7944\n",
      "Ep. 1608 done, reward: -15.0, running_reward: -15.2780, time (sec): 5630.0923\n",
      "Ep. 1610 done, reward: -17.0, running_reward: -15.2924, time (sec): 5640.6670\n",
      "Ep. 1612 done, reward: -20.0, running_reward: -15.3366, time (sec): 5651.3664\n",
      "Ep. 1614 done, reward: -18.0, running_reward: -15.2708, time (sec): 5663.3791\n",
      "Ep. 1616 done, reward: -11.0, running_reward: -15.2056, time (sec): 5674.5335\n",
      "Ep. 1618 done, reward: -18.0, running_reward: -15.1820, time (sec): 5685.1072\n",
      "Ep. 1620 done, reward: -15.0, running_reward: -15.1388, time (sec): 5695.6976\n",
      "Ep. 1622 done, reward: -17.0, running_reward: -15.1659, time (sec): 5707.1316\n",
      "Ep. 1624 done, reward: -15.0, running_reward: -15.1626, time (sec): 5719.9229\n",
      "Ep. 1626 done, reward: -11.0, running_reward: -15.1590, time (sec): 5731.3845\n",
      "Ep. 1628 done, reward: -14.0, running_reward: -15.1161, time (sec): 5743.2199\n",
      "Ep. 1630 done, reward: -13.0, running_reward: -15.1235, time (sec): 5753.5418\n",
      "Ep. 1632 done, reward: -13.0, running_reward: -15.0912, time (sec): 5764.9880\n",
      "Ep. 1634 done, reward: -9.0, running_reward: -15.0096, time (sec): 5776.2970\n",
      "Ep. 1636 done, reward: -7.0, running_reward: -14.9393, time (sec): 5788.6647\n",
      "Ep. 1638 done, reward: -14.0, running_reward: -14.9305, time (sec): 5799.4650\n",
      "Ep. 1640 done, reward: -16.0, running_reward: -14.9518, time (sec): 5811.9242\n",
      "Ep. 1642 done, reward: -12.0, running_reward: -14.9029, time (sec): 5824.6842\n",
      "Ep. 1644 done, reward: -15.0, running_reward: -14.8652, time (sec): 5837.1605\n",
      "Ep. 1646 done, reward: -19.0, running_reward: -14.9079, time (sec): 5847.3203\n",
      "Ep. 1648 done, reward: -16.0, running_reward: -14.9495, time (sec): 5858.9531\n",
      "Ep. 1650 done, reward: -18.0, running_reward: -14.9310, time (sec): 5870.7555\n",
      "Ep. 1652 done, reward: -9.0, running_reward: -14.8921, time (sec): 5881.6901\n",
      "Ep. 1654 done, reward: -17.0, running_reward: -14.9638, time (sec): 5891.1843\n",
      "Ep. 1656 done, reward: -17.0, running_reward: -14.9548, time (sec): 5903.5969\n",
      "Ep. 1658 done, reward: -19.0, running_reward: -15.0056, time (sec): 5912.9026\n",
      "Ep. 1660 done, reward: -19.0, running_reward: -15.0653, time (sec): 5924.6072\n",
      "Ep. 1662 done, reward: -13.0, running_reward: -15.0638, time (sec): 5935.8705\n",
      "Ep. 1664 done, reward: -15.0, running_reward: -15.0823, time (sec): 5946.4616\n",
      "Ep. 1666 done, reward: -15.0, running_reward: -15.0708, time (sec): 5958.9780\n",
      "Ep. 1668 done, reward: -15.0, running_reward: -15.0991, time (sec): 5969.2116\n",
      "Ep. 1670 done, reward: -9.0, running_reward: -15.0272, time (sec): 5983.4323\n",
      "Ep. 1672 done, reward: -19.0, running_reward: -15.0271, time (sec): 5995.4797\n",
      "Ep. 1674 done, reward: -19.0, running_reward: -15.0665, time (sec): 6006.4858\n",
      "Ep. 1676 done, reward: -17.0, running_reward: -15.0852, time (sec): 6018.3877\n",
      "Ep. 1678 done, reward: -15.0, running_reward: -15.0538, time (sec): 6030.4938\n",
      "Ep. 1680 done, reward: -19.0, running_reward: -15.0630, time (sec): 6042.9056\n",
      "Ep. 1682 done, reward: -16.0, running_reward: -15.0718, time (sec): 6053.1110\n",
      "Ep. 1684 done, reward: -17.0, running_reward: -15.0607, time (sec): 6063.7033\n",
      "Ep. 1686 done, reward: -17.0, running_reward: -15.1091, time (sec): 6074.4714\n",
      "Ep. 1688 done, reward: -16.0, running_reward: -15.1368, time (sec): 6086.0201\n",
      "Ep. 1690 done, reward: -14.0, running_reward: -15.1340, time (sec): 6096.4748\n",
      "Ep. 1692 done, reward: -17.0, running_reward: -15.1711, time (sec): 6106.5072\n",
      "Ep. 1694 done, reward: -17.0, running_reward: -15.1580, time (sec): 6118.5272\n",
      "Ep. 1696 done, reward: -13.0, running_reward: -15.1447, time (sec): 6130.6945\n",
      "Ep. 1698 done, reward: -18.0, running_reward: -15.1917, time (sec): 6141.2393\n",
      "Ep. 1700 done, reward: -12.0, running_reward: -15.1974, time (sec): 6153.3440\n",
      "Ep. 1702 done, reward: -17.0, running_reward: -15.2036, time (sec): 6164.9194\n",
      "Ep. 1704 done, reward: -16.0, running_reward: -15.2294, time (sec): 6176.0136\n",
      "Ep. 1706 done, reward: -17.0, running_reward: -15.2151, time (sec): 6187.6637\n",
      "Ep. 1708 done, reward: -17.0, running_reward: -15.2308, time (sec): 6200.7606\n",
      "Ep. 1710 done, reward: -11.0, running_reward: -15.1367, time (sec): 6214.3423\n",
      "Ep. 1712 done, reward: -15.0, running_reward: -15.1637, time (sec): 6227.2238\n",
      "Ep. 1714 done, reward: -17.0, running_reward: -15.1705, time (sec): 6237.9846\n",
      "Ep. 1716 done, reward: -13.0, running_reward: -15.1274, time (sec): 6249.0508\n",
      "Ep. 1718 done, reward: -13.0, running_reward: -15.1246, time (sec): 6261.3110\n",
      "Ep. 1720 done, reward: -14.0, running_reward: -15.0923, time (sec): 6272.6786\n",
      "Ep. 1722 done, reward: -14.0, running_reward: -15.0607, time (sec): 6282.9865\n",
      "Ep. 1724 done, reward: -14.0, running_reward: -15.0495, time (sec): 6296.0435\n",
      "Ep. 1726 done, reward: -15.0, running_reward: -15.0287, time (sec): 6308.2352\n",
      "Ep. 1728 done, reward: -15.0, running_reward: -15.0677, time (sec): 6318.4151\n",
      "Ep. 1730 done, reward: -16.0, running_reward: -15.0368, time (sec): 6329.9652\n",
      "Ep. 1732 done, reward: -15.0, running_reward: -15.0262, time (sec): 6343.7050\n",
      "Ep. 1734 done, reward: -16.0, running_reward: -15.0257, time (sec): 6355.8500\n",
      "Ep. 1736 done, reward: -14.0, running_reward: -15.0053, time (sec): 6367.7334\n",
      "Ep. 1738 done, reward: -15.0, running_reward: -15.0448, time (sec): 6378.8309\n",
      "Ep. 1740 done, reward: -14.0, running_reward: -14.9943, time (sec): 6393.1990\n",
      "Ep. 1742 done, reward: -13.0, running_reward: -14.9744, time (sec): 6403.9487\n",
      "Ep. 1744 done, reward: -14.0, running_reward: -14.8956, time (sec): 6417.9358\n",
      "Ep. 1746 done, reward: -15.0, running_reward: -14.8977, time (sec): 6430.3033\n",
      "Ep. 1748 done, reward: -17.0, running_reward: -14.9396, time (sec): 6440.8491\n",
      "Ep. 1750 done, reward: -12.0, running_reward: -14.8415, time (sec): 6455.3014\n",
      "Ep. 1752 done, reward: -13.0, running_reward: -14.8147, time (sec): 6467.7716\n",
      "Ep. 1754 done, reward: -10.0, running_reward: -14.7585, time (sec): 6480.8378\n",
      "Ep. 1756 done, reward: -18.0, running_reward: -14.7834, time (sec): 6492.6114\n",
      "Ep. 1758 done, reward: -17.0, running_reward: -14.8077, time (sec): 6503.9499\n",
      "Ep. 1760 done, reward: -16.0, running_reward: -14.8215, time (sec): 6516.3070\n",
      "Ep. 1762 done, reward: -17.0, running_reward: -14.7758, time (sec): 6529.3038\n",
      "Ep. 1764 done, reward: -13.0, running_reward: -14.6910, time (sec): 6542.1061\n",
      "Ep. 1766 done, reward: -16.0, running_reward: -14.6873, time (sec): 6555.5714\n",
      "Ep. 1768 done, reward: -19.0, running_reward: -14.7335, time (sec): 6566.7295\n",
      "Ep. 1770 done, reward: -17.0, running_reward: -14.7984, time (sec): 6577.8595\n",
      "Ep. 1772 done, reward: -18.0, running_reward: -14.8225, time (sec): 6589.7892\n",
      "Ep. 1774 done, reward: -19.0, running_reward: -14.8166, time (sec): 6602.2382\n",
      "Ep. 1776 done, reward: -15.0, running_reward: -14.8103, time (sec): 6614.4465\n",
      "Ep. 1778 done, reward: -14.0, running_reward: -14.7645, time (sec): 6627.0029\n",
      "Ep. 1780 done, reward: -15.0, running_reward: -14.7692, time (sec): 6638.6350\n",
      "Ep. 1782 done, reward: -13.0, running_reward: -14.6944, time (sec): 6653.1019\n",
      "Ep. 1784 done, reward: -13.0, running_reward: -14.6409, time (sec): 6665.0924\n",
      "Ep. 1786 done, reward: -16.0, running_reward: -14.6481, time (sec): 6677.1504\n",
      "Ep. 1788 done, reward: -15.0, running_reward: -14.6452, time (sec): 6688.6758\n",
      "Ep. 1790 done, reward: -18.0, running_reward: -14.6130, time (sec): 6701.4249\n",
      "Ep. 1792 done, reward: -14.0, running_reward: -14.6503, time (sec): 6712.7271\n",
      "Ep. 1794 done, reward: -14.0, running_reward: -14.6670, time (sec): 6724.0730\n",
      "Ep. 1796 done, reward: -9.0, running_reward: -14.6434, time (sec): 6738.4844\n",
      "Ep. 1798 done, reward: -15.0, running_reward: -14.6010, time (sec): 6750.3310\n",
      "Ep. 1800 done, reward: -14.0, running_reward: -14.5197, time (sec): 6764.0617\n",
      "Ep. 1802 done, reward: -9.0, running_reward: -14.4693, time (sec): 6778.2443\n",
      "Ep. 1804 done, reward: -9.0, running_reward: -14.4198, time (sec): 6793.0611\n",
      "Ep. 1806 done, reward: -13.0, running_reward: -14.4114, time (sec): 6805.2017\n",
      "Ep. 1808 done, reward: -12.0, running_reward: -14.3832, time (sec): 6817.9080\n",
      "Ep. 1810 done, reward: -17.0, running_reward: -14.3660, time (sec): 6830.9400\n",
      "Ep. 1812 done, reward: -14.0, running_reward: -14.3785, time (sec): 6843.7265\n",
      "Ep. 1814 done, reward: -19.0, running_reward: -14.4506, time (sec): 6854.7877\n",
      "Ep. 1816 done, reward: -16.0, running_reward: -14.4320, time (sec): 6867.7933\n",
      "Ep. 1818 done, reward: -11.0, running_reward: -14.4429, time (sec): 6881.4695\n",
      "Ep. 1820 done, reward: -17.0, running_reward: -14.4839, time (sec): 6892.5765\n",
      "Ep. 1822 done, reward: -12.0, running_reward: -14.4641, time (sec): 6905.4128\n",
      "Ep. 1824 done, reward: -14.0, running_reward: -14.4153, time (sec): 6916.7236\n",
      "Ep. 1826 done, reward: -9.0, running_reward: -14.3075, time (sec): 6930.2648\n",
      "Ep. 1828 done, reward: -11.0, running_reward: -14.2813, time (sec): 6942.5144\n",
      "Ep. 1830 done, reward: -13.0, running_reward: -14.2756, time (sec): 6956.3697\n",
      "Ep. 1832 done, reward: -17.0, running_reward: -14.3100, time (sec): 6967.7700\n",
      "Ep. 1834 done, reward: -14.0, running_reward: -14.3138, time (sec): 6979.8407\n",
      "Ep. 1836 done, reward: -17.0, running_reward: -14.3672, time (sec): 6990.2103\n",
      "Ep. 1838 done, reward: -11.0, running_reward: -14.3497, time (sec): 7003.0932\n",
      "Ep. 1840 done, reward: -4.0, running_reward: -14.2625, time (sec): 7015.9208\n",
      "Ep. 1842 done, reward: -14.0, running_reward: -14.2573, time (sec): 7027.8598\n",
      "Ep. 1844 done, reward: -16.0, running_reward: -14.2524, time (sec): 7040.7054\n",
      "Ep. 1846 done, reward: -17.0, running_reward: -14.2873, time (sec): 7054.4849\n",
      "Ep. 1848 done, reward: -13.0, running_reward: -14.3211, time (sec): 7065.4250\n",
      "Ep. 1850 done, reward: -17.0, running_reward: -14.3348, time (sec): 7077.5755\n",
      "Ep. 1852 done, reward: -13.0, running_reward: -14.3478, time (sec): 7088.7944\n",
      "Ep. 1854 done, reward: -15.0, running_reward: -14.3410, time (sec): 7103.0463\n",
      "Ep. 1856 done, reward: -18.0, running_reward: -14.4435, time (sec): 7112.8086\n",
      "Ep. 1858 done, reward: -18.0, running_reward: -14.4450, time (sec): 7123.7761\n",
      "Ep. 1860 done, reward: -16.0, running_reward: -14.5056, time (sec): 7134.9783\n",
      "Ep. 1862 done, reward: -15.0, running_reward: -14.4957, time (sec): 7146.7433\n",
      "Ep. 1864 done, reward: -17.0, running_reward: -14.5356, time (sec): 7158.8210\n",
      "Ep. 1866 done, reward: -14.0, running_reward: -14.5744, time (sec): 7171.6344\n",
      "Ep. 1868 done, reward: -18.0, running_reward: -14.5931, time (sec): 7182.0849\n",
      "Ep. 1870 done, reward: -16.0, running_reward: -14.6112, time (sec): 7193.6943\n",
      "Ep. 1872 done, reward: -16.0, running_reward: -14.6388, time (sec): 7205.5775\n",
      "Ep. 1874 done, reward: -19.0, running_reward: -14.7058, time (sec): 7215.7545\n",
      "Ep. 1876 done, reward: -15.0, running_reward: -14.6622, time (sec): 7228.2889\n",
      "Ep. 1878 done, reward: -20.0, running_reward: -14.7090, time (sec): 7238.1652\n",
      "Ep. 1880 done, reward: -11.0, running_reward: -14.6748, time (sec): 7248.9450\n",
      "Ep. 1882 done, reward: -15.0, running_reward: -14.6714, time (sec): 7263.0620\n",
      "Ep. 1884 done, reward: -17.0, running_reward: -14.7474, time (sec): 7273.7897\n",
      "Ep. 1886 done, reward: -13.0, running_reward: -14.7126, time (sec): 7286.6857\n",
      "Ep. 1888 done, reward: -11.0, running_reward: -14.6586, time (sec): 7300.8375\n",
      "Ep. 1890 done, reward: -14.0, running_reward: -14.6652, time (sec): 7314.3283\n",
      "Ep. 1892 done, reward: -5.0, running_reward: -14.5917, time (sec): 7329.9672\n",
      "Ep. 1894 done, reward: -12.0, running_reward: -14.5599, time (sec): 7343.0413\n",
      "Ep. 1896 done, reward: -17.0, running_reward: -14.6085, time (sec): 7354.1273\n",
      "Ep. 1898 done, reward: -12.0, running_reward: -14.5665, time (sec): 7367.7301\n",
      "Ep. 1900 done, reward: -17.0, running_reward: -14.6149, time (sec): 7378.1106\n",
      "Ep. 1902 done, reward: -15.0, running_reward: -14.5731, time (sec): 7389.3363\n",
      "Ep. 1904 done, reward: -17.0, running_reward: -14.6115, time (sec): 7399.6134\n",
      "Ep. 1906 done, reward: -11.0, running_reward: -14.5990, time (sec): 7411.9471\n",
      "Ep. 1908 done, reward: -15.0, running_reward: -14.6268, time (sec): 7422.8652\n",
      "Ep. 1910 done, reward: -17.0, running_reward: -14.6344, time (sec): 7435.3967\n",
      "Ep. 1912 done, reward: -16.0, running_reward: -14.6220, time (sec): 7447.5262\n",
      "Ep. 1914 done, reward: -15.0, running_reward: -14.6493, time (sec): 7459.1383\n",
      "Ep. 1916 done, reward: -15.0, running_reward: -14.6563, time (sec): 7471.3164\n",
      "Ep. 1918 done, reward: -21.0, running_reward: -14.7033, time (sec): 7481.2959\n",
      "Ep. 1920 done, reward: -10.0, running_reward: -14.7186, time (sec): 7493.7989\n",
      "Ep. 1922 done, reward: -15.0, running_reward: -14.6945, time (sec): 7506.1133\n",
      "Ep. 1924 done, reward: -19.0, running_reward: -14.7505, time (sec): 7515.1700\n",
      "Ep. 1926 done, reward: -15.0, running_reward: -14.7753, time (sec): 7527.5847\n",
      "Ep. 1928 done, reward: -14.0, running_reward: -14.7598, time (sec): 7539.8010\n",
      "Ep. 1930 done, reward: -9.0, running_reward: -14.6848, time (sec): 7552.8159\n",
      "Ep. 1932 done, reward: -9.0, running_reward: -14.6806, time (sec): 7565.4550\n",
      "Ep. 1934 done, reward: -16.0, running_reward: -14.7465, time (sec): 7575.7200\n",
      "Ep. 1936 done, reward: -19.0, running_reward: -14.8014, time (sec): 7589.2682\n",
      "Ep. 1938 done, reward: -15.0, running_reward: -14.8152, time (sec): 7600.4818\n",
      "Ep. 1940 done, reward: -15.0, running_reward: -14.7595, time (sec): 7612.6750\n",
      "Ep. 1942 done, reward: -17.0, running_reward: -14.8041, time (sec): 7624.4666\n",
      "Ep. 1944 done, reward: -7.0, running_reward: -14.7082, time (sec): 7637.6842\n",
      "Ep. 1946 done, reward: -17.0, running_reward: -14.7142, time (sec): 7650.4731\n",
      "Ep. 1948 done, reward: -17.0, running_reward: -14.7300, time (sec): 7661.8067\n",
      "Ep. 1950 done, reward: -13.0, running_reward: -14.6560, time (sec): 7673.5892\n",
      "Ep. 1952 done, reward: -16.0, running_reward: -14.6134, time (sec): 7687.3445\n",
      "Ep. 1954 done, reward: -10.0, running_reward: -14.5909, time (sec): 7697.6923\n",
      "Ep. 1956 done, reward: -11.0, running_reward: -14.5987, time (sec): 7708.4424\n",
      "Ep. 1958 done, reward: -14.0, running_reward: -14.5867, time (sec): 7721.8982\n",
      "Ep. 1960 done, reward: -17.0, running_reward: -14.6150, time (sec): 7734.1361\n",
      "Ep. 1962 done, reward: -14.0, running_reward: -14.5433, time (sec): 7748.7162\n",
      "Ep. 1964 done, reward: -19.0, running_reward: -14.4835, time (sec): 7761.2904\n",
      "Ep. 1966 done, reward: -17.0, running_reward: -14.5435, time (sec): 7771.8824\n",
      "Ep. 1968 done, reward: -15.0, running_reward: -14.5625, time (sec): 7783.5595\n",
      "Ep. 1970 done, reward: -13.0, running_reward: -14.5611, time (sec): 7794.5776\n",
      "Ep. 1972 done, reward: -19.0, running_reward: -14.5999, time (sec): 7805.7744\n",
      "Ep. 1974 done, reward: -13.0, running_reward: -14.5384, time (sec): 7818.8452\n",
      "Ep. 1976 done, reward: -16.0, running_reward: -14.5576, time (sec): 7830.0346\n",
      "Ep. 1978 done, reward: -15.0, running_reward: -14.5664, time (sec): 7842.9645\n",
      "Ep. 1980 done, reward: -9.0, running_reward: -14.5150, time (sec): 7856.0352\n",
      "Ep. 1982 done, reward: -8.0, running_reward: -14.4646, time (sec): 7868.4047\n",
      "Ep. 1984 done, reward: -15.0, running_reward: -14.4653, time (sec): 7879.5159\n",
      "Ep. 1986 done, reward: -13.0, running_reward: -14.4361, time (sec): 7892.9924\n",
      "Ep. 1988 done, reward: -12.0, running_reward: -14.4273, time (sec): 7907.0336\n",
      "Ep. 1990 done, reward: -19.0, running_reward: -14.4391, time (sec): 7919.2761\n",
      "Ep. 1992 done, reward: -13.0, running_reward: -14.4302, time (sec): 7930.7041\n",
      "Ep. 1994 done, reward: -17.0, running_reward: -14.4022, time (sec): 7944.0934\n",
      "Ep. 1996 done, reward: -21.0, running_reward: -14.4345, time (sec): 7955.6701\n",
      "Ep. 1998 done, reward: -16.0, running_reward: -14.4656, time (sec): 7967.2044\n",
      "Ep. 2000 done, reward: -3.0, running_reward: -14.3563, time (sec): 7983.7620\n",
      "Ep. 2002 done, reward: -14.0, running_reward: -14.3987, time (sec): 7992.9409\n",
      "Ep. 2004 done, reward: -19.0, running_reward: -14.4803, time (sec): 8002.4362\n",
      "Ep. 2006 done, reward: -13.0, running_reward: -14.4905, time (sec): 8014.6736\n",
      "Ep. 2008 done, reward: -15.0, running_reward: -14.5303, time (sec): 8026.0133\n",
      "Ep. 2010 done, reward: -12.0, running_reward: -14.5295, time (sec): 8037.3852\n",
      "Ep. 2012 done, reward: -19.0, running_reward: -14.5887, time (sec): 8048.8627\n",
      "Ep. 2014 done, reward: -17.0, running_reward: -14.6268, time (sec): 8061.0473\n",
      "Ep. 2016 done, reward: -14.0, running_reward: -14.6044, time (sec): 8073.1952\n",
      "Ep. 2018 done, reward: -13.0, running_reward: -14.5923, time (sec): 8087.4027\n",
      "Ep. 2020 done, reward: -14.0, running_reward: -14.6201, time (sec): 8099.0312\n",
      "Ep. 2022 done, reward: -11.0, running_reward: -14.5877, time (sec): 8112.3727\n",
      "Ep. 2024 done, reward: -14.0, running_reward: -14.5859, time (sec): 8124.0943\n",
      "Ep. 2026 done, reward: -15.0, running_reward: -14.5644, time (sec): 8135.7840\n",
      "Ep. 2028 done, reward: -16.0, running_reward: -14.6128, time (sec): 8146.5318\n",
      "Ep. 2030 done, reward: -13.0, running_reward: -14.5807, time (sec): 8159.7335\n",
      "Ep. 2032 done, reward: -13.0, running_reward: -14.4403, time (sec): 8174.8230\n",
      "Ep. 2034 done, reward: -15.0, running_reward: -14.4416, time (sec): 8188.0255\n",
      "Ep. 2036 done, reward: -14.0, running_reward: -14.4229, time (sec): 8201.0193\n",
      "Ep. 2038 done, reward: -16.0, running_reward: -14.4246, time (sec): 8214.8013\n",
      "Ep. 2040 done, reward: -15.0, running_reward: -14.3865, time (sec): 8228.2596\n",
      "Ep. 2042 done, reward: -12.0, running_reward: -14.3687, time (sec): 8241.5453\n",
      "Ep. 2044 done, reward: -11.0, running_reward: -14.2522, time (sec): 8257.3169\n",
      "Ep. 2046 done, reward: -13.0, running_reward: -14.2273, time (sec): 8268.5825\n",
      "Ep. 2048 done, reward: -15.0, running_reward: -14.2229, time (sec): 8280.9517\n",
      "Ep. 2050 done, reward: -11.0, running_reward: -14.1983, time (sec): 8294.8233\n",
      "Ep. 2052 done, reward: -18.0, running_reward: -14.2542, time (sec): 8306.5088\n",
      "Ep. 2054 done, reward: -21.0, running_reward: -14.2696, time (sec): 8319.8295\n",
      "Ep. 2056 done, reward: -15.0, running_reward: -14.3040, time (sec): 8331.2797\n",
      "Ep. 2058 done, reward: -14.0, running_reward: -14.2187, time (sec): 8345.2148\n",
      "Ep. 2060 done, reward: -17.0, running_reward: -14.2740, time (sec): 8356.6178\n",
      "Ep. 2062 done, reward: -12.0, running_reward: -14.2684, time (sec): 8371.5643\n",
      "Ep. 2064 done, reward: -11.0, running_reward: -14.2727, time (sec): 8383.4232\n",
      "Ep. 2066 done, reward: -15.0, running_reward: -14.2574, time (sec): 8397.3428\n",
      "Ep. 2068 done, reward: -17.0, running_reward: -14.3318, time (sec): 8411.5692\n",
      "Ep. 2070 done, reward: -12.0, running_reward: -14.3151, time (sec): 8423.4172\n",
      "Ep. 2072 done, reward: -16.0, running_reward: -14.2397, time (sec): 8438.6604\n",
      "Ep. 2074 done, reward: -13.0, running_reward: -14.2250, time (sec): 8451.3511\n",
      "Ep. 2076 done, reward: -13.0, running_reward: -14.1214, time (sec): 8466.8484\n",
      "Ep. 2078 done, reward: -18.0, running_reward: -14.1788, time (sec): 8479.7866\n",
      "Ep. 2080 done, reward: -14.0, running_reward: -14.1950, time (sec): 8492.0177\n",
      "Ep. 2082 done, reward: -19.0, running_reward: -14.2807, time (sec): 8502.3676\n",
      "Ep. 2084 done, reward: -10.0, running_reward: -14.2252, time (sec): 8514.9597\n",
      "Ep. 2086 done, reward: -19.0, running_reward: -14.2411, time (sec): 8528.3153\n",
      "Ep. 2088 done, reward: -9.0, running_reward: -14.1863, time (sec): 8541.1927\n",
      "Ep. 2090 done, reward: -13.0, running_reward: -14.2023, time (sec): 8552.6828\n",
      "Ep. 2092 done, reward: -14.0, running_reward: -14.2081, time (sec): 8564.3444\n",
      "Ep. 2094 done, reward: -17.0, running_reward: -14.2439, time (sec): 8575.5403\n",
      "Ep. 2096 done, reward: -10.0, running_reward: -14.1990, time (sec): 8590.1861\n",
      "Ep. 2098 done, reward: -15.0, running_reward: -14.2348, time (sec): 8603.2364\n",
      "Ep. 2100 done, reward: -11.0, running_reward: -14.2100, time (sec): 8614.9877\n",
      "Ep. 2102 done, reward: -15.0, running_reward: -14.2356, time (sec): 8628.1690\n",
      "Ep. 2104 done, reward: -17.0, running_reward: -14.2906, time (sec): 8639.0919\n",
      "Ep. 2106 done, reward: -14.0, running_reward: -14.3146, time (sec): 8650.6421\n",
      "Ep. 2108 done, reward: -13.0, running_reward: -14.3478, time (sec): 8660.8856\n",
      "Ep. 2110 done, reward: -10.0, running_reward: -14.3207, time (sec): 8673.6293\n",
      "Ep. 2112 done, reward: -12.0, running_reward: -14.3240, time (sec): 8687.0561\n",
      "Ep. 2114 done, reward: -13.0, running_reward: -14.3372, time (sec): 8699.4023\n",
      "Ep. 2116 done, reward: -18.0, running_reward: -14.3804, time (sec): 8709.6188\n",
      "Ep. 2118 done, reward: -15.0, running_reward: -14.3532, time (sec): 8721.6522\n",
      "Ep. 2120 done, reward: -13.0, running_reward: -14.3460, time (sec): 8734.1824\n",
      "Ep. 2122 done, reward: -15.0, running_reward: -14.3194, time (sec): 8748.6391\n",
      "Ep. 2124 done, reward: -16.0, running_reward: -14.3034, time (sec): 8761.0762\n",
      "Ep. 2126 done, reward: -11.0, running_reward: -14.2971, time (sec): 8772.9976\n",
      "Ep. 2128 done, reward: -10.0, running_reward: -14.2016, time (sec): 8787.8593\n",
      "Ep. 2130 done, reward: -12.0, running_reward: -14.1083, time (sec): 8801.4208\n",
      "Ep. 2132 done, reward: -15.0, running_reward: -14.1459, time (sec): 8813.5276\n",
      "Ep. 2134 done, reward: -13.0, running_reward: -14.0835, time (sec): 8826.2520\n",
      "Ep. 2136 done, reward: -16.0, running_reward: -14.1018, time (sec): 8838.1884\n",
      "Ep. 2138 done, reward: -14.0, running_reward: -14.1592, time (sec): 8851.0325\n",
      "Ep. 2140 done, reward: -16.0, running_reward: -14.2057, time (sec): 8861.7617\n",
      "Ep. 2142 done, reward: -9.0, running_reward: -14.1813, time (sec): 8875.9638\n",
      "Ep. 2144 done, reward: -11.0, running_reward: -14.1576, time (sec): 8887.9695\n",
      "Ep. 2146 done, reward: -15.0, running_reward: -14.1843, time (sec): 8900.1581\n",
      "Ep. 2148 done, reward: -13.0, running_reward: -14.1706, time (sec): 8913.3249\n",
      "Ep. 2150 done, reward: -17.0, running_reward: -14.1873, time (sec): 8926.9937\n",
      "Ep. 2152 done, reward: -15.0, running_reward: -14.1936, time (sec): 8937.9614\n",
      "Ep. 2154 done, reward: -13.0, running_reward: -14.1698, time (sec): 8951.4238\n",
      "Ep. 2156 done, reward: -14.0, running_reward: -14.1566, time (sec): 8966.5037\n",
      "Ep. 2158 done, reward: -11.0, running_reward: -14.1234, time (sec): 8981.8758\n",
      "Ep. 2160 done, reward: -17.0, running_reward: -14.1411, time (sec): 8993.1511\n",
      "Ep. 2162 done, reward: -9.0, running_reward: -14.0982, time (sec): 9006.0116\n",
      "Ep. 2164 done, reward: -15.0, running_reward: -14.0963, time (sec): 9017.6520\n",
      "Ep. 2166 done, reward: -13.0, running_reward: -14.0349, time (sec): 9031.9874\n",
      "Ep. 2168 done, reward: -13.0, running_reward: -13.9648, time (sec): 9046.0298\n",
      "Ep. 2170 done, reward: -9.0, running_reward: -13.9452, time (sec): 9058.8768\n",
      "Ep. 2172 done, reward: -14.0, running_reward: -13.9760, time (sec): 9069.4940\n",
      "Ep. 2174 done, reward: -19.0, running_reward: -13.9869, time (sec): 9080.9196\n",
      "Ep. 2176 done, reward: -16.0, running_reward: -14.0566, time (sec): 9092.5325\n",
      "Ep. 2178 done, reward: -12.0, running_reward: -14.0454, time (sec): 9105.4433\n",
      "Ep. 2180 done, reward: -13.0, running_reward: -14.0444, time (sec): 9116.5528\n",
      "Ep. 2182 done, reward: -9.0, running_reward: -13.9935, time (sec): 9130.8040\n",
      "Ep. 2184 done, reward: -15.0, running_reward: -14.0235, time (sec): 9143.3021\n",
      "Ep. 2186 done, reward: -19.0, running_reward: -14.0433, time (sec): 9156.4859\n",
      "Ep. 2188 done, reward: -10.0, running_reward: -13.9925, time (sec): 9174.3951\n",
      "Ep. 2190 done, reward: -13.0, running_reward: -13.9827, time (sec): 9188.2131\n",
      "Ep. 2192 done, reward: -10.0, running_reward: -13.9826, time (sec): 9202.1375\n",
      "Ep. 2194 done, reward: -11.0, running_reward: -13.9926, time (sec): 9215.7145\n",
      "Ep. 2196 done, reward: -17.0, running_reward: -13.9831, time (sec): 9229.5165\n",
      "Ep. 2198 done, reward: -16.0, running_reward: -13.9737, time (sec): 9244.7116\n",
      "Ep. 2200 done, reward: -13.0, running_reward: -13.9247, time (sec): 9258.8734\n",
      "Ep. 2202 done, reward: -15.0, running_reward: -13.9659, time (sec): 9271.2614\n",
      "Ep. 2204 done, reward: -13.0, running_reward: -13.9863, time (sec): 9283.7831\n",
      "Ep. 2206 done, reward: -16.0, running_reward: -14.0263, time (sec): 9297.7888\n",
      "Ep. 2208 done, reward: -14.0, running_reward: -14.0357, time (sec): 9309.9520\n",
      "Ep. 2210 done, reward: -13.0, running_reward: -13.9953, time (sec): 9325.9816\n",
      "Ep. 2212 done, reward: -11.0, running_reward: -13.9060, time (sec): 9341.1611\n",
      "Ep. 2214 done, reward: -9.0, running_reward: -13.8183, time (sec): 9355.7631\n",
      "Ep. 2216 done, reward: -15.0, running_reward: -13.8220, time (sec): 9369.6150\n",
      "Ep. 2218 done, reward: -19.0, running_reward: -13.8458, time (sec): 9382.6998\n",
      "Ep. 2220 done, reward: -12.0, running_reward: -13.8091, time (sec): 9396.5541\n",
      "Ep. 2222 done, reward: -19.0, running_reward: -13.8134, time (sec): 9412.1743\n",
      "Ep. 2224 done, reward: -17.0, running_reward: -13.8075, time (sec): 9425.8610\n",
      "Ep. 2226 done, reward: -13.0, running_reward: -13.8706, time (sec): 9437.3642\n",
      "Ep. 2228 done, reward: -15.0, running_reward: -13.9327, time (sec): 9449.6875\n",
      "Ep. 2230 done, reward: -14.0, running_reward: -13.9043, time (sec): 9463.0751\n",
      "Ep. 2232 done, reward: -15.0, running_reward: -13.8964, time (sec): 9475.1714\n",
      "Ep. 2234 done, reward: -15.0, running_reward: -13.8986, time (sec): 9488.6977\n",
      "Ep. 2236 done, reward: -11.0, running_reward: -13.8805, time (sec): 9502.5048\n",
      "Ep. 2238 done, reward: -15.0, running_reward: -13.9226, time (sec): 9514.1135\n",
      "Ep. 2240 done, reward: -17.0, running_reward: -13.9145, time (sec): 9528.7268\n",
      "Ep. 2242 done, reward: -16.0, running_reward: -13.9263, time (sec): 9542.5204\n",
      "Ep. 2244 done, reward: -11.0, running_reward: -13.9473, time (sec): 9556.1516\n",
      "Ep. 2246 done, reward: -18.0, running_reward: -14.0181, time (sec): 9567.2438\n",
      "Ep. 2248 done, reward: -10.0, running_reward: -13.9579, time (sec): 9582.1304\n",
      "Ep. 2250 done, reward: -13.0, running_reward: -13.9289, time (sec): 9597.1991\n",
      "Ep. 2252 done, reward: -13.0, running_reward: -13.9500, time (sec): 9609.0303\n",
      "Ep. 2254 done, reward: -15.0, running_reward: -13.9907, time (sec): 9621.1435\n",
      "Ep. 2256 done, reward: -13.0, running_reward: -14.0007, time (sec): 9635.3782\n",
      "Ep. 2258 done, reward: -15.0, running_reward: -14.0602, time (sec): 9646.3658\n",
      "Ep. 2260 done, reward: -5.0, running_reward: -13.9591, time (sec): 9660.7928\n",
      "Ep. 2262 done, reward: -16.0, running_reward: -13.9700, time (sec): 9672.2921\n",
      "Ep. 2264 done, reward: -13.0, running_reward: -13.9507, time (sec): 9687.0468\n",
      "Ep. 2266 done, reward: -11.0, running_reward: -13.9316, time (sec): 9699.8073\n",
      "Ep. 2268 done, reward: -13.0, running_reward: -13.9725, time (sec): 9712.4949\n",
      "Ep. 2270 done, reward: -7.0, running_reward: -13.9129, time (sec): 9728.8775\n",
      "Ep. 2272 done, reward: -13.0, running_reward: -13.8749, time (sec): 9743.8729\n",
      "Ep. 2274 done, reward: -17.0, running_reward: -13.9272, time (sec): 9756.4242\n",
      "Ep. 2276 done, reward: -15.0, running_reward: -13.9486, time (sec): 9770.1282\n",
      "Ep. 2278 done, reward: -10.0, running_reward: -13.8502, time (sec): 9786.1959\n",
      "Ep. 2280 done, reward: -10.0, running_reward: -13.8231, time (sec): 9798.7033\n",
      "Ep. 2282 done, reward: -12.0, running_reward: -13.7967, time (sec): 9811.4023\n",
      "Ep. 2284 done, reward: -15.0, running_reward: -13.7217, time (sec): 9825.0184\n",
      "Ep. 2286 done, reward: -16.0, running_reward: -13.7967, time (sec): 9837.5509\n",
      "Ep. 2288 done, reward: -18.0, running_reward: -13.8011, time (sec): 9852.6178\n",
      "Ep. 2290 done, reward: -12.0, running_reward: -13.7950, time (sec): 9866.7940\n",
      "Ep. 2292 done, reward: -14.0, running_reward: -13.7001, time (sec): 9883.8320\n",
      "Ep. 2294 done, reward: -10.0, running_reward: -13.6561, time (sec): 9898.8021\n",
      "Ep. 2296 done, reward: -5.0, running_reward: -13.5433, time (sec): 9917.1029\n",
      "Ep. 2298 done, reward: -19.0, running_reward: -13.5925, time (sec): 9933.2785\n",
      "Ep. 2300 done, reward: -19.0, running_reward: -13.6506, time (sec): 9944.8676\n",
      "Ep. 2302 done, reward: -12.0, running_reward: -13.6573, time (sec): 9956.7699\n",
      "Ep. 2304 done, reward: -3.0, running_reward: -13.5443, time (sec): 9977.0795\n",
      "Ep. 2306 done, reward: -17.0, running_reward: -13.5338, time (sec): 9990.0162\n",
      "Ep. 2308 done, reward: -12.0, running_reward: -13.4736, time (sec): 10004.2380\n",
      "Ep. 2310 done, reward: -8.0, running_reward: -13.4538, time (sec): 10019.9440\n",
      "Ep. 2312 done, reward: -11.0, running_reward: -13.4148, time (sec): 10035.8826\n",
      "Ep. 2314 done, reward: -13.0, running_reward: -13.3868, time (sec): 10052.8966\n",
      "Ep. 2316 done, reward: -5.0, running_reward: -13.3288, time (sec): 10066.5265\n",
      "Ep. 2318 done, reward: -5.0, running_reward: -13.2522, time (sec): 10082.5627\n",
      "Ep. 2320 done, reward: -17.0, running_reward: -13.3267, time (sec): 10095.5395\n",
      "Ep. 2322 done, reward: -14.0, running_reward: -13.2906, time (sec): 10109.5684\n",
      "Ep. 2324 done, reward: -17.0, running_reward: -13.3248, time (sec): 10123.4828\n",
      "Ep. 2326 done, reward: -15.0, running_reward: -13.3483, time (sec): 10137.6092\n",
      "Ep. 2328 done, reward: -16.0, running_reward: -13.4308, time (sec): 10149.8142\n",
      "Ep. 2330 done, reward: -11.0, running_reward: -13.3428, time (sec): 10164.7912\n",
      "Ep. 2332 done, reward: -14.0, running_reward: -13.2470, time (sec): 10181.6683\n",
      "Ep. 2334 done, reward: -18.0, running_reward: -13.2722, time (sec): 10194.0897\n",
      "Ep. 2336 done, reward: -12.0, running_reward: -13.2667, time (sec): 10207.9154\n",
      "Ep. 2338 done, reward: -8.0, running_reward: -13.2114, time (sec): 10221.9413\n",
      "Ep. 2340 done, reward: -13.0, running_reward: -13.1280, time (sec): 10238.7765\n",
      "Ep. 2342 done, reward: -13.0, running_reward: -13.1453, time (sec): 10253.3839\n",
      "Ep. 2344 done, reward: -9.0, running_reward: -13.1321, time (sec): 10266.2615\n",
      "Ep. 2346 done, reward: -10.0, running_reward: -13.0598, time (sec): 10281.9407\n",
      "Ep. 2348 done, reward: -15.0, running_reward: -13.0985, time (sec): 10295.5107\n",
      "Ep. 2350 done, reward: -20.0, running_reward: -13.2160, time (sec): 10309.3027\n",
      "Ep. 2352 done, reward: -8.0, running_reward: -13.1221, time (sec): 10327.1747\n",
      "Ep. 2354 done, reward: -11.0, running_reward: -13.1393, time (sec): 10339.1152\n",
      "Ep. 2356 done, reward: -7.0, running_reward: -13.0567, time (sec): 10355.2693\n",
      "Ep. 2358 done, reward: -14.0, running_reward: -13.0656, time (sec): 10367.3226\n",
      "Ep. 2360 done, reward: -17.0, running_reward: -13.1142, time (sec): 10381.3611\n",
      "Ep. 2362 done, reward: -12.0, running_reward: -13.1316, time (sec): 10394.1449\n",
      "Ep. 2364 done, reward: 3.0, running_reward: -12.9294, time (sec): 10412.3219\n",
      "Ep. 2366 done, reward: -12.0, running_reward: -12.9604, time (sec): 10425.8086\n",
      "Ep. 2368 done, reward: -19.0, running_reward: -12.9915, time (sec): 10438.4740\n",
      "Ep. 2370 done, reward: -11.0, running_reward: -13.0310, time (sec): 10451.8523\n",
      "Ep. 2372 done, reward: -14.0, running_reward: -13.0701, time (sec): 10466.8324\n",
      "Ep. 2374 done, reward: -9.0, running_reward: -12.9495, time (sec): 10483.5893\n",
      "Ep. 2376 done, reward: -11.0, running_reward: -12.9305, time (sec): 10499.6656\n",
      "Ep. 2378 done, reward: -10.0, running_reward: -12.8128, time (sec): 10516.3388\n",
      "Ep. 2380 done, reward: -15.0, running_reward: -12.8167, time (sec): 10530.2509\n",
      "Ep. 2382 done, reward: -11.0, running_reward: -12.8004, time (sec): 10545.0414\n",
      "Ep. 2384 done, reward: -9.0, running_reward: -12.7644, time (sec): 10559.3295\n",
      "Ep. 2386 done, reward: -10.0, running_reward: -12.6994, time (sec): 10576.1698\n",
      "Ep. 2388 done, reward: -15.0, running_reward: -12.7452, time (sec): 10589.9429\n",
      "Ep. 2390 done, reward: -15.0, running_reward: -12.7109, time (sec): 10607.5575\n",
      "Ep. 2392 done, reward: -11.0, running_reward: -12.7263, time (sec): 10621.2821\n",
      "Ep. 2394 done, reward: -16.0, running_reward: -12.7222, time (sec): 10634.9922\n",
      "Ep. 2396 done, reward: -14.0, running_reward: -12.7476, time (sec): 10646.9325\n",
      "Ep. 2398 done, reward: -14.0, running_reward: -12.7824, time (sec): 10659.8839\n",
      "Ep. 2400 done, reward: -16.0, running_reward: -12.8267, time (sec): 10673.6662\n",
      "Ep. 2402 done, reward: -15.0, running_reward: -12.8699, time (sec): 10687.1776\n",
      "Ep. 2404 done, reward: -11.0, running_reward: -12.8327, time (sec): 10702.0391\n",
      "Ep. 2406 done, reward: -12.0, running_reward: -12.8260, time (sec): 10718.6299\n",
      "Ep. 2408 done, reward: -11.0, running_reward: -12.8095, time (sec): 10734.6466\n",
      "Ep. 2410 done, reward: -6.0, running_reward: -12.7334, time (sec): 10748.8617\n",
      "Ep. 2412 done, reward: -19.0, running_reward: -12.7492, time (sec): 10762.3709\n",
      "Ep. 2414 done, reward: -16.0, running_reward: -12.7941, time (sec): 10776.7341\n",
      "Ep. 2416 done, reward: -6.0, running_reward: -12.7282, time (sec): 10790.7897\n",
      "Ep. 2418 done, reward: -14.0, running_reward: -12.7634, time (sec): 10805.2890\n",
      "Ep. 2420 done, reward: -8.0, running_reward: -12.7775, time (sec): 10820.3599\n",
      "Ep. 2422 done, reward: -3.0, running_reward: -12.6819, time (sec): 10835.8542\n",
      "Ep. 2424 done, reward: -19.0, running_reward: -12.7780, time (sec): 10848.9963\n",
      "Ep. 2426 done, reward: -11.0, running_reward: -12.7426, time (sec): 10865.6899\n",
      "Ep. 2428 done, reward: -11.0, running_reward: -12.6980, time (sec): 10880.5072\n",
      "Ep. 2430 done, reward: -13.0, running_reward: -12.7139, time (sec): 10893.6495\n",
      "Ep. 2432 done, reward: -13.0, running_reward: -12.6404, time (sec): 10910.6014\n",
      "Ep. 2434 done, reward: -13.0, running_reward: -12.6773, time (sec): 10924.0776\n",
      "Ep. 2436 done, reward: -13.0, running_reward: -12.7233, time (sec): 10938.2977\n",
      "Ep. 2438 done, reward: -19.0, running_reward: -12.7096, time (sec): 10953.2243\n",
      "Ep. 2440 done, reward: -16.0, running_reward: -12.7157, time (sec): 10966.3305\n",
      "Ep. 2442 done, reward: -10.0, running_reward: -12.6616, time (sec): 10981.4553\n",
      "Ep. 2444 done, reward: -17.0, running_reward: -12.6886, time (sec): 10994.6769\n",
      "Ep. 2446 done, reward: -9.0, running_reward: -12.6647, time (sec): 11008.7715\n",
      "Ep. 2448 done, reward: -15.0, running_reward: -12.6418, time (sec): 11023.7833\n",
      "Ep. 2450 done, reward: -8.0, running_reward: -12.6386, time (sec): 11038.2578\n",
      "Ep. 2452 done, reward: -13.0, running_reward: -12.6854, time (sec): 11051.7743\n",
      "Ep. 2454 done, reward: -18.0, running_reward: -12.7416, time (sec): 11062.9089\n",
      "Ep. 2456 done, reward: -17.0, running_reward: -12.8462, time (sec): 11077.9819\n",
      "Ep. 2458 done, reward: -12.0, running_reward: -12.8590, time (sec): 11091.6456\n",
      "Ep. 2460 done, reward: -9.0, running_reward: -12.8020, time (sec): 11107.1131\n",
      "Ep. 2462 done, reward: -13.0, running_reward: -12.8654, time (sec): 11119.9370\n",
      "Ep. 2464 done, reward: -17.0, running_reward: -12.9179, time (sec): 11131.8879\n",
      "Ep. 2466 done, reward: -13.0, running_reward: -12.9493, time (sec): 11144.3467\n",
      "Ep. 2468 done, reward: -15.0, running_reward: -12.9208, time (sec): 11159.1780\n",
      "Ep. 2470 done, reward: -15.0, running_reward: -12.9523, time (sec): 11171.7868\n",
      "Ep. 2472 done, reward: -19.0, running_reward: -12.9340, time (sec): 11186.0327\n",
      "Ep. 2474 done, reward: -9.0, running_reward: -12.9448, time (sec): 11199.4685\n",
      "Ep. 2476 done, reward: -15.0, running_reward: -12.9857, time (sec): 11213.2883\n",
      "Ep. 2478 done, reward: -13.0, running_reward: -13.0256, time (sec): 11226.2012\n",
      "Ep. 2480 done, reward: -14.0, running_reward: -12.9955, time (sec): 11239.6919\n",
      "Ep. 2482 done, reward: -18.0, running_reward: -12.9763, time (sec): 11254.4996\n",
      "Ep. 2484 done, reward: -15.0, running_reward: -12.9572, time (sec): 11269.7672\n",
      "Ep. 2486 done, reward: -19.0, running_reward: -12.9982, time (sec): 11282.3671\n",
      "Ep. 2488 done, reward: -16.0, running_reward: -13.0579, time (sec): 11295.1865\n",
      "Ep. 2490 done, reward: -17.0, running_reward: -13.0671, time (sec): 11310.2356\n",
      "Ep. 2492 done, reward: -12.0, running_reward: -13.0360, time (sec): 11326.1540\n",
      "Ep. 2494 done, reward: -17.0, running_reward: -13.0059, time (sec): 11342.6092\n",
      "Ep. 2496 done, reward: -13.0, running_reward: -13.0652, time (sec): 11354.8799\n",
      "Ep. 2498 done, reward: -19.0, running_reward: -13.0150, time (sec): 11370.5086\n",
      "Ep. 2500 done, reward: -9.0, running_reward: -12.9648, time (sec): 11384.7924\n",
      "Ep. 2502 done, reward: -5.0, running_reward: -12.8459, time (sec): 11404.1485\n",
      "Ep. 2504 done, reward: -11.0, running_reward: -12.8290, time (sec): 11420.4799\n",
      "Ep. 2506 done, reward: -15.0, running_reward: -12.8128, time (sec): 11434.9315\n",
      "Ep. 2508 done, reward: -14.0, running_reward: -12.8067, time (sec): 11450.2096\n",
      "Ep. 2510 done, reward: -11.0, running_reward: -12.7906, time (sec): 11466.2557\n",
      "Ep. 2512 done, reward: -10.0, running_reward: -12.7350, time (sec): 11486.2567\n",
      "Ep. 2514 done, reward: -11.0, running_reward: -12.7401, time (sec): 11501.3971\n",
      "Ep. 2516 done, reward: -13.0, running_reward: -12.7552, time (sec): 11515.0076\n",
      "Ep. 2518 done, reward: -13.0, running_reward: -12.7007, time (sec): 11531.2850\n",
      "Ep. 2520 done, reward: -10.0, running_reward: -12.5875, time (sec): 11549.5616\n",
      "Ep. 2522 done, reward: -8.0, running_reward: -12.5457, time (sec): 11565.3708\n",
      "Ep. 2524 done, reward: -14.0, running_reward: -12.6044, time (sec): 11581.9466\n",
      "Ep. 2526 done, reward: -15.0, running_reward: -12.6124, time (sec): 11597.9144\n",
      "Ep. 2528 done, reward: -14.0, running_reward: -12.5905, time (sec): 11610.7601\n",
      "Ep. 2530 done, reward: -12.0, running_reward: -12.6085, time (sec): 11626.1615\n",
      "Ep. 2532 done, reward: -14.0, running_reward: -12.6560, time (sec): 11638.5206\n",
      "Ep. 2534 done, reward: -10.0, running_reward: -12.6130, time (sec): 11654.8697\n",
      "Ep. 2536 done, reward: -16.0, running_reward: -12.6111, time (sec): 11668.8259\n",
      "Ep. 2538 done, reward: -14.0, running_reward: -12.6190, time (sec): 11684.5785\n",
      "Ep. 2540 done, reward: -13.0, running_reward: -12.6464, time (sec): 11697.3108\n",
      "Ep. 2542 done, reward: -9.0, running_reward: -12.6530, time (sec): 11712.3217\n",
      "Ep. 2544 done, reward: -19.0, running_reward: -12.6209, time (sec): 11727.2801\n",
      "Ep. 2546 done, reward: -14.0, running_reward: -12.6582, time (sec): 11740.6175\n",
      "Ep. 2548 done, reward: -11.0, running_reward: -12.6252, time (sec): 11758.7180\n",
      "Ep. 2550 done, reward: -9.0, running_reward: -12.6026, time (sec): 11774.9744\n",
      "Ep. 2552 done, reward: -7.0, running_reward: -12.5505, time (sec): 11794.6298\n",
      "Ep. 2554 done, reward: -10.0, running_reward: -12.5097, time (sec): 11813.5675\n",
      "Ep. 2556 done, reward: -13.0, running_reward: -12.5392, time (sec): 11827.3106\n",
      "Ep. 2558 done, reward: -14.0, running_reward: -12.4693, time (sec): 11842.3056\n",
      "Ep. 2560 done, reward: -14.0, running_reward: -12.4601, time (sec): 11860.7267\n",
      "Ep. 2562 done, reward: -11.0, running_reward: -12.4113, time (sec): 11874.6028\n",
      "Ep. 2564 done, reward: -12.0, running_reward: -12.4427, time (sec): 11887.7078\n",
      "Ep. 2566 done, reward: -13.0, running_reward: -12.4538, time (sec): 11900.1729\n",
      "Ep. 2568 done, reward: -11.0, running_reward: -12.4447, time (sec): 11914.5543\n",
      "Ep. 2570 done, reward: -10.0, running_reward: -12.4158, time (sec): 11929.9410\n",
      "Ep. 2572 done, reward: -15.0, running_reward: -12.4375, time (sec): 11943.4996\n",
      "Ep. 2574 done, reward: -15.0, running_reward: -12.4786, time (sec): 11956.2727\n",
      "Ep. 2576 done, reward: -13.0, running_reward: -12.4890, time (sec): 11970.1982\n",
      "Ep. 2578 done, reward: -15.0, running_reward: -12.4202, time (sec): 11987.5893\n",
      "Ep. 2580 done, reward: -13.0, running_reward: -12.4713, time (sec): 12000.9460\n",
      "Ep. 2582 done, reward: -17.0, running_reward: -12.5614, time (sec): 12015.5802\n",
      "Ep. 2584 done, reward: -15.0, running_reward: -12.6100, time (sec): 12028.9512\n",
      "Ep. 2586 done, reward: -11.0, running_reward: -12.6175, time (sec): 12043.0833\n",
      "Ep. 2588 done, reward: -17.0, running_reward: -12.6552, time (sec): 12056.8345\n",
      "Ep. 2590 done, reward: -13.0, running_reward: -12.6918, time (sec): 12072.3556\n",
      "Ep. 2592 done, reward: -9.0, running_reward: -12.6282, time (sec): 12088.3751\n",
      "Ep. 2594 done, reward: -14.0, running_reward: -12.5862, time (sec): 12102.9868\n",
      "Ep. 2596 done, reward: -17.0, running_reward: -12.6741, time (sec): 12114.0603\n",
      "Ep. 2598 done, reward: -14.0, running_reward: -12.7004, time (sec): 12128.9229\n",
      "Ep. 2600 done, reward: -14.0, running_reward: -12.6966, time (sec): 12141.6771\n",
      "Ep. 2602 done, reward: -16.0, running_reward: -12.7524, time (sec): 12156.3975\n",
      "Ep. 2604 done, reward: -15.0, running_reward: -12.7576, time (sec): 12169.0933\n",
      "Ep. 2606 done, reward: -14.0, running_reward: -12.8120, time (sec): 12181.9216\n",
      "Ep. 2608 done, reward: -19.0, running_reward: -12.8460, time (sec): 12197.3049\n",
      "Ep. 2610 done, reward: -6.0, running_reward: -12.7494, time (sec): 12214.0801\n",
      "Ep. 2612 done, reward: -9.0, running_reward: -12.6748, time (sec): 12229.3339\n",
      "Ep. 2614 done, reward: -7.0, running_reward: -12.6015, time (sec): 12244.4559\n",
      "Ep. 2616 done, reward: -16.0, running_reward: -12.6790, time (sec): 12256.0636\n",
      "Ep. 2618 done, reward: -4.0, running_reward: -12.5756, time (sec): 12271.0142\n",
      "Ep. 2620 done, reward: -15.0, running_reward: -12.5842, time (sec): 12284.0288\n",
      "Ep. 2622 done, reward: -12.0, running_reward: -12.5825, time (sec): 12297.1739\n",
      "Ep. 2624 done, reward: -14.0, running_reward: -12.5909, time (sec): 12312.2005\n",
      "Ep. 2626 done, reward: -13.0, running_reward: -12.5792, time (sec): 12325.7048\n",
      "Ep. 2628 done, reward: -15.0, running_reward: -12.5581, time (sec): 12338.4765\n",
      "Ep. 2630 done, reward: -10.0, running_reward: -12.5567, time (sec): 12351.5575\n",
      "Ep. 2632 done, reward: -11.0, running_reward: -12.5653, time (sec): 12363.7528\n",
      "Ep. 2634 done, reward: -13.0, running_reward: -12.5641, time (sec): 12377.1867\n",
      "Ep. 2636 done, reward: -11.0, running_reward: -12.5132, time (sec): 12393.2410\n",
      "Ep. 2638 done, reward: -13.0, running_reward: -12.5327, time (sec): 12404.6450\n",
      "Ep. 2640 done, reward: -21.0, running_reward: -12.6319, time (sec): 12417.3305\n",
      "Ep. 2642 done, reward: -12.0, running_reward: -12.6095, time (sec): 12430.1537\n",
      "Ep. 2644 done, reward: -4.0, running_reward: -12.5767, time (sec): 12443.4230\n",
      "Ep. 2646 done, reward: -15.0, running_reward: -12.5656, time (sec): 12457.0814\n",
      "Ep. 2648 done, reward: -13.0, running_reward: -12.5643, time (sec): 12472.2776\n",
      "Ep. 2650 done, reward: -12.0, running_reward: -12.5234, time (sec): 12486.9886\n",
      "Ep. 2652 done, reward: -13.0, running_reward: -12.5626, time (sec): 12500.1749\n",
      "Ep. 2654 done, reward: -6.0, running_reward: -12.4815, time (sec): 12515.5533\n",
      "Ep. 2656 done, reward: -16.0, running_reward: -12.4426, time (sec): 12530.7214\n",
      "Ep. 2658 done, reward: -9.0, running_reward: -12.4533, time (sec): 12543.1717\n",
      "Ep. 2660 done, reward: -10.0, running_reward: -12.4639, time (sec): 12558.6835\n",
      "Ep. 2662 done, reward: -12.0, running_reward: -12.5041, time (sec): 12571.5330\n",
      "Ep. 2664 done, reward: -15.0, running_reward: -12.5340, time (sec): 12585.7552\n",
      "Ep. 2666 done, reward: -6.0, running_reward: -12.4832, time (sec): 12599.9061\n",
      "Ep. 2668 done, reward: -8.0, running_reward: -12.3049, time (sec): 12616.3385\n",
      "Ep. 2670 done, reward: -13.0, running_reward: -12.1999, time (sec): 12631.6893\n",
      "Ep. 2672 done, reward: -13.0, running_reward: -12.2356, time (sec): 12643.1898\n",
      "Ep. 2674 done, reward: -6.0, running_reward: -12.1511, time (sec): 12660.3032\n",
      "Ep. 2676 done, reward: -14.0, running_reward: -12.1186, time (sec): 12673.4881\n",
      "Ep. 2678 done, reward: -16.0, running_reward: -12.0870, time (sec): 12687.3325\n",
      "Ep. 2680 done, reward: -11.0, running_reward: -12.1247, time (sec): 12700.5512\n",
      "Ep. 2682 done, reward: -11.0, running_reward: -12.1518, time (sec): 12715.2154\n",
      "Ep. 2684 done, reward: -15.0, running_reward: -12.1887, time (sec): 12729.3699\n",
      "Ep. 2686 done, reward: -9.0, running_reward: -12.1550, time (sec): 12741.9689\n",
      "Ep. 2688 done, reward: -12.0, running_reward: -12.1321, time (sec): 12757.8102\n",
      "Ep. 2690 done, reward: -14.0, running_reward: -12.1990, time (sec): 12769.7010\n",
      "Ep. 2692 done, reward: -5.0, running_reward: -12.0656, time (sec): 12787.9633\n",
      "Ep. 2694 done, reward: -17.0, running_reward: -12.1440, time (sec): 12799.4208\n",
      "Ep. 2696 done, reward: -13.0, running_reward: -12.0719, time (sec): 12814.7002\n",
      "Ep. 2698 done, reward: -7.0, running_reward: -12.0700, time (sec): 12828.0868\n",
      "Ep. 2700 done, reward: -15.0, running_reward: -12.0491, time (sec): 12841.4341\n",
      "Ep. 2702 done, reward: -13.0, running_reward: -12.0581, time (sec): 12855.9201\n",
      "Ep. 2704 done, reward: -12.0, running_reward: -12.0570, time (sec): 12869.9139\n",
      "Ep. 2706 done, reward: -6.0, running_reward: -11.9859, time (sec): 12885.0985\n",
      "Ep. 2708 done, reward: -17.0, running_reward: -12.0956, time (sec): 12897.1208\n",
      "Ep. 2710 done, reward: -11.0, running_reward: -12.0639, time (sec): 12912.6243\n",
      "Ep. 2712 done, reward: -14.0, running_reward: -12.0628, time (sec): 12927.4978\n",
      "Ep. 2714 done, reward: -15.0, running_reward: -12.0322, time (sec): 12941.7772\n",
      "Ep. 2716 done, reward: -12.0, running_reward: -12.0414, time (sec): 12956.4314\n",
      "Ep. 2718 done, reward: -4.0, running_reward: -11.9606, time (sec): 12971.9785\n",
      "Ep. 2720 done, reward: -10.0, running_reward: -11.9711, time (sec): 12985.4775\n",
      "Ep. 2722 done, reward: -10.0, running_reward: -11.9220, time (sec): 12999.7807\n",
      "Ep. 2724 done, reward: -16.0, running_reward: -12.0130, time (sec): 13011.8316\n",
      "Ep. 2726 done, reward: -4.0, running_reward: -11.9031, time (sec): 13030.4624\n",
      "Ep. 2728 done, reward: -13.0, running_reward: -11.8952, time (sec): 13044.3259\n",
      "Ep. 2730 done, reward: -17.0, running_reward: -11.9572, time (sec): 13057.1528\n",
      "Ep. 2732 done, reward: -14.0, running_reward: -11.9483, time (sec): 13071.3638\n",
      "Ep. 2734 done, reward: -14.0, running_reward: -11.9397, time (sec): 13084.2035\n",
      "Ep. 2736 done, reward: -7.0, running_reward: -11.8612, time (sec): 13101.4090\n",
      "Ep. 2738 done, reward: -9.0, running_reward: -11.8240, time (sec): 13115.7245\n",
      "Ep. 2740 done, reward: -15.0, running_reward: -11.8674, time (sec): 13131.5041\n",
      "Ep. 2742 done, reward: -5.0, running_reward: -11.6912, time (sec): 13149.3255\n",
      "Ep. 2744 done, reward: -8.0, running_reward: -11.7365, time (sec): 13162.0699\n",
      "Ep. 2746 done, reward: -10.0, running_reward: -11.7317, time (sec): 13177.4584\n",
      "Ep. 2748 done, reward: -15.0, running_reward: -11.7571, time (sec): 13190.8005\n",
      "Ep. 2750 done, reward: -8.0, running_reward: -11.7120, time (sec): 13206.7468\n",
      "Ep. 2752 done, reward: -7.0, running_reward: -11.6381, time (sec): 13224.7697\n",
      "Ep. 2754 done, reward: -13.0, running_reward: -11.6157, time (sec): 13239.2097\n",
      "Ep. 2756 done, reward: -9.0, running_reward: -11.5834, time (sec): 13255.0315\n",
      "Ep. 2758 done, reward: -11.0, running_reward: -11.6114, time (sec): 13267.5954\n",
      "Ep. 2760 done, reward: 1.0, running_reward: -11.4198, time (sec): 13288.0755\n",
      "Ep. 2762 done, reward: -7.0, running_reward: -11.3913, time (sec): 13301.8183\n",
      "Ep. 2764 done, reward: -14.0, running_reward: -11.4333, time (sec): 13315.6767\n",
      "Ep. 2766 done, reward: -8.0, running_reward: -11.4046, time (sec): 13330.3302\n",
      "Ep. 2768 done, reward: -18.0, running_reward: -11.4368, time (sec): 13343.3276\n",
      "Ep. 2770 done, reward: -7.0, running_reward: -11.4178, time (sec): 13356.5212\n",
      "Ep. 2772 done, reward: -15.0, running_reward: -11.4891, time (sec): 13370.5559\n",
      "Ep. 2774 done, reward: -11.0, running_reward: -11.4695, time (sec): 13385.1897\n",
      "Ep. 2776 done, reward: -16.0, running_reward: -11.5101, time (sec): 13397.1920\n",
      "Ep. 2778 done, reward: -11.0, running_reward: -11.5396, time (sec): 13409.1655\n",
      "Ep. 2780 done, reward: -17.0, running_reward: -11.6086, time (sec): 13421.9482\n",
      "Ep. 2782 done, reward: -17.0, running_reward: -11.5872, time (sec): 13436.8630\n",
      "Ep. 2784 done, reward: -7.0, running_reward: -11.4465, time (sec): 13453.3399\n",
      "Ep. 2786 done, reward: -13.0, running_reward: -11.4972, time (sec): 13468.2651\n",
      "Ep. 2788 done, reward: -9.0, running_reward: -11.4574, time (sec): 13482.1997\n",
      "Ep. 2790 done, reward: -10.0, running_reward: -11.4185, time (sec): 13499.1771\n",
      "Ep. 2792 done, reward: -14.0, running_reward: -11.4599, time (sec): 13511.9187\n",
      "Ep. 2794 done, reward: -15.0, running_reward: -11.5502, time (sec): 13524.7597\n",
      "Ep. 2796 done, reward: -15.0, running_reward: -11.5990, time (sec): 13538.4030\n",
      "Ep. 2798 done, reward: -7.0, running_reward: -11.6065, time (sec): 13552.4498\n",
      "Ep. 2800 done, reward: -13.0, running_reward: -11.6640, time (sec): 13565.8145\n",
      "Ep. 2802 done, reward: -15.0, running_reward: -11.6610, time (sec): 13580.4666\n",
      "Ep. 2804 done, reward: -14.0, running_reward: -11.6977, time (sec): 13597.3179\n",
      "Ep. 2806 done, reward: -15.0, running_reward: -11.7634, time (sec): 13610.9922\n",
      "Ep. 2808 done, reward: -15.0, running_reward: -11.8278, time (sec): 13622.7011\n",
      "Ep. 2810 done, reward: -15.0, running_reward: -11.7721, time (sec): 13638.1985\n",
      "Ep. 2812 done, reward: -14.0, running_reward: -11.7274, time (sec): 13653.6249\n",
      "Ep. 2814 done, reward: -12.0, running_reward: -11.7031, time (sec): 13671.3384\n",
      "Ep. 2816 done, reward: -9.0, running_reward: -11.6889, time (sec): 13687.0719\n",
      "Ep. 2818 done, reward: -9.0, running_reward: -11.6552, time (sec): 13701.2809\n",
      "Ep. 2820 done, reward: -13.0, running_reward: -11.6721, time (sec): 13715.6496\n",
      "Ep. 2822 done, reward: -15.0, running_reward: -11.7581, time (sec): 13728.9293\n",
      "Ep. 2824 done, reward: -8.0, running_reward: -11.7328, time (sec): 13744.1360\n",
      "Ep. 2826 done, reward: -9.0, running_reward: -11.6982, time (sec): 13758.3514\n",
      "Ep. 2828 done, reward: -15.0, running_reward: -11.7639, time (sec): 13771.2261\n",
      "Ep. 2830 done, reward: -15.0, running_reward: -11.8382, time (sec): 13783.7332\n",
      "Ep. 2832 done, reward: -14.0, running_reward: -11.9109, time (sec): 13796.1980\n",
      "Ep. 2834 done, reward: -9.0, running_reward: -11.7936, time (sec): 13812.9023\n",
      "Ep. 2836 done, reward: -9.0, running_reward: -11.7083, time (sec): 13827.4036\n",
      "Ep. 2838 done, reward: -19.0, running_reward: -11.7940, time (sec): 13839.1830\n",
      "Ep. 2840 done, reward: -17.0, running_reward: -11.8085, time (sec): 13852.9293\n",
      "Ep. 2842 done, reward: -12.0, running_reward: -11.8321, time (sec): 13865.7550\n",
      "Ep. 2844 done, reward: -10.0, running_reward: -11.7858, time (sec): 13881.4448\n",
      "Ep. 2846 done, reward: -13.0, running_reward: -11.7307, time (sec): 13895.7880\n",
      "Ep. 2848 done, reward: -12.0, running_reward: -11.6272, time (sec): 13909.4933\n",
      "Ep. 2850 done, reward: -12.0, running_reward: -11.6643, time (sec): 13923.4042\n",
      "Ep. 2852 done, reward: -8.0, running_reward: -11.6508, time (sec): 13937.2643\n",
      "Ep. 2854 done, reward: -10.0, running_reward: -11.6278, time (sec): 13952.1141\n",
      "Ep. 2856 done, reward: -8.0, running_reward: -11.5853, time (sec): 13966.0596\n",
      "Ep. 2858 done, reward: -9.0, running_reward: -11.5735, time (sec): 13979.2587\n",
      "Ep. 2860 done, reward: -13.0, running_reward: -11.6019, time (sec): 13991.1363\n",
      "Ep. 2862 done, reward: -13.0, running_reward: -11.6891, time (sec): 14003.0640\n",
      "Ep. 2864 done, reward: -9.0, running_reward: -11.5663, time (sec): 14019.3774\n",
      "Ep. 2866 done, reward: -14.0, running_reward: -11.5949, time (sec): 14031.7970\n",
      "Ep. 2868 done, reward: -17.0, running_reward: -11.5936, time (sec): 14044.4534\n",
      "Ep. 2870 done, reward: -7.0, running_reward: -11.5418, time (sec): 14058.5395\n",
      "Ep. 2872 done, reward: -9.0, running_reward: -11.4912, time (sec): 14072.7670\n",
      "Ep. 2874 done, reward: -6.0, running_reward: -11.4710, time (sec): 14085.6648\n",
      "Ep. 2876 done, reward: -10.0, running_reward: -11.4516, time (sec): 14099.2831\n",
      "Ep. 2878 done, reward: -15.0, running_reward: -11.5025, time (sec): 14112.1636\n",
      "Ep. 2880 done, reward: -9.0, running_reward: -11.4428, time (sec): 14127.0960\n",
      "Ep. 2882 done, reward: -13.0, running_reward: -11.4737, time (sec): 14142.6447\n",
      "Ep. 2884 done, reward: -7.0, running_reward: -11.4243, time (sec): 14157.7763\n",
      "Ep. 2886 done, reward: -12.0, running_reward: -11.4556, time (sec): 14173.8901\n",
      "Ep. 2888 done, reward: -7.0, running_reward: -11.3966, time (sec): 14188.2102\n",
      "Ep. 2890 done, reward: -7.0, running_reward: -11.3388, time (sec): 14203.6005\n",
      "Ep. 2892 done, reward: -8.0, running_reward: -11.3021, time (sec): 14217.0383\n",
      "Ep. 2894 done, reward: -15.0, running_reward: -11.2767, time (sec): 14230.4961\n",
      "Ep. 2896 done, reward: -10.0, running_reward: -11.2315, time (sec): 14246.9279\n",
      "Ep. 2898 done, reward: -17.0, running_reward: -11.2473, time (sec): 14258.6962\n",
      "Ep. 2900 done, reward: -14.0, running_reward: -11.2624, time (sec): 14273.9060\n",
      "Ep. 2902 done, reward: -11.0, running_reward: -11.2869, time (sec): 14286.0849\n",
      "Ep. 2904 done, reward: -14.0, running_reward: -11.3211, time (sec): 14299.9641\n",
      "Ep. 2906 done, reward: -16.0, running_reward: -11.3350, time (sec): 14314.8796\n",
      "Ep. 2908 done, reward: -13.0, running_reward: -11.2889, time (sec): 14329.7574\n",
      "Ep. 2910 done, reward: -5.0, running_reward: -11.2628, time (sec): 14342.6057\n",
      "Ep. 2912 done, reward: -13.0, running_reward: -11.2875, time (sec): 14355.1796\n",
      "Ep. 2914 done, reward: -13.0, running_reward: -11.3215, time (sec): 14368.4998\n",
      "Ep. 2916 done, reward: -15.0, running_reward: -11.3254, time (sec): 14383.4073\n",
      "Ep. 2918 done, reward: -11.0, running_reward: -11.2794, time (sec): 14400.3505\n",
      "Ep. 2920 done, reward: -3.0, running_reward: -11.1146, time (sec): 14419.3970\n",
      "Ep. 2922 done, reward: -13.0, running_reward: -11.2115, time (sec): 14430.8653\n",
      "Ep. 2924 done, reward: -17.0, running_reward: -11.2475, time (sec): 14445.0652\n",
      "Ep. 2926 done, reward: -8.0, running_reward: -11.1730, time (sec): 14460.8981\n",
      "Ep. 2928 done, reward: -13.0, running_reward: -11.2193, time (sec): 14474.2566\n",
      "Ep. 2930 done, reward: -10.0, running_reward: -11.2049, time (sec): 14488.0090\n",
      "Ep. 2932 done, reward: -10.0, running_reward: -11.2502, time (sec): 14501.2024\n",
      "Ep. 2934 done, reward: -19.0, running_reward: -11.3252, time (sec): 14516.6421\n",
      "Ep. 2936 done, reward: -13.0, running_reward: -11.2596, time (sec): 14532.1921\n",
      "Ep. 2938 done, reward: -15.0, running_reward: -11.2251, time (sec): 14549.8874\n",
      "Ep. 2940 done, reward: -15.0, running_reward: -11.2903, time (sec): 14563.7080\n",
      "Ep. 2942 done, reward: -7.0, running_reward: -11.2445, time (sec): 14581.9854\n",
      "Ep. 2944 done, reward: -8.0, running_reward: -11.1800, time (sec): 14596.8311\n",
      "Ep. 2946 done, reward: -15.0, running_reward: -11.1966, time (sec): 14613.1427\n",
      "Ep. 2948 done, reward: -15.0, running_reward: -11.2525, time (sec): 14628.2552\n",
      "Ep. 2950 done, reward: -7.0, running_reward: -11.1778, time (sec): 14643.2030\n",
      "Ep. 2952 done, reward: -13.0, running_reward: -11.2239, time (sec): 14659.0268\n",
      "Ep. 2954 done, reward: -13.0, running_reward: -11.1999, time (sec): 14675.0437\n",
      "Ep. 2956 done, reward: -16.0, running_reward: -11.2459, time (sec): 14688.7623\n",
      "Ep. 2958 done, reward: -15.0, running_reward: -11.3008, time (sec): 14703.6460\n",
      "Ep. 2960 done, reward: -3.0, running_reward: -11.2346, time (sec): 14720.7428\n",
      "Ep. 2962 done, reward: -5.0, running_reward: -11.1204, time (sec): 14738.3672\n",
      "Ep. 2964 done, reward: -12.0, running_reward: -11.1280, time (sec): 14754.5241\n",
      "Ep. 2966 done, reward: -9.0, running_reward: -11.0758, time (sec): 14771.1556\n",
      "Ep. 2968 done, reward: -15.0, running_reward: -11.1638, time (sec): 14783.5893\n",
      "Ep. 2970 done, reward: -16.0, running_reward: -11.2006, time (sec): 14796.1763\n",
      "Ep. 2972 done, reward: -10.0, running_reward: -11.2064, time (sec): 14811.8688\n",
      "Ep. 2974 done, reward: -8.0, running_reward: -11.1129, time (sec): 14827.8820\n",
      "Ep. 2976 done, reward: -9.0, running_reward: -11.0511, time (sec): 14844.2373\n",
      "Ep. 2978 done, reward: -13.0, running_reward: -11.1097, time (sec): 14858.9302\n",
      "Ep. 2980 done, reward: -7.0, running_reward: -11.0972, time (sec): 14874.3397\n",
      "Ep. 2982 done, reward: -8.0, running_reward: -11.0949, time (sec): 14887.6589\n",
      "Ep. 2984 done, reward: -9.0, running_reward: -11.0335, time (sec): 14904.1052\n",
      "Ep. 2986 done, reward: -15.0, running_reward: -11.0728, time (sec): 14920.1513\n",
      "Ep. 2988 done, reward: -12.0, running_reward: -11.0813, time (sec): 14935.2854\n",
      "Ep. 2990 done, reward: -9.0, running_reward: -11.0795, time (sec): 14950.4216\n",
      "Ep. 2992 done, reward: -9.0, running_reward: -11.0282, time (sec): 14967.5748\n",
      "Ep. 2994 done, reward: 9.0, running_reward: -10.8178, time (sec): 14983.3553\n",
      "Ep. 2996 done, reward: -2.0, running_reward: -10.6819, time (sec): 15000.1030\n",
      "Ep. 2998 done, reward: -11.0, running_reward: -10.6387, time (sec): 15017.0261\n",
      "Ep. 3000 done, reward: 3.0, running_reward: -10.5059, time (sec): 15035.5337\n",
      "Ep. 3002 done, reward: -15.0, running_reward: -10.4865, time (sec): 15049.9794\n",
      "Ep. 3004 done, reward: -10.0, running_reward: -10.4768, time (sec): 15067.3846\n",
      "Ep. 3006 done, reward: -6.0, running_reward: -10.4075, time (sec): 15085.2306\n",
      "Ep. 3008 done, reward: -15.0, running_reward: -10.3603, time (sec): 15105.2397\n",
      "Ep. 3010 done, reward: -15.0, running_reward: -10.3635, time (sec): 15123.3956\n",
      "Ep. 3012 done, reward: -6.0, running_reward: -10.3064, time (sec): 15138.5791\n",
      "Ep. 3014 done, reward: -15.0, running_reward: -10.3899, time (sec): 15154.0258\n",
      "Ep. 3016 done, reward: -14.0, running_reward: -10.3924, time (sec): 15170.5794\n",
      "Ep. 3018 done, reward: -16.0, running_reward: -10.4347, time (sec): 15183.9977\n",
      "Ep. 3020 done, reward: -11.0, running_reward: -10.3470, time (sec): 15202.9889\n",
      "Ep. 3022 done, reward: -12.0, running_reward: -10.4195, time (sec): 15220.1709\n",
      "Ep. 3024 done, reward: -15.0, running_reward: -10.4512, time (sec): 15234.7530\n",
      "Ep. 3026 done, reward: -11.0, running_reward: -10.3928, time (sec): 15251.7802\n",
      "Ep. 3028 done, reward: -9.0, running_reward: -10.4047, time (sec): 15268.5923\n",
      "Ep. 3030 done, reward: -8.0, running_reward: -10.3866, time (sec): 15285.7020\n",
      "Ep. 3032 done, reward: -9.0, running_reward: -10.4283, time (sec): 15301.8110\n",
      "Ep. 3034 done, reward: -10.0, running_reward: -10.3504, time (sec): 15318.9064\n",
      "Ep. 3036 done, reward: -14.0, running_reward: -10.3043, time (sec): 15335.3144\n",
      "Ep. 3038 done, reward: -14.0, running_reward: -10.3580, time (sec): 15349.5989\n",
      "Ep. 3040 done, reward: -11.0, running_reward: -10.3708, time (sec): 15366.0343\n",
      "Ep. 3042 done, reward: -5.0, running_reward: -10.3530, time (sec): 15382.3238\n",
      "Ep. 3044 done, reward: -15.0, running_reward: -10.4554, time (sec): 15394.7899\n",
      "Ep. 3046 done, reward: -17.0, running_reward: -10.5460, time (sec): 15409.8624\n",
      "Ep. 3048 done, reward: -15.0, running_reward: -10.6050, time (sec): 15425.2833\n",
      "Ep. 3050 done, reward: -9.0, running_reward: -10.5730, time (sec): 15440.2288\n",
      "Ep. 3052 done, reward: -10.0, running_reward: -10.6012, time (sec): 15453.4197\n",
      "Ep. 3054 done, reward: -16.0, running_reward: -10.5602, time (sec): 15469.1045\n",
      "Ep. 3056 done, reward: -15.0, running_reward: -10.6485, time (sec): 15481.1798\n",
      "Ep. 3058 done, reward: -13.0, running_reward: -10.7349, time (sec): 15493.5464\n",
      "Ep. 3060 done, reward: -15.0, running_reward: -10.7406, time (sec): 15508.6653\n",
      "Ep. 3062 done, reward: -12.0, running_reward: -10.7557, time (sec): 15523.0826\n",
      "Ep. 3064 done, reward: -9.0, running_reward: -10.7307, time (sec): 15537.7701\n",
      "Ep. 3066 done, reward: -16.0, running_reward: -10.7465, time (sec): 15552.2719\n",
      "Ep. 3068 done, reward: -17.0, running_reward: -10.7818, time (sec): 15566.8238\n",
      "Ep. 3070 done, reward: -5.0, running_reward: -10.7162, time (sec): 15583.6836\n",
      "Ep. 3072 done, reward: -12.0, running_reward: -10.7418, time (sec): 15599.3941\n",
      "Ep. 3074 done, reward: -7.0, running_reward: -10.7762, time (sec): 15612.4977\n",
      "Ep. 3076 done, reward: -13.0, running_reward: -10.7908, time (sec): 15628.6276\n",
      "Ep. 3078 done, reward: -4.0, running_reward: -10.7645, time (sec): 15643.8380\n",
      "Ep. 3080 done, reward: -14.0, running_reward: -10.8586, time (sec): 15655.6365\n",
      "Ep. 3082 done, reward: -7.0, running_reward: -10.8313, time (sec): 15671.7191\n",
      "Ep. 3084 done, reward: -15.0, running_reward: -10.8153, time (sec): 15684.1239\n",
      "Ep. 3086 done, reward: -17.0, running_reward: -10.8394, time (sec): 15701.0664\n",
      "Ep. 3088 done, reward: -7.0, running_reward: -10.8323, time (sec): 15717.8720\n",
      "Ep. 3090 done, reward: -8.0, running_reward: -10.8155, time (sec): 15732.6325\n",
      "Ep. 3092 done, reward: -7.0, running_reward: -10.7891, time (sec): 15747.6114\n",
      "Ep. 3094 done, reward: -12.0, running_reward: -10.8033, time (sec): 15764.7585\n",
      "Ep. 3096 done, reward: -9.0, running_reward: -10.7575, time (sec): 15779.8899\n",
      "Ep. 3098 done, reward: -10.0, running_reward: -10.7820, time (sec): 15794.4207\n",
      "Ep. 3100 done, reward: -3.0, running_reward: -10.7163, time (sec): 15813.7394\n",
      "Ep. 3102 done, reward: -17.0, running_reward: -10.7819, time (sec): 15830.3095\n",
      "Ep. 3104 done, reward: -8.0, running_reward: -10.7562, time (sec): 15847.2853\n",
      "Ep. 3106 done, reward: -8.0, running_reward: -10.7113, time (sec): 15864.1576\n",
      "Ep. 3108 done, reward: -6.0, running_reward: -10.6967, time (sec): 15881.1097\n",
      "Ep. 3110 done, reward: -3.0, running_reward: -10.6129, time (sec): 15898.8272\n",
      "Ep. 3112 done, reward: -9.0, running_reward: -10.6006, time (sec): 15916.3588\n",
      "Ep. 3114 done, reward: -12.0, running_reward: -10.6185, time (sec): 15934.5982\n",
      "Ep. 3116 done, reward: -14.0, running_reward: -10.6363, time (sec): 15949.2682\n",
      "Ep. 3118 done, reward: -17.0, running_reward: -10.6640, time (sec): 15964.6169\n",
      "Ep. 3120 done, reward: -4.0, running_reward: -10.5610, time (sec): 15984.5963\n",
      "Ep. 3122 done, reward: -9.0, running_reward: -10.5696, time (sec): 16001.0667\n",
      "Ep. 3124 done, reward: -17.0, running_reward: -10.5688, time (sec): 16016.9509\n",
      "Ep. 3126 done, reward: -10.0, running_reward: -10.6268, time (sec): 16031.7910\n",
      "Ep. 3128 done, reward: -12.0, running_reward: -10.6344, time (sec): 16050.3840\n",
      "Ep. 3130 done, reward: -9.0, running_reward: -10.5523, time (sec): 16070.0331\n",
      "Ep. 3132 done, reward: -3.0, running_reward: -10.5010, time (sec): 16087.3742\n",
      "Ep. 3134 done, reward: -9.0, running_reward: -10.4811, time (sec): 16104.5781\n",
      "Ep. 3136 done, reward: -10.0, running_reward: -10.5012, time (sec): 16119.4142\n",
      "Ep. 3138 done, reward: -11.0, running_reward: -10.5309, time (sec): 16134.0393\n",
      "Ep. 3140 done, reward: -14.0, running_reward: -10.6198, time (sec): 16146.8060\n",
      "Ep. 3142 done, reward: -12.0, running_reward: -10.6472, time (sec): 16162.0005\n",
      "Ep. 3144 done, reward: -6.0, running_reward: -10.6141, time (sec): 16176.0817\n",
      "Ep. 3146 done, reward: -9.0, running_reward: -10.6612, time (sec): 16188.4727\n",
      "Ep. 3148 done, reward: -13.0, running_reward: -10.6484, time (sec): 16202.1749\n",
      "Ep. 3150 done, reward: -7.0, running_reward: -10.6550, time (sec): 16217.0044\n",
      "Ep. 3152 done, reward: -7.0, running_reward: -10.5525, time (sec): 16233.0339\n",
      "Ep. 3154 done, reward: -13.0, running_reward: -10.5616, time (sec): 16246.3064\n",
      "Ep. 3156 done, reward: -3.0, running_reward: -10.4607, time (sec): 16263.1404\n",
      "Ep. 3158 done, reward: -15.0, running_reward: -10.4916, time (sec): 16276.0358\n",
      "Ep. 3160 done, reward: -12.0, running_reward: -10.5018, time (sec): 16293.0813\n",
      "Ep. 3162 done, reward: -6.0, running_reward: -10.4815, time (sec): 16307.5654\n",
      "Ep. 3164 done, reward: -9.0, running_reward: -10.4718, time (sec): 16322.5224\n",
      "Ep. 3166 done, reward: -7.0, running_reward: -10.4819, time (sec): 16335.7783\n",
      "Ep. 3168 done, reward: -11.0, running_reward: -10.5814, time (sec): 16349.2320\n",
      "Ep. 3170 done, reward: -9.0, running_reward: -10.4707, time (sec): 16367.9358\n",
      "Ep. 3172 done, reward: -12.0, running_reward: -10.5110, time (sec): 16381.4421\n",
      "Ep. 3174 done, reward: -12.0, running_reward: -10.5406, time (sec): 16394.8473\n",
      "Ep. 3176 done, reward: -9.0, running_reward: -10.5001, time (sec): 16409.1082\n",
      "Ep. 3178 done, reward: -18.0, running_reward: -10.5998, time (sec): 16420.9922\n",
      "Ep. 3180 done, reward: -10.0, running_reward: -10.5582, time (sec): 16434.1973\n",
      "Ep. 3182 done, reward: -10.0, running_reward: -10.5471, time (sec): 16449.9006\n",
      "Ep. 3184 done, reward: -8.0, running_reward: -10.5558, time (sec): 16465.6047\n",
      "Ep. 3186 done, reward: -13.0, running_reward: -10.4460, time (sec): 16479.6001\n",
      "Ep. 3188 done, reward: -4.0, running_reward: -10.3475, time (sec): 16496.9039\n",
      "Ep. 3190 done, reward: -17.0, running_reward: -10.3908, time (sec): 16510.1358\n",
      "Ep. 3192 done, reward: -3.0, running_reward: -10.2437, time (sec): 16528.9736\n",
      "Ep. 3194 done, reward: -8.0, running_reward: -10.2089, time (sec): 16544.2075\n",
      "Ep. 3196 done, reward: -14.0, running_reward: -10.2349, time (sec): 16559.0007\n",
      "Ep. 3198 done, reward: -17.0, running_reward: -10.3299, time (sec): 16573.1429\n",
      "Ep. 3200 done, reward: -13.0, running_reward: -10.3137, time (sec): 16588.0938\n",
      "Ep. 3202 done, reward: -13.0, running_reward: -10.3276, time (sec): 16601.3227\n",
      "Ep. 3204 done, reward: -18.0, running_reward: -10.4110, time (sec): 16614.6359\n",
      "Ep. 3206 done, reward: -15.0, running_reward: -10.4528, time (sec): 16628.6069\n",
      "Ep. 3208 done, reward: -4.0, running_reward: -10.3640, time (sec): 16645.5338\n",
      "Ep. 3210 done, reward: -12.0, running_reward: -10.3272, time (sec): 16661.3767\n",
      "Ep. 3212 done, reward: -9.0, running_reward: -10.3206, time (sec): 16677.6120\n",
      "Ep. 3214 done, reward: -9.0, running_reward: -10.2745, time (sec): 16693.9602\n",
      "Ep. 3216 done, reward: -3.0, running_reward: -10.2288, time (sec): 16708.1174\n",
      "Ep. 3218 done, reward: -13.0, running_reward: -10.3037, time (sec): 16721.6539\n",
      "Ep. 3220 done, reward: -9.0, running_reward: -10.2877, time (sec): 16736.0789\n",
      "Ep. 3222 done, reward: -5.0, running_reward: -10.2023, time (sec): 16751.8592\n",
      "Ep. 3224 done, reward: -9.0, running_reward: -10.2179, time (sec): 16767.8769\n",
      "Ep. 3226 done, reward: -14.0, running_reward: -10.2239, time (sec): 16779.7498\n",
      "Ep. 3228 done, reward: 5.0, running_reward: -10.0694, time (sec): 16794.3921\n",
      "Ep. 3230 done, reward: -15.0, running_reward: -10.1478, time (sec): 16808.3484\n",
      "Ep. 3232 done, reward: -12.0, running_reward: -10.0262, time (sec): 16824.8199\n",
      "Ep. 3234 done, reward: -6.0, running_reward: -10.0352, time (sec): 16842.8475\n",
      "Ep. 3236 done, reward: -12.0, running_reward: -10.0050, time (sec): 16858.1484\n",
      "Ep. 3238 done, reward: -13.0, running_reward: -10.0646, time (sec): 16872.3508\n",
      "Ep. 3240 done, reward: -15.0, running_reward: -10.1529, time (sec): 16884.9128\n",
      "Ep. 3242 done, reward: -8.0, running_reward: -10.1101, time (sec): 16903.1719\n",
      "Ep. 3244 done, reward: -16.0, running_reward: -10.1679, time (sec): 16916.8060\n",
      "Ep. 3246 done, reward: -1.0, running_reward: -10.0646, time (sec): 16932.9571\n",
      "Ep. 3248 done, reward: -3.0, running_reward: -9.9142, time (sec): 16949.8649\n",
      "Ep. 3250 done, reward: -9.0, running_reward: -9.8564, time (sec): 16964.9808\n",
      "Ep. 3252 done, reward: -14.0, running_reward: -9.9091, time (sec): 16978.3115\n",
      "Ep. 3254 done, reward: -13.0, running_reward: -9.8716, time (sec): 16994.9435\n",
      "Ep. 3256 done, reward: -5.0, running_reward: -9.8242, time (sec): 17011.3731\n",
      "Ep. 3258 done, reward: -9.0, running_reward: -9.8870, time (sec): 17026.6446\n",
      "Ep. 3260 done, reward: -12.0, running_reward: -9.9785, time (sec): 17038.2376\n",
      "Ep. 3262 done, reward: -6.0, running_reward: -9.9093, time (sec): 17055.6825\n",
      "Ep. 3264 done, reward: -9.0, running_reward: -9.9110, time (sec): 17070.9579\n",
      "Ep. 3266 done, reward: -7.0, running_reward: -9.8728, time (sec): 17088.0240\n",
      "Ep. 3268 done, reward: -15.0, running_reward: -9.9056, time (sec): 17101.6852\n",
      "Ep. 3270 done, reward: -10.0, running_reward: -9.9866, time (sec): 17114.9571\n",
      "Ep. 3272 done, reward: -11.0, running_reward: -10.0068, time (sec): 17129.8275\n",
      "Ep. 3274 done, reward: -9.0, running_reward: -10.0264, time (sec): 17144.2208\n",
      "Ep. 3276 done, reward: -7.0, running_reward: -10.0157, time (sec): 17159.3512\n",
      "Ep. 3278 done, reward: -17.0, running_reward: -10.1348, time (sec): 17171.6147\n",
      "Ep. 3280 done, reward: 1.0, running_reward: -9.9727, time (sec): 17190.8792\n",
      "Ep. 3282 done, reward: -9.0, running_reward: -9.9335, time (sec): 17206.8123\n",
      "Ep. 3284 done, reward: -17.0, running_reward: -10.0444, time (sec): 17220.8978\n",
      "Ep. 3286 done, reward: -4.0, running_reward: -9.9340, time (sec): 17243.2158\n",
      "Ep. 3288 done, reward: -9.0, running_reward: -9.9947, time (sec): 17256.0738\n",
      "Ep. 3290 done, reward: -13.0, running_reward: -9.9654, time (sec): 17271.7612\n",
      "Ep. 3292 done, reward: -9.0, running_reward: -10.0154, time (sec): 17285.6232\n",
      "Ep. 3294 done, reward: -9.0, running_reward: -9.9358, time (sec): 17303.3381\n",
      "Ep. 3296 done, reward: -11.0, running_reward: -9.9372, time (sec): 17320.7055\n",
      "Ep. 3298 done, reward: -10.0, running_reward: -9.9187, time (sec): 17337.5401\n",
      "Ep. 3300 done, reward: -9.0, running_reward: -9.9400, time (sec): 17354.3564\n",
      "Ep. 3302 done, reward: -8.0, running_reward: -9.9311, time (sec): 17370.0295\n",
      "Ep. 3304 done, reward: -15.0, running_reward: -9.9924, time (sec): 17383.8423\n",
      "Ep. 3306 done, reward: -14.0, running_reward: -10.0523, time (sec): 17396.5491\n",
      "Ep. 3308 done, reward: -6.0, running_reward: -9.9717, time (sec): 17413.4922\n",
      "Ep. 3310 done, reward: -8.0, running_reward: -9.9621, time (sec): 17427.5890\n",
      "Ep. 3312 done, reward: -9.0, running_reward: -9.9628, time (sec): 17443.0925\n",
      "Ep. 3314 done, reward: -4.0, running_reward: -9.9530, time (sec): 17459.1017\n",
      "Ep. 3316 done, reward: -9.0, running_reward: -9.9341, time (sec): 17473.8742\n",
      "Ep. 3318 done, reward: -10.0, running_reward: -9.9651, time (sec): 17489.9578\n",
      "Ep. 3320 done, reward: -11.0, running_reward: -9.9461, time (sec): 17507.1270\n",
      "Ep. 3322 done, reward: -15.0, running_reward: -9.9377, time (sec): 17524.1895\n",
      "Ep. 3324 done, reward: -4.0, running_reward: -9.8394, time (sec): 17540.9608\n",
      "Ep. 3326 done, reward: -9.0, running_reward: -9.8920, time (sec): 17557.1377\n",
      "Ep. 3328 done, reward: -9.0, running_reward: -9.9039, time (sec): 17570.3388\n",
      "Ep. 3330 done, reward: -18.0, running_reward: -9.9858, time (sec): 17583.8491\n",
      "Ep. 3332 done, reward: -8.0, running_reward: -9.9562, time (sec): 17598.7467\n",
      "Ep. 3334 done, reward: -12.0, running_reward: -9.9177, time (sec): 17615.1851\n",
      "Ep. 3336 done, reward: -13.0, running_reward: -9.9394, time (sec): 17629.8461\n",
      "Ep. 3338 done, reward: -7.0, running_reward: -9.9205, time (sec): 17646.5189\n",
      "Ep. 3340 done, reward: -13.0, running_reward: -9.9917, time (sec): 17661.3062\n",
      "Ep. 3342 done, reward: -5.0, running_reward: -9.9518, time (sec): 17677.9726\n",
      "Ep. 3344 done, reward: -11.0, running_reward: -9.9528, time (sec): 17695.8502\n",
      "Ep. 3346 done, reward: -11.0, running_reward: -10.0133, time (sec): 17716.7824\n",
      "Ep. 3348 done, reward: -5.0, running_reward: -9.9927, time (sec): 17733.9840\n",
      "Ep. 3350 done, reward: -11.0, running_reward: -9.9534, time (sec): 17750.1589\n",
      "Ep. 3352 done, reward: -8.0, running_reward: -9.9145, time (sec): 17766.2653\n",
      "Ep. 3354 done, reward: -12.0, running_reward: -9.9065, time (sec): 17781.5576\n",
      "Ep. 3356 done, reward: -10.0, running_reward: -9.8588, time (sec): 17799.5376\n",
      "Ep. 3358 done, reward: -14.0, running_reward: -9.8918, time (sec): 17815.8065\n",
      "Ep. 3360 done, reward: -16.0, running_reward: -10.0034, time (sec): 17830.1322\n",
      "Ep. 3362 done, reward: -11.0, running_reward: -10.0430, time (sec): 17846.1850\n",
      "Ep. 3364 done, reward: -13.0, running_reward: -10.0623, time (sec): 17860.4164\n",
      "Ep. 3366 done, reward: -10.0, running_reward: -10.0412, time (sec): 17876.7426\n",
      "Ep. 3368 done, reward: -13.0, running_reward: -10.1199, time (sec): 17890.7756\n",
      "Ep. 3370 done, reward: -1.0, running_reward: -10.0275, time (sec): 17909.6599\n",
      "Ep. 3372 done, reward: -6.0, running_reward: -9.9771, time (sec): 17926.2271\n",
      "Ep. 3374 done, reward: -7.0, running_reward: -9.9772, time (sec): 17944.9018\n",
      "Ep. 3376 done, reward: -11.0, running_reward: -10.0075, time (sec): 17961.0931\n",
      "Ep. 3378 done, reward: -7.0, running_reward: -9.9476, time (sec): 17978.0794\n",
      "Ep. 3380 done, reward: -16.0, running_reward: -9.9394, time (sec): 17994.5929\n",
      "Ep. 3382 done, reward: -2.0, running_reward: -9.8507, time (sec): 18010.7513\n",
      "Ep. 3384 done, reward: -5.0, running_reward: -9.7740, time (sec): 18029.3629\n",
      "Ep. 3386 done, reward: -6.0, running_reward: -9.7682, time (sec): 18045.9271\n",
      "Ep. 3388 done, reward: -5.0, running_reward: -9.7822, time (sec): 18060.7875\n",
      "Ep. 3390 done, reward: -15.0, running_reward: -9.8662, time (sec): 18074.6671\n",
      "Ep. 3392 done, reward: -12.0, running_reward: -9.8394, time (sec): 18091.3546\n",
      "Ep. 3394 done, reward: -12.0, running_reward: -9.8230, time (sec): 18106.3613\n",
      "Ep. 3396 done, reward: -9.0, running_reward: -9.8264, time (sec): 18124.6150\n",
      "Ep. 3398 done, reward: -14.0, running_reward: -9.8006, time (sec): 18143.2041\n",
      "Ep. 3400 done, reward: -13.0, running_reward: -9.6068, time (sec): 18157.5583\n",
      "Ep. 3402 done, reward: -17.0, running_reward: -9.7341, time (sec): 18171.5868\n",
      "Ep. 3404 done, reward: -12.0, running_reward: -9.7693, time (sec): 18187.8194\n",
      "Ep. 3406 done, reward: -17.0, running_reward: -9.8538, time (sec): 18203.3537\n",
      "Ep. 3408 done, reward: -16.0, running_reward: -9.9563, time (sec): 18215.8933\n",
      "Ep. 3410 done, reward: -8.0, running_reward: -9.9372, time (sec): 18232.3428\n",
      "Ep. 3412 done, reward: -13.0, running_reward: -9.9982, time (sec): 18245.9006\n",
      "Ep. 3414 done, reward: -14.0, running_reward: -10.0382, time (sec): 18259.8896\n",
      "Ep. 3416 done, reward: -13.0, running_reward: -10.0377, time (sec): 18276.2881\n",
      "Ep. 3418 done, reward: -14.0, running_reward: -10.1364, time (sec): 18288.2824\n",
      "Ep. 3420 done, reward: -12.0, running_reward: -10.1735, time (sec): 18304.1162\n",
      "Ep. 3422 done, reward: -15.0, running_reward: -10.2497, time (sec): 18318.4243\n",
      "Ep. 3424 done, reward: -8.0, running_reward: -10.2544, time (sec): 18333.1774\n",
      "Ep. 3426 done, reward: -9.0, running_reward: -10.2295, time (sec): 18348.8886\n",
      "Ep. 3428 done, reward: -7.0, running_reward: -10.1454, time (sec): 18370.0694\n",
      "Ep. 3430 done, reward: -11.0, running_reward: -10.1129, time (sec): 18387.7744\n",
      "Ep. 3432 done, reward: -9.0, running_reward: -10.0512, time (sec): 18404.3390\n",
      "Ep. 3434 done, reward: -10.0, running_reward: -10.0799, time (sec): 18419.7908\n",
      "Ep. 3436 done, reward: -9.0, running_reward: -10.0089, time (sec): 18438.5554\n",
      "Ep. 3438 done, reward: -8.0, running_reward: -10.0382, time (sec): 18453.0900\n",
      "Ep. 3440 done, reward: -9.0, running_reward: -10.0571, time (sec): 18471.7578\n",
      "Ep. 3442 done, reward: -9.0, running_reward: -9.9866, time (sec): 18490.3919\n",
      "Ep. 3444 done, reward: -18.0, running_reward: -10.1560, time (sec): 18503.4413\n",
      "Ep. 3446 done, reward: -4.0, running_reward: -10.0533, time (sec): 18522.8780\n",
      "Ep. 3448 done, reward: -17.0, running_reward: -10.1123, time (sec): 18539.3157\n",
      "Ep. 3450 done, reward: -13.0, running_reward: -10.1302, time (sec): 18557.6406\n",
      "Ep. 3452 done, reward: -2.0, running_reward: -10.0476, time (sec): 18576.2968\n",
      "Ep. 3454 done, reward: -14.0, running_reward: -10.1460, time (sec): 18589.6785\n",
      "Ep. 3456 done, reward: -8.0, running_reward: -10.0934, time (sec): 18604.8848\n",
      "Ep. 3458 done, reward: -14.0, running_reward: -10.2009, time (sec): 18617.2510\n",
      "Ep. 3460 done, reward: -9.0, running_reward: -10.1374, time (sec): 18634.2661\n",
      "Ep. 3462 done, reward: -8.0, running_reward: -10.1443, time (sec): 18652.6007\n",
      "Ep. 3464 done, reward: -10.0, running_reward: -10.1910, time (sec): 18674.3024\n",
      "Ep. 3466 done, reward: -8.0, running_reward: -10.1573, time (sec): 18690.0217\n",
      "Ep. 3468 done, reward: -10.0, running_reward: -10.1442, time (sec): 18706.4653\n",
      "Ep. 3470 done, reward: -13.0, running_reward: -10.0922, time (sec): 18722.1506\n",
      "Ep. 3472 done, reward: -4.0, running_reward: -10.0006, time (sec): 18740.3091\n",
      "Ep. 3474 done, reward: -9.0, running_reward: -9.9708, time (sec): 18758.4307\n",
      "Ep. 3476 done, reward: -1.0, running_reward: -9.8517, time (sec): 18781.7049\n",
      "Ep. 3478 done, reward: -1.0, running_reward: -9.7448, time (sec): 18799.9820\n",
      "Ep. 3480 done, reward: -17.0, running_reward: -9.8397, time (sec): 18813.4649\n",
      "Ep. 3482 done, reward: -9.0, running_reward: -9.8626, time (sec): 18828.7044\n",
      "Ep. 3484 done, reward: -16.0, running_reward: -9.9550, time (sec): 18841.8858\n",
      "Ep. 3486 done, reward: -7.0, running_reward: -9.9556, time (sec): 18859.0981\n",
      "Ep. 3488 done, reward: -12.0, running_reward: -9.9369, time (sec): 18874.6378\n",
      "Ep. 3490 done, reward: -13.0, running_reward: -9.9781, time (sec): 18890.2849\n",
      "Ep. 3492 done, reward: -9.0, running_reward: -10.0279, time (sec): 18904.5702\n",
      "Ep. 3494 done, reward: -9.0, running_reward: -9.8689, time (sec): 18921.2372\n",
      "Ep. 3496 done, reward: -4.0, running_reward: -9.7521, time (sec): 18939.2984\n",
      "Ep. 3498 done, reward: -5.0, running_reward: -9.7268, time (sec): 18958.0415\n",
      "Ep. 3500 done, reward: -7.0, running_reward: -9.7220, time (sec): 18975.6075\n",
      "Ep. 3502 done, reward: -11.0, running_reward: -9.7475, time (sec): 18990.3802\n",
      "Ep. 3504 done, reward: -11.0, running_reward: -9.8219, time (sec): 19005.7546\n",
      "Ep. 3506 done, reward: -18.0, running_reward: -9.8163, time (sec): 19023.0075\n",
      "Ep. 3508 done, reward: -15.0, running_reward: -9.9096, time (sec): 19036.9269\n",
      "Ep. 3510 done, reward: -17.0, running_reward: -9.9913, time (sec): 19054.0940\n",
      "Ep. 3512 done, reward: -10.0, running_reward: -9.9123, time (sec): 19074.4281\n",
      "Ep. 3514 done, reward: -12.0, running_reward: -9.8053, time (sec): 19090.8904\n",
      "Ep. 3516 done, reward: -16.0, running_reward: -9.8494, time (sec): 19104.9609\n",
      "Ep. 3518 done, reward: -7.0, running_reward: -9.7630, time (sec): 19120.9954\n",
      "Ep. 3520 done, reward: -11.0, running_reward: -9.7876, time (sec): 19135.8666\n",
      "Ep. 3522 done, reward: -8.0, running_reward: -9.7520, time (sec): 19153.5102\n",
      "Ep. 3524 done, reward: 1.0, running_reward: -9.6569, time (sec): 19170.4761\n",
      "Ep. 3526 done, reward: -14.0, running_reward: -9.6146, time (sec): 19187.1068\n",
      "Ep. 3528 done, reward: -8.0, running_reward: -9.6320, time (sec): 19201.0383\n",
      "Ep. 3530 done, reward: -2.0, running_reward: -9.6286, time (sec): 19214.9423\n",
      "Ep. 3532 done, reward: -13.0, running_reward: -9.7353, time (sec): 19227.4062\n",
      "Ep. 3534 done, reward: -13.0, running_reward: -9.8200, time (sec): 19242.6060\n",
      "Ep. 3536 done, reward: -5.0, running_reward: -9.8231, time (sec): 19255.8524\n",
      "Ep. 3538 done, reward: -11.0, running_reward: -9.8960, time (sec): 19268.4660\n",
      "Ep. 3540 done, reward: -10.0, running_reward: -9.9377, time (sec): 19285.3809\n",
      "Ep. 3542 done, reward: -5.0, running_reward: -9.8791, time (sec): 19301.1526\n",
      "Ep. 3544 done, reward: -13.0, running_reward: -9.8719, time (sec): 19314.7960\n",
      "Ep. 3546 done, reward: -11.0, running_reward: -9.9042, time (sec): 19330.3753\n",
      "Ep. 3548 done, reward: -4.0, running_reward: -9.8560, time (sec): 19349.3965\n",
      "Ep. 3550 done, reward: -11.0, running_reward: -9.8986, time (sec): 19364.6262\n",
      "Ep. 3552 done, reward: -9.0, running_reward: -9.8708, time (sec): 19380.9496\n",
      "Ep. 3554 done, reward: -19.0, running_reward: -9.9040, time (sec): 19396.6393\n",
      "Ep. 3556 done, reward: -8.0, running_reward: -9.8958, time (sec): 19412.3469\n",
      "Ep. 3558 done, reward: -11.0, running_reward: -9.8881, time (sec): 19427.0724\n",
      "Ep. 3560 done, reward: -3.0, running_reward: -9.8005, time (sec): 19443.2562\n",
      "Ep. 3562 done, reward: -3.0, running_reward: -9.7444, time (sec): 19462.4074\n",
      "Ep. 3564 done, reward: -1.0, running_reward: -9.6792, time (sec): 19480.3731\n",
      "Ep. 3566 done, reward: -7.0, running_reward: -9.7051, time (sec): 19496.4332\n",
      "Ep. 3568 done, reward: -11.0, running_reward: -9.7408, time (sec): 19511.7844\n",
      "Ep. 3570 done, reward: -7.0, running_reward: -9.6664, time (sec): 19530.0432\n",
      "Ep. 3572 done, reward: -11.0, running_reward: -9.6732, time (sec): 19546.4880\n",
      "Ep. 3574 done, reward: -11.0, running_reward: -9.6996, time (sec): 19560.1451\n",
      "Ep. 3576 done, reward: -9.0, running_reward: -9.7154, time (sec): 19575.9076\n",
      "Ep. 3578 done, reward: -13.0, running_reward: -9.7807, time (sec): 19591.0897\n",
      "Ep. 3580 done, reward: -14.0, running_reward: -9.8548, time (sec): 19603.2167\n",
      "Ep. 3582 done, reward: -9.0, running_reward: -9.7784, time (sec): 19620.6429\n",
      "Ep. 3584 done, reward: -1.0, running_reward: -9.6928, time (sec): 19639.2968\n",
      "Ep. 3586 done, reward: -10.0, running_reward: -9.6197, time (sec): 19656.3609\n",
      "Ep. 3588 done, reward: -10.0, running_reward: -9.6768, time (sec): 19670.2087\n",
      "Ep. 3590 done, reward: -9.0, running_reward: -9.7029, time (sec): 19685.5849\n",
      "Ep. 3592 done, reward: -7.0, running_reward: -9.6788, time (sec): 19700.2376\n",
      "Ep. 3594 done, reward: 3.0, running_reward: -9.5750, time (sec): 19715.6250\n",
      "Ep. 3596 done, reward: -11.0, running_reward: -9.5737, time (sec): 19730.8261\n",
      "Ep. 3598 done, reward: -15.0, running_reward: -9.5728, time (sec): 19744.6995\n",
      "Ep. 3600 done, reward: -8.0, running_reward: -9.4920, time (sec): 19760.9625\n",
      "Ep. 3602 done, reward: -14.0, running_reward: -9.5718, time (sec): 19773.7912\n",
      "Ep. 3604 done, reward: -9.0, running_reward: -9.5901, time (sec): 19788.0238\n",
      "Ep. 3606 done, reward: -3.0, running_reward: -9.5183, time (sec): 19805.1809\n",
      "Ep. 3608 done, reward: -11.0, running_reward: -9.5676, time (sec): 19818.8859\n",
      "Ep. 3610 done, reward: -7.0, running_reward: -9.5957, time (sec): 19833.6368\n",
      "Ep. 3612 done, reward: -7.0, running_reward: -9.6134, time (sec): 19846.7269\n",
      "Ep. 3614 done, reward: -16.0, running_reward: -9.7405, time (sec): 19860.1703\n",
      "Ep. 3616 done, reward: -11.0, running_reward: -9.6863, time (sec): 19876.4242\n",
      "Ep. 3618 done, reward: -9.0, running_reward: -9.7123, time (sec): 19890.2229\n",
      "Ep. 3620 done, reward: -5.0, running_reward: -9.5096, time (sec): 19906.0421\n",
      "Ep. 3622 done, reward: -11.0, running_reward: -9.5195, time (sec): 19922.6197\n",
      "Ep. 3624 done, reward: -7.0, running_reward: -9.3901, time (sec): 19940.5134\n",
      "Ep. 3626 done, reward: -7.0, running_reward: -9.3426, time (sec): 19956.9056\n",
      "Ep. 3628 done, reward: -12.0, running_reward: -9.3954, time (sec): 19971.1573\n",
      "Ep. 3630 done, reward: -16.0, running_reward: -9.4774, time (sec): 19984.6045\n",
      "Ep. 3632 done, reward: -12.0, running_reward: -9.4880, time (sec): 20001.4397\n",
      "Ep. 3634 done, reward: -7.0, running_reward: -9.4286, time (sec): 20019.0344\n",
      "Ep. 3636 done, reward: -13.0, running_reward: -9.4798, time (sec): 20033.3952\n",
      "Ep. 3638 done, reward: -5.0, running_reward: -9.4798, time (sec): 20048.8397\n",
      "Ep. 3640 done, reward: -10.0, running_reward: -9.4802, time (sec): 20065.5818\n",
      "Ep. 3642 done, reward: -15.0, running_reward: -9.5703, time (sec): 20077.0987\n",
      "Ep. 3644 done, reward: -5.0, running_reward: -9.4694, time (sec): 20094.5256\n",
      "Ep. 3646 done, reward: -9.0, running_reward: -9.5393, time (sec): 20108.9884\n",
      "Ep. 3648 done, reward: -12.0, running_reward: -9.5388, time (sec): 20124.6426\n",
      "Ep. 3650 done, reward: -12.0, running_reward: -9.5382, time (sec): 20140.4961\n",
      "Ep. 3652 done, reward: -13.0, running_reward: -9.5180, time (sec): 20155.6032\n",
      "Ep. 3654 done, reward: -4.0, running_reward: -9.4973, time (sec): 20173.2516\n",
      "Ep. 3656 done, reward: -10.0, running_reward: -9.5172, time (sec): 20190.1665\n",
      "Ep. 3658 done, reward: -8.0, running_reward: -9.4672, time (sec): 20208.7941\n",
      "Ep. 3660 done, reward: -13.0, running_reward: -9.5276, time (sec): 20222.3324\n",
      "Ep. 3662 done, reward: -9.0, running_reward: -9.4775, time (sec): 20236.5837\n",
      "Ep. 3664 done, reward: -9.0, running_reward: -9.5076, time (sec): 20250.4246\n",
      "Ep. 3666 done, reward: -7.0, running_reward: -9.4478, time (sec): 20266.2044\n",
      "Ep. 3668 done, reward: -10.0, running_reward: -9.4489, time (sec): 20282.2187\n",
      "Ep. 3670 done, reward: -5.0, running_reward: -9.3703, time (sec): 20299.8577\n",
      "Ep. 3672 done, reward: -8.0, running_reward: -9.3529, time (sec): 20315.1208\n",
      "Ep. 3674 done, reward: -17.0, running_reward: -9.4655, time (sec): 20327.6226\n",
      "Ep. 3676 done, reward: -11.0, running_reward: -9.4960, time (sec): 20343.0038\n",
      "Ep. 3678 done, reward: -13.0, running_reward: -9.4866, time (sec): 20359.0033\n",
      "Ep. 3680 done, reward: -4.0, running_reward: -9.3873, time (sec): 20376.5556\n",
      "Ep. 3682 done, reward: -13.0, running_reward: -9.3602, time (sec): 20392.2058\n",
      "Ep. 3684 done, reward: -9.0, running_reward: -9.3728, time (sec): 20409.0416\n",
      "Ep. 3686 done, reward: -7.0, running_reward: -9.1870, time (sec): 20425.5653\n",
      "Ep. 3688 done, reward: -9.0, running_reward: -9.1635, time (sec): 20440.5535\n",
      "Ep. 3690 done, reward: -12.0, running_reward: -9.1110, time (sec): 20456.0877\n",
      "Ep. 3692 done, reward: -9.0, running_reward: -9.1286, time (sec): 20472.9998\n",
      "Ep. 3694 done, reward: -11.0, running_reward: -9.1361, time (sec): 20486.0460\n",
      "Ep. 3696 done, reward: -15.0, running_reward: -9.2528, time (sec): 20498.6201\n",
      "Ep. 3698 done, reward: -11.0, running_reward: -9.3371, time (sec): 20511.5898\n",
      "Ep. 3700 done, reward: -3.0, running_reward: -9.2506, time (sec): 20527.4130\n",
      "Ep. 3702 done, reward: -11.0, running_reward: -9.2953, time (sec): 20543.0422\n",
      "Ep. 3704 done, reward: -20.0, running_reward: -9.4093, time (sec): 20555.9956\n",
      "Ep. 3706 done, reward: -2.0, running_reward: -9.2916, time (sec): 20574.4251\n",
      "Ep. 3708 done, reward: -11.0, running_reward: -9.3256, time (sec): 20588.8752\n",
      "Ep. 3710 done, reward: -3.0, running_reward: -9.3284, time (sec): 20604.4748\n",
      "Ep. 3712 done, reward: -8.0, running_reward: -9.2921, time (sec): 20622.4443\n",
      "Ep. 3714 done, reward: -5.0, running_reward: -9.2463, time (sec): 20638.9604\n",
      "Ep. 3716 done, reward: -11.0, running_reward: -9.2614, time (sec): 20653.4124\n",
      "Ep. 3718 done, reward: -8.0, running_reward: -9.1868, time (sec): 20668.7705\n",
      "Ep. 3720 done, reward: -9.0, running_reward: -9.1236, time (sec): 20686.4845\n",
      "Ep. 3722 done, reward: -14.0, running_reward: -9.1811, time (sec): 20699.7799\n",
      "Ep. 3724 done, reward: -9.0, running_reward: -9.2171, time (sec): 20715.0420\n",
      "Ep. 3726 done, reward: -3.0, running_reward: -9.1825, time (sec): 20732.1619\n",
      "Ep. 3728 done, reward: -17.0, running_reward: -9.1400, time (sec): 20746.3904\n",
      "Ep. 3730 done, reward: -13.0, running_reward: -9.0584, time (sec): 20764.5046\n",
      "Ep. 3732 done, reward: -8.0, running_reward: -8.8988, time (sec): 20780.8607\n",
      "Ep. 3734 done, reward: -7.0, running_reward: -8.8808, time (sec): 20796.4978\n",
      "Ep. 3736 done, reward: -9.0, running_reward: -8.8832, time (sec): 20811.8778\n",
      "Ep. 3738 done, reward: -17.0, running_reward: -8.9259, time (sec): 20826.1851\n",
      "Ep. 3740 done, reward: -11.0, running_reward: -8.9375, time (sec): 20840.1998\n",
      "Ep. 3742 done, reward: -4.0, running_reward: -8.9481, time (sec): 20854.7129\n",
      "Ep. 3744 done, reward: -10.0, running_reward: -8.9690, time (sec): 20870.5244\n",
      "Ep. 3746 done, reward: -14.0, running_reward: -8.9405, time (sec): 20887.2844\n",
      "Ep. 3748 done, reward: -15.0, running_reward: -9.0412, time (sec): 20899.6422\n",
      "Ep. 3750 done, reward: -12.0, running_reward: -8.9912, time (sec): 20916.6081\n",
      "Ep. 3752 done, reward: -11.0, running_reward: -9.0312, time (sec): 20928.8599\n",
      "Ep. 3754 done, reward: -15.0, running_reward: -9.0708, time (sec): 20942.6558\n",
      "Ep. 3756 done, reward: -6.0, running_reward: -9.0988, time (sec): 20961.2770\n",
      "Ep. 3758 done, reward: -14.0, running_reward: -9.1567, time (sec): 20975.5451\n",
      "Ep. 3760 done, reward: -11.0, running_reward: -9.1736, time (sec): 20990.9669\n",
      "Ep. 3762 done, reward: -2.0, running_reward: -9.1199, time (sec): 21005.7096\n",
      "Ep. 3764 done, reward: -11.0, running_reward: -9.1276, time (sec): 21022.6262\n",
      "Ep. 3766 done, reward: -8.0, running_reward: -9.1745, time (sec): 21038.7589\n",
      "Ep. 3768 done, reward: -7.0, running_reward: -9.0520, time (sec): 21056.8338\n",
      "Ep. 3770 done, reward: -15.0, running_reward: -9.1209, time (sec): 21071.0707\n",
      "Ep. 3772 done, reward: -3.0, running_reward: -8.9991, time (sec): 21085.4228\n",
      "Ep. 3774 done, reward: 1.0, running_reward: -8.9585, time (sec): 21101.6103\n",
      "Ep. 3776 done, reward: -15.0, running_reward: -8.9500, time (sec): 21117.7877\n",
      "Ep. 3778 done, reward: -6.0, running_reward: -8.8418, time (sec): 21136.7763\n",
      "Ep. 3780 done, reward: -9.0, running_reward: -8.7361, time (sec): 21154.0929\n",
      "Ep. 3782 done, reward: -11.0, running_reward: -8.6623, time (sec): 21169.0600\n",
      "Ep. 3784 done, reward: -13.0, running_reward: -8.6694, time (sec): 21182.6897\n",
      "Ep. 3786 done, reward: -17.0, running_reward: -8.7659, time (sec): 21196.2930\n",
      "Ep. 3788 done, reward: -11.0, running_reward: -8.8104, time (sec): 21211.2056\n",
      "Ep. 3790 done, reward: -13.0, running_reward: -8.8740, time (sec): 21225.7134\n",
      "Ep. 3792 done, reward: -11.0, running_reward: -8.9658, time (sec): 21238.9658\n",
      "Ep. 3794 done, reward: -3.0, running_reward: -8.8965, time (sec): 21255.7370\n",
      "Ep. 3796 done, reward: -6.0, running_reward: -8.8686, time (sec): 21272.7478\n",
      "Ep. 3798 done, reward: -7.0, running_reward: -8.7819, time (sec): 21290.6095\n",
      "Ep. 3800 done, reward: -12.0, running_reward: -8.7866, time (sec): 21307.1583\n",
      "Ep. 3802 done, reward: -12.0, running_reward: -8.8505, time (sec): 21323.5602\n",
      "Ep. 3804 done, reward: -7.0, running_reward: -8.8929, time (sec): 21338.3826\n",
      "Ep. 3806 done, reward: -15.0, running_reward: -9.0045, time (sec): 21351.3518\n",
      "Ep. 3808 done, reward: -6.0, running_reward: -8.9744, time (sec): 21367.7120\n",
      "Ep. 3810 done, reward: -11.0, running_reward: -9.0246, time (sec): 21382.9407\n",
      "Ep. 3812 done, reward: -5.0, running_reward: -8.9544, time (sec): 21400.4746\n",
      "Ep. 3814 done, reward: -11.0, running_reward: -9.0050, time (sec): 21414.8327\n",
      "Ep. 3816 done, reward: -11.0, running_reward: -9.0843, time (sec): 21429.1513\n",
      "Ep. 3818 done, reward: -10.0, running_reward: -9.1026, time (sec): 21445.0688\n",
      "Ep. 3820 done, reward: -2.0, running_reward: -9.0107, time (sec): 21462.3993\n",
      "Ep. 3822 done, reward: -3.0, running_reward: -9.0297, time (sec): 21477.6989\n",
      "Ep. 3824 done, reward: 1.0, running_reward: -8.9489, time (sec): 21492.4076\n",
      "Ep. 3826 done, reward: -13.0, running_reward: -9.0295, time (sec): 21506.1268\n",
      "Ep. 3828 done, reward: -15.0, running_reward: -9.0295, time (sec): 21521.1065\n",
      "Ep. 3830 done, reward: -3.0, running_reward: -8.9591, time (sec): 21538.4655\n",
      "Ep. 3832 done, reward: -4.0, running_reward: -8.9297, time (sec): 21556.1345\n",
      "Ep. 3834 done, reward: -20.0, running_reward: -9.0015, time (sec): 21570.0915\n",
      "Ep. 3836 done, reward: -12.0, running_reward: -8.9621, time (sec): 21586.8393\n",
      "Ep. 3838 done, reward: -13.0, running_reward: -8.9633, time (sec): 21603.0955\n",
      "Ep. 3840 done, reward: -11.0, running_reward: -9.0038, time (sec): 21617.5228\n",
      "Ep. 3842 done, reward: -14.0, running_reward: -9.0340, time (sec): 21632.6152\n",
      "Ep. 3844 done, reward: 1.0, running_reward: -8.8838, time (sec): 21653.5821\n",
      "Ep. 3846 done, reward: -8.0, running_reward: -8.8761, time (sec): 21669.3508\n",
      "Ep. 3848 done, reward: -2.0, running_reward: -8.8284, time (sec): 21685.2394\n",
      "Ep. 3850 done, reward: -16.0, running_reward: -8.8325, time (sec): 21701.7020\n",
      "Ep. 3852 done, reward: -11.0, running_reward: -8.8558, time (sec): 21715.7730\n",
      "Ep. 3854 done, reward: -9.0, running_reward: -8.8389, time (sec): 21733.6683\n",
      "Ep. 3856 done, reward: -3.0, running_reward: -8.7128, time (sec): 21754.9165\n",
      "Ep. 3858 done, reward: -11.0, running_reward: -8.7187, time (sec): 21773.1008\n",
      "Ep. 3860 done, reward: -18.0, running_reward: -8.7450, time (sec): 21790.0418\n",
      "Ep. 3862 done, reward: -11.0, running_reward: -8.7107, time (sec): 21806.8540\n",
      "Ep. 3864 done, reward: -3.0, running_reward: -8.7158, time (sec): 21820.5059\n",
      "Ep. 3866 done, reward: -16.0, running_reward: -8.7915, time (sec): 21833.6635\n",
      "Ep. 3868 done, reward: -7.0, running_reward: -8.7162, time (sec): 21852.8819\n",
      "Ep. 3870 done, reward: -6.0, running_reward: -8.6919, time (sec): 21868.4286\n",
      "Ep. 3872 done, reward: -11.0, running_reward: -8.7378, time (sec): 21883.0242\n",
      "Ep. 3874 done, reward: -15.0, running_reward: -8.8426, time (sec): 21897.8172\n",
      "Ep. 3876 done, reward: -12.0, running_reward: -8.8362, time (sec): 21912.3864\n",
      "Ep. 3878 done, reward: -11.0, running_reward: -8.8495, time (sec): 21929.4469\n",
      "Ep. 3880 done, reward: -6.0, running_reward: -8.8423, time (sec): 21945.8126\n",
      "Ep. 3882 done, reward: 8.0, running_reward: -8.6260, time (sec): 21960.9225\n",
      "Ep. 3884 done, reward: -16.0, running_reward: -8.7331, time (sec): 21976.4476\n",
      "Ep. 3886 done, reward: -12.0, running_reward: -8.7981, time (sec): 21991.4471\n",
      "Ep. 3888 done, reward: -10.0, running_reward: -8.8616, time (sec): 22009.0908\n",
      "Ep. 3890 done, reward: 1.0, running_reward: -8.7644, time (sec): 22027.0272\n",
      "Ep. 3892 done, reward: -11.0, running_reward: -8.7990, time (sec): 22041.5819\n",
      "Ep. 3894 done, reward: 4.0, running_reward: -8.7522, time (sec): 22057.1210\n",
      "Ep. 3896 done, reward: -13.0, running_reward: -8.7773, time (sec): 22073.3383\n",
      "Ep. 3898 done, reward: -15.0, running_reward: -8.8219, time (sec): 22088.6484\n",
      "Ep. 3900 done, reward: -5.0, running_reward: -8.8152, time (sec): 22103.8997\n",
      "Ep. 3902 done, reward: -12.0, running_reward: -8.8687, time (sec): 22117.6150\n",
      "Ep. 3904 done, reward: -10.0, running_reward: -8.8813, time (sec): 22132.4888\n",
      "Ep. 3906 done, reward: -3.0, running_reward: -8.8038, time (sec): 22150.4589\n",
      "Ep. 3908 done, reward: -15.0, running_reward: -8.8479, time (sec): 22164.7715\n",
      "Ep. 3910 done, reward: -9.0, running_reward: -8.8609, time (sec): 22181.9617\n",
      "Ep. 3912 done, reward: -11.0, running_reward: -8.8242, time (sec): 22198.1766\n",
      "Ep. 3914 done, reward: -15.0, running_reward: -8.8778, time (sec): 22212.1133\n",
      "Ep. 3916 done, reward: -11.0, running_reward: -8.9498, time (sec): 22226.5678\n",
      "Ep. 3918 done, reward: -3.0, running_reward: -8.8611, time (sec): 22245.1905\n",
      "Ep. 3920 done, reward: -9.0, running_reward: -8.8935, time (sec): 22259.6426\n",
      "Ep. 3922 done, reward: -2.0, running_reward: -8.9048, time (sec): 22275.4878\n",
      "Ep. 3924 done, reward: -11.0, running_reward: -8.8772, time (sec): 22290.4205\n",
      "Ep. 3926 done, reward: -9.0, running_reward: -8.9193, time (sec): 22305.6306\n",
      "Ep. 3928 done, reward: -9.0, running_reward: -8.8615, time (sec): 22321.8043\n",
      "Ep. 3930 done, reward: -5.0, running_reward: -8.8440, time (sec): 22341.2338\n",
      "Ep. 3932 done, reward: -10.0, running_reward: -8.8868, time (sec): 22357.6122\n",
      "Ep. 3934 done, reward: -10.0, running_reward: -8.9684, time (sec): 22372.6791\n",
      "Ep. 3936 done, reward: -19.0, running_reward: -9.1284, time (sec): 22385.5658\n",
      "Ep. 3938 done, reward: -6.0, running_reward: -9.0365, time (sec): 22404.9931\n",
      "Ep. 3940 done, reward: -11.0, running_reward: -9.0953, time (sec): 22420.5266\n",
      "Ep. 3942 done, reward: -4.0, running_reward: -9.0137, time (sec): 22437.8096\n",
      "Ep. 3944 done, reward: -15.0, running_reward: -9.1131, time (sec): 22450.8688\n",
      "Ep. 3946 done, reward: -12.0, running_reward: -9.1309, time (sec): 22466.3986\n",
      "Ep. 3948 done, reward: -10.0, running_reward: -9.1185, time (sec): 22482.6640\n",
      "Ep. 3950 done, reward: -5.0, running_reward: -9.1455, time (sec): 22497.0932\n",
      "Ep. 3952 done, reward: -10.0, running_reward: -9.1328, time (sec): 22512.7131\n",
      "Ep. 3954 done, reward: -13.0, running_reward: -9.0711, time (sec): 22530.2933\n",
      "Ep. 3956 done, reward: -11.0, running_reward: -8.9808, time (sec): 22546.6117\n",
      "Ep. 3958 done, reward: -12.0, running_reward: -8.9914, time (sec): 22561.3950\n",
      "Ep. 3960 done, reward: -13.0, running_reward: -9.1009, time (sec): 22574.0701\n",
      "Ep. 3962 done, reward: -2.0, running_reward: -9.0388, time (sec): 22592.4550\n",
      "Ep. 3964 done, reward: -7.0, running_reward: -9.0576, time (sec): 22608.7813\n",
      "Ep. 3966 done, reward: -9.0, running_reward: -8.9772, time (sec): 22626.3655\n",
      "Ep. 3968 done, reward: -4.0, running_reward: -8.9673, time (sec): 22641.7489\n",
      "Ep. 3970 done, reward: -12.0, running_reward: -9.0672, time (sec): 22656.8077\n",
      "Ep. 3972 done, reward: -13.0, running_reward: -9.1455, time (sec): 22669.8235\n",
      "Ep. 3974 done, reward: -11.0, running_reward: -9.1428, time (sec): 22685.3944\n",
      "Ep. 3976 done, reward: -17.0, running_reward: -9.2695, time (sec): 22698.5568\n",
      "Ep. 3978 done, reward: 3.0, running_reward: -9.1144, time (sec): 22718.5687\n",
      "Ep. 3980 done, reward: -15.0, running_reward: -9.2018, time (sec): 22733.2266\n",
      "Ep. 3982 done, reward: -13.0, running_reward: -9.1190, time (sec): 22750.3477\n",
      "Ep. 3984 done, reward: -10.0, running_reward: -9.1266, time (sec): 22768.1100\n",
      "Ep. 3986 done, reward: -13.0, running_reward: -9.2235, time (sec): 22782.6353\n",
      "Ep. 3988 done, reward: -9.0, running_reward: -9.1795, time (sec): 22800.1821\n",
      "Ep. 3990 done, reward: -13.0, running_reward: -9.1664, time (sec): 22818.2622\n",
      "Ep. 3992 done, reward: -3.0, running_reward: -9.1328, time (sec): 22837.2057\n",
      "Ep. 3994 done, reward: -7.0, running_reward: -9.1200, time (sec): 22853.8791\n",
      "Ep. 3996 done, reward: -5.0, running_reward: -9.0975, time (sec): 22871.8994\n",
      "Ep. 3998 done, reward: -13.0, running_reward: -9.1454, time (sec): 22885.6988\n",
      "Ep. 4000 done, reward: -1.0, running_reward: -9.0427, time (sec): 22903.1141\n",
      "Ep. 4002 done, reward: -6.0, running_reward: -8.9921, time (sec): 22920.4853\n",
      "Ep. 4004 done, reward: -13.0, running_reward: -9.0421, time (sec): 22935.5004\n",
      "Ep. 4006 done, reward: -7.0, running_reward: -9.0510, time (sec): 22951.2614\n",
      "Ep. 4008 done, reward: -9.0, running_reward: -9.0302, time (sec): 22969.2467\n",
      "Ep. 4010 done, reward: -13.0, running_reward: -9.0894, time (sec): 22983.7925\n",
      "Ep. 4012 done, reward: 1.0, running_reward: -8.9480, time (sec): 23002.3291\n",
      "Ep. 4014 done, reward: -13.0, running_reward: -8.9791, time (sec): 23017.8345\n",
      "Ep. 4016 done, reward: -9.0, running_reward: -8.9895, time (sec): 23033.6182\n",
      "Ep. 4018 done, reward: -5.0, running_reward: -8.9200, time (sec): 23051.6160\n",
      "Ep. 4020 done, reward: -15.0, running_reward: -8.9519, time (sec): 23066.4144\n",
      "Ep. 4022 done, reward: 3.0, running_reward: -8.8526, time (sec): 23086.5499\n",
      "Ep. 4024 done, reward: -7.0, running_reward: -8.8058, time (sec): 23104.3267\n",
      "Ep. 4026 done, reward: 7.0, running_reward: -8.6002, time (sec): 23121.5524\n",
      "Ep. 4028 done, reward: -7.0, running_reward: -8.5189, time (sec): 23139.6681\n",
      "Ep. 4030 done, reward: -5.0, running_reward: -8.5280, time (sec): 23155.8497\n",
      "Ep. 4032 done, reward: 3.0, running_reward: -8.4273, time (sec): 23173.8887\n",
      "Ep. 4034 done, reward: -11.0, running_reward: -8.5478, time (sec): 23188.3026\n",
      "Ep. 4036 done, reward: -3.0, running_reward: -8.5067, time (sec): 23205.6642\n",
      "Ep. 4038 done, reward: -13.0, running_reward: -8.6555, time (sec): 23217.6590\n",
      "Ep. 4040 done, reward: -11.0, running_reward: -8.6824, time (sec): 23233.7190\n",
      "Ep. 4042 done, reward: -10.0, running_reward: -8.7284, time (sec): 23252.7819\n",
      "Ep. 4044 done, reward: -10.0, running_reward: -8.7339, time (sec): 23271.5601\n",
      "Ep. 4046 done, reward: -18.0, running_reward: -8.8193, time (sec): 23285.0295\n",
      "Ep. 4048 done, reward: -1.0, running_reward: -8.7528, time (sec): 23302.6551\n",
      "Ep. 4050 done, reward: -9.0, running_reward: -8.7775, time (sec): 23318.1711\n",
      "Ep. 4052 done, reward: -10.0, running_reward: -8.7227, time (sec): 23336.8485\n",
      "Ep. 4054 done, reward: -1.0, running_reward: -8.5888, time (sec): 23355.0486\n",
      "Ep. 4056 done, reward: -5.0, running_reward: -8.5570, time (sec): 23372.9232\n",
      "Ep. 4058 done, reward: -12.0, running_reward: -8.5958, time (sec): 23388.4845\n",
      "Ep. 4060 done, reward: -13.0, running_reward: -8.6735, time (sec): 23402.6216\n",
      "Ep. 4062 done, reward: -13.0, running_reward: -8.7794, time (sec): 23418.2423\n",
      "Ep. 4064 done, reward: -11.0, running_reward: -8.8335, time (sec): 23433.1902\n",
      "Ep. 4066 done, reward: -3.0, running_reward: -8.7372, time (sec): 23449.1355\n",
      "Ep. 4068 done, reward: -11.0, running_reward: -8.7822, time (sec): 23463.8064\n",
      "Ep. 4070 done, reward: -13.0, running_reward: -8.8662, time (sec): 23476.9414\n",
      "Ep. 4072 done, reward: -7.0, running_reward: -8.8488, time (sec): 23492.8190\n",
      "Ep. 4074 done, reward: -17.0, running_reward: -8.9913, time (sec): 23505.9330\n",
      "Ep. 4076 done, reward: -5.0, running_reward: -8.8722, time (sec): 23526.2043\n",
      "Ep. 4078 done, reward: -3.0, running_reward: -8.7455, time (sec): 23544.9893\n",
      "Ep. 4080 done, reward: -1.0, running_reward: -8.7101, time (sec): 23561.3478\n",
      "Ep. 4082 done, reward: -6.0, running_reward: -8.7057, time (sec): 23578.7541\n",
      "Ep. 4084 done, reward: -11.0, running_reward: -8.7811, time (sec): 23594.5500\n",
      "Ep. 4086 done, reward: -7.0, running_reward: -8.7258, time (sec): 23610.6043\n",
      "Ep. 4088 done, reward: -11.0, running_reward: -8.6919, time (sec): 23629.2829\n",
      "Ep. 4090 done, reward: -8.0, running_reward: -8.7474, time (sec): 23644.0647\n",
      "Ep. 4092 done, reward: -8.0, running_reward: -8.7820, time (sec): 23662.4049\n",
      "Ep. 4094 done, reward: -9.0, running_reward: -8.8557, time (sec): 23677.2102\n",
      "Ep. 4096 done, reward: -11.0, running_reward: -8.8587, time (sec): 23691.8690\n",
      "Ep. 4098 done, reward: -5.0, running_reward: -8.8414, time (sec): 23707.8515\n",
      "Ep. 4100 done, reward: -11.0, running_reward: -8.8843, time (sec): 23725.6457\n",
      "Ep. 4102 done, reward: -13.0, running_reward: -8.9563, time (sec): 23741.5603\n",
      "Ep. 4104 done, reward: -6.0, running_reward: -8.9668, time (sec): 23757.0413\n",
      "Ep. 4106 done, reward: -8.0, running_reward: -9.0069, time (sec): 23772.7753\n",
      "Ep. 4108 done, reward: -3.0, running_reward: -9.0062, time (sec): 23790.8671\n",
      "Ep. 4110 done, reward: -9.0, running_reward: -9.0457, time (sec): 23806.9697\n",
      "Ep. 4112 done, reward: -5.0, running_reward: -9.0048, time (sec): 23823.4289\n",
      "Ep. 4114 done, reward: -12.0, running_reward: -9.0050, time (sec): 23840.3027\n",
      "Ep. 4116 done, reward: -13.0, running_reward: -9.0746, time (sec): 23855.0379\n",
      "Ep. 4118 done, reward: -13.0, running_reward: -9.0735, time (sec): 23872.5781\n",
      "Ep. 4120 done, reward: -15.0, running_reward: -9.1122, time (sec): 23886.8689\n",
      "Ep. 4122 done, reward: -8.0, running_reward: -9.1099, time (sec): 23904.4525\n",
      "Ep. 4124 done, reward: 2.0, running_reward: -9.0571, time (sec): 23921.0200\n",
      "Ep. 4126 done, reward: 3.0, running_reward: -8.9063, time (sec): 23938.8774\n",
      "Ep. 4128 done, reward: -9.0, running_reward: -8.9675, time (sec): 23953.6529\n",
      "Ep. 4130 done, reward: -12.0, running_reward: -9.0477, time (sec): 23968.8399\n",
      "Ep. 4132 done, reward: -15.0, running_reward: -9.1562, time (sec): 23982.5174\n",
      "Ep. 4134 done, reward: -12.0, running_reward: -9.2029, time (sec): 23998.0087\n",
      "Ep. 4136 done, reward: -2.0, running_reward: -9.1289, time (sec): 24014.5707\n",
      "Ep. 4138 done, reward: -13.0, running_reward: -9.1267, time (sec): 24030.2759\n",
      "Ep. 4140 done, reward: -14.0, running_reward: -9.1247, time (sec): 24046.0779\n",
      "Ep. 4142 done, reward: -13.0, running_reward: -9.2513, time (sec): 24058.1357\n",
      "Ep. 4144 done, reward: -11.0, running_reward: -9.3059, time (sec): 24073.7845\n",
      "Ep. 4146 done, reward: -7.0, running_reward: -9.2699, time (sec): 24092.7469\n",
      "Ep. 4148 done, reward: -5.0, running_reward: -9.2444, time (sec): 24109.5730\n",
      "Ep. 4150 done, reward: -15.0, running_reward: -9.3193, time (sec): 24123.6902\n",
      "Ep. 4152 done, reward: 6.0, running_reward: -9.1431, time (sec): 24138.6776\n",
      "Ep. 4154 done, reward: -7.0, running_reward: -9.1203, time (sec): 24155.1573\n",
      "Ep. 4156 done, reward: -7.0, running_reward: -9.0880, time (sec): 24169.7657\n",
      "Ep. 4158 done, reward: -3.0, running_reward: -9.0361, time (sec): 24189.2304\n",
      "Ep. 4160 done, reward: -13.0, running_reward: -9.0358, time (sec): 24204.3328\n",
      "Ep. 4162 done, reward: -10.0, running_reward: -9.0352, time (sec): 24220.1649\n",
      "Ep. 4164 done, reward: -7.0, running_reward: -9.0343, time (sec): 24236.7570\n",
      "Ep. 4166 done, reward: -15.0, running_reward: -9.0540, time (sec): 24253.9953\n",
      "Ep. 4168 done, reward: -4.0, running_reward: -8.9931, time (sec): 24271.8355\n",
      "Ep. 4170 done, reward: -1.0, running_reward: -8.9528, time (sec): 24285.9494\n",
      "Ep. 4172 done, reward: -12.0, running_reward: -9.0827, time (sec): 24296.3628\n",
      "Ep. 4174 done, reward: -14.0, running_reward: -9.0816, time (sec): 24312.0621\n",
      "Ep. 4176 done, reward: -9.0, running_reward: -9.1196, time (sec): 24328.9459\n",
      "Ep. 4178 done, reward: -15.0, running_reward: -9.1970, time (sec): 24345.7413\n",
      "Ep. 4180 done, reward: -9.0, running_reward: -9.1832, time (sec): 24361.9274\n",
      "Ep. 4182 done, reward: -6.0, running_reward: -9.1495, time (sec): 24377.2244\n",
      "Ep. 4184 done, reward: -10.0, running_reward: -9.1169, time (sec): 24394.1275\n",
      "Ep. 4186 done, reward: -9.0, running_reward: -9.1344, time (sec): 24412.6028\n",
      "Ep. 4188 done, reward: -14.0, running_reward: -9.1718, time (sec): 24427.9104\n",
      "Ep. 4190 done, reward: -8.0, running_reward: -9.0792, time (sec): 24447.4015\n",
      "Ep. 4192 done, reward: -5.0, running_reward: -9.0277, time (sec): 24466.9363\n",
      "Ep. 4194 done, reward: -13.0, running_reward: -9.0078, time (sec): 24484.1534\n",
      "Ep. 4196 done, reward: -14.0, running_reward: -9.1368, time (sec): 24497.9563\n",
      "Ep. 4198 done, reward: -14.0, running_reward: -9.1643, time (sec): 24512.8209\n",
      "Ep. 4200 done, reward: -7.0, running_reward: -9.1806, time (sec): 24527.2611\n",
      "Ep. 4202 done, reward: -6.0, running_reward: -9.0778, time (sec): 24544.3484\n",
      "Ep. 4204 done, reward: -1.0, running_reward: -8.8774, time (sec): 24561.1992\n",
      "Ep. 4206 done, reward: -9.0, running_reward: -8.8996, time (sec): 24576.6856\n",
      "Ep. 4208 done, reward: -4.0, running_reward: -8.8120, time (sec): 24595.5763\n",
      "Ep. 4210 done, reward: -9.0, running_reward: -8.7960, time (sec): 24613.1561\n",
      "Ep. 4212 done, reward: -5.0, running_reward: -8.8788, time (sec): 24628.4400\n",
      "Ep. 4214 done, reward: -14.0, running_reward: -8.9313, time (sec): 24644.7949\n",
      "Ep. 4216 done, reward: -8.0, running_reward: -8.9523, time (sec): 24660.7310\n",
      "Ep. 4218 done, reward: -5.0, running_reward: -8.9628, time (sec): 24677.6445\n",
      "Ep. 4220 done, reward: 3.0, running_reward: -8.8435, time (sec): 24697.3427\n",
      "Ep. 4222 done, reward: -10.0, running_reward: -8.9061, time (sec): 24713.4875\n",
      "Ep. 4224 done, reward: -13.0, running_reward: -8.8985, time (sec): 24731.1935\n",
      "Ep. 4226 done, reward: -1.0, running_reward: -8.7611, time (sec): 24751.9173\n",
      "Ep. 4228 done, reward: -2.0, running_reward: -8.6959, time (sec): 24768.1256\n",
      "Ep. 4230 done, reward: -10.0, running_reward: -8.7515, time (sec): 24784.8778\n",
      "Ep. 4232 done, reward: -15.0, running_reward: -8.8660, time (sec): 24798.6229\n",
      "Ep. 4234 done, reward: -13.0, running_reward: -8.9482, time (sec): 24812.9677\n",
      "Ep. 4236 done, reward: -7.0, running_reward: -8.9095, time (sec): 24833.4164\n",
      "Ep. 4238 done, reward: -7.0, running_reward: -8.8715, time (sec): 24848.3703\n",
      "Ep. 4240 done, reward: -14.0, running_reward: -8.9834, time (sec): 24862.1591\n",
      "Ep. 4242 done, reward: -10.0, running_reward: -8.9443, time (sec): 24880.4479\n",
      "Ep. 4244 done, reward: -11.0, running_reward: -8.9159, time (sec): 24895.9302\n",
      "Ep. 4246 done, reward: -16.0, running_reward: -8.9974, time (sec): 24910.8617\n",
      "Ep. 4248 done, reward: -6.0, running_reward: -8.9774, time (sec): 24925.6546\n",
      "Ep. 4250 done, reward: -9.0, running_reward: -8.9481, time (sec): 24942.9842\n",
      "Ep. 4252 done, reward: 3.0, running_reward: -8.8787, time (sec): 24959.2143\n",
      "Ep. 4254 done, reward: -15.0, running_reward: -8.9015, time (sec): 24976.7004\n",
      "Ep. 4256 done, reward: -13.0, running_reward: -8.9830, time (sec): 24989.6782\n",
      "Ep. 4258 done, reward: 2.0, running_reward: -8.8140, time (sec): 25007.2015\n",
      "Ep. 4260 done, reward: -3.0, running_reward: -8.6785, time (sec): 25024.9965\n",
      "Ep. 4262 done, reward: -15.0, running_reward: -8.6855, time (sec): 25042.8378\n",
      "Ep. 4264 done, reward: -7.0, running_reward: -8.6915, time (sec): 25059.2508\n",
      "Ep. 4266 done, reward: -11.0, running_reward: -8.6682, time (sec): 25076.3412\n",
      "Ep. 4268 done, reward: -5.0, running_reward: -8.6942, time (sec): 25095.6465\n",
      "Ep. 4270 done, reward: 3.0, running_reward: -8.6298, time (sec): 25113.3589\n",
      "Ep. 4272 done, reward: -6.0, running_reward: -8.5477, time (sec): 25132.5877\n",
      "Ep. 4274 done, reward: -7.0, running_reward: -8.5565, time (sec): 25149.1122\n",
      "Ep. 4276 done, reward: -8.0, running_reward: -8.5554, time (sec): 25164.2987\n",
      "Ep. 4278 done, reward: -9.0, running_reward: -8.5147, time (sec): 25181.6814\n",
      "Ep. 4280 done, reward: 1.0, running_reward: -8.4244, time (sec): 25199.1453\n",
      "Ep. 4282 done, reward: -9.0, running_reward: -8.5150, time (sec): 25214.2167\n",
      "Ep. 4284 done, reward: -12.0, running_reward: -8.5052, time (sec): 25230.7696\n",
      "Ep. 4286 done, reward: -16.0, running_reward: -8.6147, time (sec): 25244.3677\n",
      "Ep. 4288 done, reward: -8.0, running_reward: -8.6124, time (sec): 25258.7310\n",
      "Ep. 4290 done, reward: -12.0, running_reward: -8.7194, time (sec): 25273.5575\n",
      "Ep. 4292 done, reward: -9.0, running_reward: -8.5765, time (sec): 25287.3633\n",
      "Ep. 4294 done, reward: 3.0, running_reward: -8.5342, time (sec): 25303.9690\n",
      "Ep. 4296 done, reward: -7.0, running_reward: -8.5433, time (sec): 25321.9950\n",
      "Ep. 4298 done, reward: -2.0, running_reward: -8.5121, time (sec): 25338.0737\n",
      "Ep. 4300 done, reward: -4.0, running_reward: -8.4916, time (sec): 25353.4001\n",
      "Ep. 4302 done, reward: -1.0, running_reward: -8.4316, time (sec): 25370.4325\n",
      "Ep. 4304 done, reward: -7.0, running_reward: -8.4823, time (sec): 25386.5388\n",
      "Ep. 4306 done, reward: -1.0, running_reward: -8.4423, time (sec): 25403.0705\n",
      "Ep. 4308 done, reward: -5.0, running_reward: -8.4431, time (sec): 25419.8179\n",
      "Ep. 4310 done, reward: -3.0, running_reward: -8.4635, time (sec): 25434.6586\n",
      "Ep. 4312 done, reward: -14.0, running_reward: -8.5044, time (sec): 25451.5359\n",
      "Ep. 4314 done, reward: -7.0, running_reward: -8.4942, time (sec): 25468.1508\n",
      "Ep. 4316 done, reward: -6.0, running_reward: -8.4149, time (sec): 25485.0382\n",
      "Ep. 4318 done, reward: -11.0, running_reward: -8.3376, time (sec): 25501.1809\n",
      "Ep. 4320 done, reward: -2.0, running_reward: -8.3204, time (sec): 25517.9332\n",
      "Ep. 4322 done, reward: -4.0, running_reward: -8.2641, time (sec): 25536.2349\n",
      "Ep. 4324 done, reward: -10.0, running_reward: -8.3383, time (sec): 25553.0028\n",
      "Ep. 4326 done, reward: -10.0, running_reward: -8.3516, time (sec): 25568.1386\n",
      "Ep. 4328 done, reward: -7.0, running_reward: -8.2257, time (sec): 25584.8976\n",
      "Ep. 4330 done, reward: -10.0, running_reward: -8.1719, time (sec): 25606.3628\n",
      "Ep. 4332 done, reward: 1.0, running_reward: -8.0883, time (sec): 25624.4553\n",
      "Ep. 4334 done, reward: -9.0, running_reward: -8.0966, time (sec): 25640.2499\n",
      "Ep. 4336 done, reward: -3.0, running_reward: -8.0051, time (sec): 25658.4667\n",
      "Ep. 4338 done, reward: -5.0, running_reward: -7.9354, time (sec): 25679.7001\n",
      "Ep. 4340 done, reward: -3.0, running_reward: -7.8372, time (sec): 25698.4761\n",
      "Ep. 4342 done, reward: -9.0, running_reward: -7.8306, time (sec): 25714.5495\n",
      "Ep. 4344 done, reward: -9.0, running_reward: -7.6757, time (sec): 25729.7719\n",
      "Ep. 4346 done, reward: -7.0, running_reward: -7.7612, time (sec): 25744.9549\n",
      "Ep. 4348 done, reward: -11.0, running_reward: -7.7663, time (sec): 25760.2346\n",
      "Ep. 4350 done, reward: -15.0, running_reward: -7.9102, time (sec): 25773.2479\n",
      "Ep. 4352 done, reward: -6.0, running_reward: -7.9217, time (sec): 25789.0967\n",
      "Ep. 4354 done, reward: -5.0, running_reward: -7.8636, time (sec): 25806.0865\n",
      "Ep. 4356 done, reward: -13.0, running_reward: -7.9361, time (sec): 25820.5014\n",
      "Ep. 4358 done, reward: -7.0, running_reward: -7.9571, time (sec): 25837.3553\n",
      "Ep. 4360 done, reward: -8.0, running_reward: -7.9975, time (sec): 25853.9597\n",
      "Ep. 4362 done, reward: -8.0, running_reward: -7.9481, time (sec): 25871.1711\n",
      "Ep. 4364 done, reward: -7.0, running_reward: -7.9490, time (sec): 25887.4485\n",
      "Ep. 4366 done, reward: -7.0, running_reward: -7.9301, time (sec): 25903.3618\n",
      "Ep. 4368 done, reward: 6.0, running_reward: -7.8212, time (sec): 25920.0258\n",
      "Ep. 4370 done, reward: -13.0, running_reward: -7.8946, time (sec): 25935.9528\n",
      "Ep. 4372 done, reward: -11.0, running_reward: -7.9267, time (sec): 25951.1784\n",
      "Ep. 4374 done, reward: -7.0, running_reward: -7.8785, time (sec): 25968.2925\n",
      "Ep. 4376 done, reward: -1.0, running_reward: -7.6624, time (sec): 25985.0981\n",
      "Ep. 4378 done, reward: 1.0, running_reward: -7.5791, time (sec): 26003.1732\n",
      "Ep. 4380 done, reward: -8.0, running_reward: -7.5776, time (sec): 26019.5866\n",
      "Ep. 4382 done, reward: -3.0, running_reward: -7.5162, time (sec): 26037.5631\n",
      "Ep. 4384 done, reward: -9.0, running_reward: -7.5557, time (sec): 26055.8841\n",
      "Ep. 4386 done, reward: -13.0, running_reward: -7.5947, time (sec): 26073.0211\n",
      "Ep. 4388 done, reward: -8.0, running_reward: -7.6127, time (sec): 26089.1387\n",
      "Ep. 4390 done, reward: -8.0, running_reward: -7.6897, time (sec): 26103.3957\n",
      "Ep. 4392 done, reward: -15.0, running_reward: -7.7757, time (sec): 26118.5503\n",
      "Ep. 4394 done, reward: -3.0, running_reward: -7.7896, time (sec): 26133.7605\n",
      "Ep. 4396 done, reward: -15.0, running_reward: -7.8737, time (sec): 26148.5530\n",
      "Ep. 4398 done, reward: 7.0, running_reward: -7.7163, time (sec): 26165.8654\n",
      "Ep. 4400 done, reward: -4.0, running_reward: -7.6919, time (sec): 26182.3768\n",
      "Ep. 4402 done, reward: -13.0, running_reward: -7.7579, time (sec): 26197.6794\n",
      "Ep. 4404 done, reward: -10.0, running_reward: -7.8124, time (sec): 26215.0493\n",
      "Ep. 4406 done, reward: -5.0, running_reward: -7.6772, time (sec): 26232.4117\n",
      "Ep. 4408 done, reward: -11.0, running_reward: -7.8028, time (sec): 26246.9282\n",
      "Ep. 4410 done, reward: -8.0, running_reward: -7.8067, time (sec): 26264.0828\n",
      "Ep. 4412 done, reward: -3.0, running_reward: -7.7803, time (sec): 26281.9722\n",
      "Ep. 4414 done, reward: 1.0, running_reward: -7.7244, time (sec): 26297.1602\n",
      "Ep. 4416 done, reward: -7.0, running_reward: -7.6902, time (sec): 26313.6218\n",
      "Ep. 4418 done, reward: -7.0, running_reward: -7.6963, time (sec): 26329.2801\n",
      "Ep. 4420 done, reward: -6.0, running_reward: -7.6328, time (sec): 26348.7358\n",
      "Ep. 4422 done, reward: -3.0, running_reward: -7.5901, time (sec): 26365.7641\n",
      "Ep. 4424 done, reward: -13.0, running_reward: -7.6384, time (sec): 26381.3642\n",
      "Ep. 4426 done, reward: -8.0, running_reward: -7.6456, time (sec): 26398.8882\n",
      "Ep. 4428 done, reward: -15.0, running_reward: -7.7622, time (sec): 26413.8512\n",
      "Ep. 4430 done, reward: -8.0, running_reward: -7.7966, time (sec): 26429.4964\n",
      "Ep. 4432 done, reward: -7.0, running_reward: -7.7610, time (sec): 26446.0053\n",
      "Ep. 4434 done, reward: -14.0, running_reward: -7.7366, time (sec): 26461.8419\n",
      "Ep. 4436 done, reward: -10.0, running_reward: -7.7718, time (sec): 26478.6746\n",
      "Ep. 4438 done, reward: -12.0, running_reward: -7.8559, time (sec): 26491.2230\n",
      "Ep. 4440 done, reward: -12.0, running_reward: -7.7701, time (sec): 26507.4068\n",
      "Ep. 4442 done, reward: -7.0, running_reward: -7.7350, time (sec): 26524.4966\n",
      "Ep. 4444 done, reward: 1.0, running_reward: -7.6304, time (sec): 26541.5543\n",
      "Ep. 4446 done, reward: -1.0, running_reward: -7.6371, time (sec): 26556.4633\n",
      "Ep. 4448 done, reward: 4.0, running_reward: -7.5441, time (sec): 26572.6318\n",
      "Ep. 4450 done, reward: -17.0, running_reward: -7.6036, time (sec): 26589.3830\n",
      "Ep. 4452 done, reward: -5.0, running_reward: -7.4924, time (sec): 26607.9402\n",
      "Ep. 4454 done, reward: -10.0, running_reward: -7.5324, time (sec): 26623.3077\n",
      "Ep. 4456 done, reward: -7.0, running_reward: -7.4822, time (sec): 26641.3763\n",
      "Ep. 4458 done, reward: -13.0, running_reward: -7.5722, time (sec): 26656.2878\n",
      "Ep. 4460 done, reward: -3.0, running_reward: -7.6297, time (sec): 26671.5836\n",
      "Ep. 4462 done, reward: -7.0, running_reward: -7.6568, time (sec): 26687.4314\n",
      "Ep. 4464 done, reward: -12.0, running_reward: -7.7531, time (sec): 26702.9381\n",
      "Ep. 4466 done, reward: -3.0, running_reward: -7.7377, time (sec): 26719.6364\n",
      "Ep. 4468 done, reward: -5.0, running_reward: -7.7327, time (sec): 26737.1888\n",
      "Ep. 4470 done, reward: -9.0, running_reward: -7.5798, time (sec): 26754.1726\n",
      "Ep. 4472 done, reward: -7.0, running_reward: -7.4890, time (sec): 26772.2413\n",
      "Ep. 4474 done, reward: 6.0, running_reward: -7.3592, time (sec): 26789.2537\n",
      "Ep. 4476 done, reward: 4.0, running_reward: -7.2420, time (sec): 26805.8674\n",
      "Ep. 4478 done, reward: -11.0, running_reward: -7.1188, time (sec): 26822.8733\n",
      "Ep. 4480 done, reward: -9.0, running_reward: -7.0969, time (sec): 26840.0965\n",
      "Ep. 4482 done, reward: -2.0, running_reward: -7.0350, time (sec): 26857.7649\n",
      "Ep. 4484 done, reward: -13.0, running_reward: -7.1141, time (sec): 26874.7006\n",
      "Ep. 4486 done, reward: -15.0, running_reward: -7.2117, time (sec): 26889.5423\n",
      "Ep. 4488 done, reward: -3.0, running_reward: -7.1279, time (sec): 26909.8344\n",
      "Ep. 4490 done, reward: -13.0, running_reward: -7.0665, time (sec): 26927.3814\n",
      "Ep. 4492 done, reward: -9.0, running_reward: -6.9664, time (sec): 26945.5622\n",
      "Ep. 4494 done, reward: -18.0, running_reward: -7.0771, time (sec): 26961.5992\n",
      "Ep. 4496 done, reward: -14.0, running_reward: -7.1356, time (sec): 26978.9003\n",
      "Ep. 4498 done, reward: -11.0, running_reward: -7.1234, time (sec): 26996.9027\n",
      "Ep. 4500 done, reward: -11.0, running_reward: -7.1016, time (sec): 27012.9464\n",
      "Ep. 4502 done, reward: -9.0, running_reward: -7.1393, time (sec): 27029.0026\n",
      "Ep. 4504 done, reward: -6.0, running_reward: -7.1068, time (sec): 27046.3094\n",
      "Ep. 4506 done, reward: -13.0, running_reward: -7.1943, time (sec): 27062.0146\n",
      "Ep. 4508 done, reward: -7.0, running_reward: -7.1608, time (sec): 27081.2126\n",
      "Ep. 4510 done, reward: 7.0, running_reward: -7.0077, time (sec): 27097.8364\n",
      "Ep. 4512 done, reward: -12.0, running_reward: -6.9090, time (sec): 27113.8049\n",
      "Ep. 4514 done, reward: -14.0, running_reward: -6.9907, time (sec): 27130.8698\n",
      "Ep. 4516 done, reward: -8.0, running_reward: -6.9910, time (sec): 27149.0059\n",
      "Ep. 4518 done, reward: -9.0, running_reward: -7.0508, time (sec): 27163.7044\n",
      "Ep. 4520 done, reward: -10.0, running_reward: -7.0402, time (sec): 27180.8386\n",
      "Ep. 4522 done, reward: -3.0, running_reward: -7.1182, time (sec): 27199.3037\n",
      "Ep. 4524 done, reward: -3.0, running_reward: -6.9867, time (sec): 27216.7316\n",
      "Ep. 4526 done, reward: -10.0, running_reward: -7.0566, time (sec): 27233.1177\n",
      "Ep. 4528 done, reward: -7.0, running_reward: -7.0654, time (sec): 27251.0948\n",
      "Ep. 4530 done, reward: -3.0, running_reward: -7.0241, time (sec): 27269.6208\n",
      "Ep. 4532 done, reward: -7.0, running_reward: -7.0434, time (sec): 27287.8416\n",
      "Ep. 4534 done, reward: -13.0, running_reward: -7.1520, time (sec): 27302.5162\n",
      "Ep. 4536 done, reward: -8.0, running_reward: -7.1887, time (sec): 27316.2098\n",
      "Ep. 4538 done, reward: -7.0, running_reward: -7.1652, time (sec): 27334.1865\n",
      "Ep. 4540 done, reward: -6.0, running_reward: -7.2113, time (sec): 27351.2574\n",
      "Ep. 4542 done, reward: -14.0, running_reward: -7.2969, time (sec): 27365.6166\n",
      "Ep. 4544 done, reward: -5.0, running_reward: -7.2908, time (sec): 27382.9431\n",
      "Ep. 4546 done, reward: -14.0, running_reward: -7.3253, time (sec): 27398.1588\n",
      "Ep. 4548 done, reward: -7.0, running_reward: -7.3089, time (sec): 27416.0329\n",
      "Ep. 4550 done, reward: -15.0, running_reward: -7.3926, time (sec): 27430.3118\n",
      "Ep. 4552 done, reward: -10.0, running_reward: -7.4643, time (sec): 27447.8048\n",
      "Ep. 4554 done, reward: -14.0, running_reward: -7.5152, time (sec): 27463.8928\n",
      "Ep. 4556 done, reward: -10.0, running_reward: -7.5844, time (sec): 27481.0428\n",
      "Ep. 4558 done, reward: -5.0, running_reward: -7.5924, time (sec): 27498.0457\n",
      "Ep. 4560 done, reward: -2.0, running_reward: -7.6098, time (sec): 27513.0619\n",
      "Ep. 4562 done, reward: -9.0, running_reward: -7.5088, time (sec): 27530.3296\n",
      "Ep. 4564 done, reward: -6.0, running_reward: -7.4590, time (sec): 27548.1002\n",
      "Ep. 4566 done, reward: -2.0, running_reward: -7.4097, time (sec): 27566.2469\n",
      "Ep. 4568 done, reward: -9.0, running_reward: -7.4216, time (sec): 27580.9177\n",
      "Ep. 4570 done, reward: -11.0, running_reward: -7.4532, time (sec): 27598.0788\n",
      "Ep. 4572 done, reward: -9.0, running_reward: -7.4840, time (sec): 27615.8593\n",
      "Ep. 4574 done, reward: -6.0, running_reward: -7.4643, time (sec): 27633.4173\n",
      "Ep. 4576 done, reward: -12.0, running_reward: -7.5051, time (sec): 27651.0409\n",
      "Ep. 4578 done, reward: -2.0, running_reward: -7.4747, time (sec): 27671.9297\n",
      "Ep. 4580 done, reward: -11.0, running_reward: -7.5845, time (sec): 27685.8400\n",
      "Ep. 4582 done, reward: -9.0, running_reward: -7.5335, time (sec): 27704.9125\n",
      "Ep. 4584 done, reward: -4.0, running_reward: -7.5423, time (sec): 27720.8311\n",
      "Ep. 4586 done, reward: -8.0, running_reward: -7.5614, time (sec): 27737.3676\n",
      "Ep. 4588 done, reward: -4.0, running_reward: -7.5598, time (sec): 27755.3375\n",
      "Ep. 4590 done, reward: -10.0, running_reward: -7.5588, time (sec): 27773.0806\n",
      "Ep. 4592 done, reward: -13.0, running_reward: -7.6275, time (sec): 27790.9853\n",
      "Ep. 4594 done, reward: -7.0, running_reward: -7.6150, time (sec): 27810.2351\n",
      "Ep. 4596 done, reward: -10.0, running_reward: -7.5932, time (sec): 27826.3897\n",
      "Ep. 4598 done, reward: -10.0, running_reward: -7.6708, time (sec): 27840.9610\n",
      "Ep. 4600 done, reward: -11.0, running_reward: -7.7568, time (sec): 27856.3843\n",
      "Ep. 4602 done, reward: -13.0, running_reward: -7.8414, time (sec): 27871.9240\n",
      "Ep. 4604 done, reward: -16.0, running_reward: -7.8849, time (sec): 27888.5912\n",
      "Ep. 4606 done, reward: -12.0, running_reward: -7.9569, time (sec): 27904.4801\n",
      "Ep. 4608 done, reward: -7.0, running_reward: -8.0270, time (sec): 27919.9962\n",
      "Ep. 4610 done, reward: -12.0, running_reward: -8.1357, time (sec): 27935.0414\n",
      "Ep. 4612 done, reward: -3.0, running_reward: -8.0632, time (sec): 27952.7367\n",
      "Ep. 4614 done, reward: -2.0, running_reward: -7.8931, time (sec): 27973.2191\n",
      "Ep. 4616 done, reward: 1.0, running_reward: -7.7755, time (sec): 27993.0066\n",
      "Ep. 4618 done, reward: 3.0, running_reward: -7.7195, time (sec): 28008.0272\n",
      "Ep. 4620 done, reward: -6.0, running_reward: -7.6952, time (sec): 28025.3735\n",
      "Ep. 4622 done, reward: 5.0, running_reward: -7.4623, time (sec): 28044.2419\n",
      "Ep. 4624 done, reward: -5.0, running_reward: -7.3440, time (sec): 28060.9247\n",
      "Ep. 4626 done, reward: -2.0, running_reward: -7.2872, time (sec): 28079.5940\n",
      "Ep. 4628 done, reward: -3.0, running_reward: -7.2811, time (sec): 28098.2991\n",
      "Ep. 4630 done, reward: -3.0, running_reward: -7.1959, time (sec): 28117.4260\n",
      "Ep. 4632 done, reward: -11.0, running_reward: -7.2221, time (sec): 28136.1549\n",
      "Ep. 4634 done, reward: -11.0, running_reward: -7.2775, time (sec): 28153.5148\n",
      "Ep. 4636 done, reward: -11.0, running_reward: -7.2921, time (sec): 28170.0283\n",
      "Ep. 4638 done, reward: -2.0, running_reward: -7.1274, time (sec): 28189.4099\n",
      "Ep. 4640 done, reward: -15.0, running_reward: -7.2049, time (sec): 28206.4786\n",
      "Ep. 4642 done, reward: -13.0, running_reward: -7.2806, time (sec): 28221.7395\n",
      "Ep. 4644 done, reward: -11.0, running_reward: -7.3249, time (sec): 28235.8454\n",
      "Ep. 4646 done, reward: -13.0, running_reward: -7.3389, time (sec): 28252.5634\n",
      "Ep. 4648 done, reward: -6.0, running_reward: -7.3320, time (sec): 28269.6875\n",
      "Ep. 4650 done, reward: -7.0, running_reward: -7.3749, time (sec): 28286.9251\n",
      "Ep. 4652 done, reward: -12.0, running_reward: -7.4175, time (sec): 28304.0268\n",
      "Ep. 4654 done, reward: -7.0, running_reward: -7.3200, time (sec): 28324.9904\n",
      "Ep. 4656 done, reward: -5.0, running_reward: -7.2046, time (sec): 28343.8895\n",
      "Ep. 4658 done, reward: -5.0, running_reward: -7.1805, time (sec): 28361.8351\n",
      "Ep. 4660 done, reward: -7.0, running_reward: -7.2561, time (sec): 28380.4232\n",
      "Ep. 4662 done, reward: -5.0, running_reward: -7.2508, time (sec): 28400.3705\n",
      "Ep. 4664 done, reward: -5.0, running_reward: -7.2456, time (sec): 28416.6743\n",
      "Ep. 4666 done, reward: -6.0, running_reward: -7.2802, time (sec): 28435.3501\n",
      "Ep. 4668 done, reward: -10.0, running_reward: -7.3047, time (sec): 28451.8481\n",
      "Ep. 4670 done, reward: -5.0, running_reward: -7.2588, time (sec): 28470.8263\n",
      "Ep. 4672 done, reward: -15.0, running_reward: -7.4128, time (sec): 28484.0985\n",
      "Ep. 4674 done, reward: -10.0, running_reward: -7.4643, time (sec): 28500.5005\n",
      "Ep. 4676 done, reward: -8.0, running_reward: -7.4156, time (sec): 28516.7615\n",
      "Ep. 4678 done, reward: -9.0, running_reward: -7.3382, time (sec): 28535.5486\n",
      "Ep. 4680 done, reward: -9.0, running_reward: -7.3911, time (sec): 28551.5593\n",
      "Ep. 4682 done, reward: -13.0, running_reward: -7.5225, time (sec): 28567.5287\n",
      "Ep. 4684 done, reward: 2.0, running_reward: -7.4419, time (sec): 28584.8629\n",
      "Ep. 4686 done, reward: -13.0, running_reward: -7.4931, time (sec): 28602.1264\n",
      "Ep. 4688 done, reward: -12.0, running_reward: -7.5927, time (sec): 28617.0766\n",
      "Ep. 4690 done, reward: -9.0, running_reward: -7.6009, time (sec): 28633.6601\n",
      "Ep. 4692 done, reward: -7.0, running_reward: -7.6780, time (sec): 28650.3721\n",
      "Ep. 4694 done, reward: -7.0, running_reward: -7.6943, time (sec): 28666.4905\n",
      "Ep. 4696 done, reward: -6.0, running_reward: -7.6506, time (sec): 28686.7651\n",
      "Ep. 4698 done, reward: -8.0, running_reward: -7.6279, time (sec): 28700.8903\n",
      "Ep. 4700 done, reward: -5.0, running_reward: -7.5459, time (sec): 28720.0753\n",
      "Ep. 4702 done, reward: 4.0, running_reward: -7.5240, time (sec): 28736.2811\n",
      "Ep. 4704 done, reward: -8.0, running_reward: -7.6127, time (sec): 28749.7429\n",
      "Ep. 4706 done, reward: -7.0, running_reward: -7.6203, time (sec): 28766.7676\n",
      "Ep. 4708 done, reward: -12.0, running_reward: -7.5590, time (sec): 28783.6669\n",
      "Ep. 4710 done, reward: -9.0, running_reward: -7.5183, time (sec): 28799.6261\n",
      "Ep. 4712 done, reward: -1.0, running_reward: -7.4678, time (sec): 28819.8602\n",
      "Ep. 4714 done, reward: -10.0, running_reward: -7.4885, time (sec): 28835.5101\n",
      "Ep. 4716 done, reward: -6.0, running_reward: -7.4985, time (sec): 28852.7144\n",
      "Ep. 4718 done, reward: -10.0, running_reward: -7.4592, time (sec): 28872.1848\n",
      "Ep. 4720 done, reward: -13.0, running_reward: -7.4704, time (sec): 28888.4707\n",
      "Ep. 4722 done, reward: -9.0, running_reward: -7.4217, time (sec): 28907.7655\n",
      "Ep. 4724 done, reward: -6.0, running_reward: -7.4231, time (sec): 28923.7854\n",
      "Ep. 4726 done, reward: -6.0, running_reward: -7.4542, time (sec): 28943.0747\n",
      "Ep. 4728 done, reward: -5.0, running_reward: -7.2865, time (sec): 28959.1266\n",
      "Ep. 4730 done, reward: -9.0, running_reward: -7.3701, time (sec): 28973.6254\n",
      "Ep. 4732 done, reward: -10.0, running_reward: -7.4225, time (sec): 28988.8731\n",
      "Ep. 4734 done, reward: -3.0, running_reward: -7.2949, time (sec): 29009.5961\n",
      "Ep. 4736 done, reward: -9.0, running_reward: -7.3189, time (sec): 29026.4091\n",
      "Ep. 4738 done, reward: -5.0, running_reward: -7.2925, time (sec): 29043.8707\n",
      "Ep. 4740 done, reward: -3.0, running_reward: -7.2863, time (sec): 29059.8439\n",
      "Ep. 4742 done, reward: -9.0, running_reward: -7.3501, time (sec): 29074.6015\n",
      "Ep. 4744 done, reward: -1.0, running_reward: -7.2931, time (sec): 29093.6707\n",
      "Ep. 4746 done, reward: -13.0, running_reward: -7.3670, time (sec): 29109.9828\n",
      "Ep. 4748 done, reward: -11.0, running_reward: -7.4195, time (sec): 29127.2848\n",
      "Ep. 4750 done, reward: -9.0, running_reward: -7.4708, time (sec): 29141.6200\n",
      "Ep. 4752 done, reward: 3.0, running_reward: -7.2822, time (sec): 29162.6645\n",
      "Ep. 4754 done, reward: -4.0, running_reward: -7.2169, time (sec): 29179.5592\n",
      "Ep. 4756 done, reward: -8.0, running_reward: -7.2127, time (sec): 29196.6194\n",
      "Ep. 4758 done, reward: -15.0, running_reward: -7.2983, time (sec): 29212.4382\n",
      "Ep. 4760 done, reward: -4.0, running_reward: -7.2327, time (sec): 29231.1880\n",
      "Ep. 4762 done, reward: -10.0, running_reward: -7.2977, time (sec): 29248.8546\n",
      "Ep. 4764 done, reward: -4.0, running_reward: -7.3013, time (sec): 29264.7041\n",
      "Ep. 4766 done, reward: -11.0, running_reward: -7.3255, time (sec): 29284.1935\n",
      "Ep. 4768 done, reward: -14.0, running_reward: -7.3692, time (sec): 29301.4560\n",
      "Ep. 4770 done, reward: -10.0, running_reward: -7.3720, time (sec): 29320.1012\n",
      "Ep. 4772 done, reward: -7.0, running_reward: -7.3151, time (sec): 29337.8688\n",
      "Ep. 4774 done, reward: -5.0, running_reward: -7.3780, time (sec): 29354.6230\n",
      "Ep. 4776 done, reward: -5.0, running_reward: -7.2910, time (sec): 29372.4112\n",
      "Ep. 4778 done, reward: -3.0, running_reward: -7.2254, time (sec): 29389.8354\n",
      "Ep. 4780 done, reward: 4.0, running_reward: -7.0912, time (sec): 29409.4941\n",
      "Ep. 4782 done, reward: -8.0, running_reward: -6.9607, time (sec): 29425.7327\n",
      "Ep. 4784 done, reward: -8.0, running_reward: -6.8824, time (sec): 29446.3995\n",
      "Ep. 4786 done, reward: 2.0, running_reward: -6.8839, time (sec): 29461.8898\n",
      "Ep. 4788 done, reward: -3.0, running_reward: -6.8462, time (sec): 29479.9294\n",
      "Ep. 4790 done, reward: -7.0, running_reward: -6.8195, time (sec): 29499.1114\n",
      "Ep. 4792 done, reward: -1.0, running_reward: -6.8225, time (sec): 29514.8288\n",
      "Ep. 4794 done, reward: -3.0, running_reward: -6.7960, time (sec): 29535.2917\n",
      "Ep. 4796 done, reward: -14.0, running_reward: -6.8403, time (sec): 29552.4179\n",
      "Ep. 4798 done, reward: -5.0, running_reward: -6.9027, time (sec): 29567.0300\n",
      "Ep. 4800 done, reward: -5.0, running_reward: -6.9143, time (sec): 29584.6025\n",
      "Ep. 4802 done, reward: -4.0, running_reward: -6.8761, time (sec): 29601.8426\n",
      "Ep. 4804 done, reward: -10.0, running_reward: -6.9284, time (sec): 29617.0238\n",
      "Ep. 4806 done, reward: -9.0, running_reward: -6.9696, time (sec): 29633.0774\n",
      "Ep. 4808 done, reward: -3.0, running_reward: -6.9698, time (sec): 29650.1157\n",
      "Ep. 4810 done, reward: -13.0, running_reward: -7.0799, time (sec): 29661.7874\n",
      "Ep. 4812 done, reward: 4.0, running_reward: -6.9881, time (sec): 29679.1958\n",
      "Ep. 4814 done, reward: -3.0, running_reward: -6.8989, time (sec): 29698.7446\n",
      "Ep. 4816 done, reward: -8.0, running_reward: -6.9505, time (sec): 29716.6360\n",
      "Ep. 4818 done, reward: -11.0, running_reward: -7.0014, time (sec): 29735.3963\n",
      "Ep. 4820 done, reward: -14.0, running_reward: -7.0119, time (sec): 29755.6028\n",
      "Ep. 4822 done, reward: -2.0, running_reward: -7.0112, time (sec): 29771.6136\n",
      "Ep. 4824 done, reward: -4.0, running_reward: -7.0206, time (sec): 29788.6433\n",
      "Ep. 4826 done, reward: -10.0, running_reward: -7.1096, time (sec): 29804.4147\n",
      "Ep. 4828 done, reward: -8.0, running_reward: -7.0976, time (sec): 29822.0888\n",
      "Ep. 4830 done, reward: -11.0, running_reward: -7.1456, time (sec): 29839.6698\n",
      "Ep. 4832 done, reward: -17.0, running_reward: -7.2724, time (sec): 29856.0118\n",
      "Ep. 4834 done, reward: -3.0, running_reward: -7.1873, time (sec): 29874.1660\n",
      "Ep. 4836 done, reward: -10.0, running_reward: -7.2730, time (sec): 29887.8005\n",
      "Ep. 4838 done, reward: -7.0, running_reward: -7.3171, time (sec): 29905.9835\n",
      "Ep. 4840 done, reward: -1.0, running_reward: -7.1716, time (sec): 29927.0193\n",
      "Ep. 4842 done, reward: -6.0, running_reward: -7.1483, time (sec): 29946.1626\n",
      "Ep. 4844 done, reward: -10.0, running_reward: -7.1654, time (sec): 29964.9935\n",
      "Ep. 4846 done, reward: -13.0, running_reward: -7.0340, time (sec): 29978.3321\n",
      "Ep. 4848 done, reward: 1.0, running_reward: -6.9533, time (sec): 29999.3825\n",
      "Ep. 4850 done, reward: -7.0, running_reward: -6.9840, time (sec): 30015.2347\n",
      "Ep. 4852 done, reward: -13.0, running_reward: -7.0146, time (sec): 30031.4630\n",
      "Ep. 4854 done, reward: -9.0, running_reward: -7.0541, time (sec): 30049.5879\n",
      "Ep. 4856 done, reward: -17.0, running_reward: -7.1926, time (sec): 30063.8794\n",
      "Ep. 4858 done, reward: 2.0, running_reward: -7.0691, time (sec): 30080.1291\n",
      "Ep. 4860 done, reward: -3.0, running_reward: -7.0475, time (sec): 30098.1520\n",
      "Ep. 4862 done, reward: -14.0, running_reward: -7.0869, time (sec): 30114.0371\n",
      "Ep. 4864 done, reward: -7.0, running_reward: -6.9663, time (sec): 30130.5382\n",
      "Ep. 4866 done, reward: 3.0, running_reward: -6.9165, time (sec): 30147.2691\n",
      "Ep. 4868 done, reward: 5.0, running_reward: -6.7784, time (sec): 30165.2130\n",
      "Ep. 4870 done, reward: -9.0, running_reward: -6.7929, time (sec): 30180.8918\n",
      "Ep. 4872 done, reward: 11.0, running_reward: -6.6170, time (sec): 30198.7226\n",
      "Ep. 4874 done, reward: -7.0, running_reward: -6.6345, time (sec): 30215.5006\n",
      "Ep. 4876 done, reward: -6.0, running_reward: -6.6318, time (sec): 30234.2804\n",
      "Ep. 4878 done, reward: -13.0, running_reward: -6.6892, time (sec): 30250.1194\n",
      "Ep. 4880 done, reward: -12.0, running_reward: -6.7058, time (sec): 30267.1978\n",
      "Ep. 4882 done, reward: -10.0, running_reward: -6.6427, time (sec): 30284.7586\n",
      "Ep. 4884 done, reward: 6.0, running_reward: -6.5198, time (sec): 30301.9004\n",
      "Ep. 4886 done, reward: -6.0, running_reward: -6.4995, time (sec): 30317.5134\n",
      "Ep. 4888 done, reward: -10.0, running_reward: -6.5989, time (sec): 30332.9502\n",
      "Ep. 4890 done, reward: -9.0, running_reward: -6.6665, time (sec): 30349.7654\n",
      "Ep. 4892 done, reward: -7.0, running_reward: -6.7028, time (sec): 30368.2543\n",
      "Ep. 4894 done, reward: -5.0, running_reward: -6.5798, time (sec): 30384.8975\n",
      "Ep. 4896 done, reward: -7.0, running_reward: -6.6575, time (sec): 30399.9533\n",
      "Ep. 4898 done, reward: 4.0, running_reward: -6.5939, time (sec): 30416.3287\n",
      "Ep. 4900 done, reward: -10.0, running_reward: -6.6716, time (sec): 30432.6017\n",
      "Ep. 4902 done, reward: -17.0, running_reward: -6.8078, time (sec): 30449.5451\n",
      "Ep. 4904 done, reward: -10.0, running_reward: -6.8416, time (sec): 30467.0892\n",
      "Ep. 4906 done, reward: 3.0, running_reward: -6.7745, time (sec): 30484.3743\n",
      "Ep. 4908 done, reward: -3.0, running_reward: -6.7588, time (sec): 30501.2375\n",
      "Ep. 4910 done, reward: -7.0, running_reward: -6.7339, time (sec): 30519.6819\n",
      "Ep. 4912 done, reward: 3.0, running_reward: -6.5303, time (sec): 30539.0578\n",
      "Ep. 4914 done, reward: -5.0, running_reward: -6.4998, time (sec): 30557.5500\n",
      "Ep. 4916 done, reward: -9.0, running_reward: -6.5397, time (sec): 30571.2084\n",
      "Ep. 4918 done, reward: -15.0, running_reward: -6.6189, time (sec): 30586.1404\n",
      "Ep. 4920 done, reward: 1.0, running_reward: -6.5267, time (sec): 30603.8347\n",
      "Ep. 4922 done, reward: -2.0, running_reward: -6.5257, time (sec): 30622.5039\n",
      "Ep. 4924 done, reward: -7.0, running_reward: -6.5946, time (sec): 30638.3348\n",
      "Ep. 4926 done, reward: -13.0, running_reward: -6.6725, time (sec): 30656.1576\n",
      "Ep. 4928 done, reward: -10.0, running_reward: -6.7388, time (sec): 30671.8861\n",
      "Ep. 4930 done, reward: -13.0, running_reward: -6.6159, time (sec): 30687.2430\n",
      "Ep. 4932 done, reward: -4.0, running_reward: -6.6529, time (sec): 30704.1449\n",
      "Ep. 4934 done, reward: -7.0, running_reward: -6.7093, time (sec): 30720.9551\n",
      "Ep. 4936 done, reward: -14.0, running_reward: -6.6861, time (sec): 30738.0331\n",
      "Ep. 4938 done, reward: -7.0, running_reward: -6.7517, time (sec): 30755.4065\n",
      "Ep. 4940 done, reward: -2.0, running_reward: -6.6770, time (sec): 30774.8695\n",
      "Ep. 4942 done, reward: -6.0, running_reward: -6.5942, time (sec): 30794.2938\n",
      "Ep. 4944 done, reward: -16.0, running_reward: -6.7022, time (sec): 30809.2600\n",
      "Ep. 4946 done, reward: -13.0, running_reward: -6.8473, time (sec): 30824.2676\n",
      "Ep. 4948 done, reward: -6.0, running_reward: -6.8997, time (sec): 30841.7578\n",
      "Ep. 4950 done, reward: -6.0, running_reward: -6.8620, time (sec): 30861.3366\n",
      "Ep. 4952 done, reward: -4.0, running_reward: -6.8150, time (sec): 30879.5131\n",
      "Ep. 4954 done, reward: 1.0, running_reward: -6.7882, time (sec): 30896.4538\n",
      "Ep. 4956 done, reward: -10.0, running_reward: -6.8818, time (sec): 30911.9630\n",
      "Ep. 4958 done, reward: -15.0, running_reward: -6.9542, time (sec): 30928.2809\n",
      "Ep. 4960 done, reward: -5.0, running_reward: -6.9846, time (sec): 30942.9743\n",
      "Ep. 4962 done, reward: -4.0, running_reward: -6.8956, time (sec): 30963.1570\n",
      "Ep. 4964 done, reward: -2.0, running_reward: -6.8773, time (sec): 30979.9457\n",
      "Ep. 4966 done, reward: -7.0, running_reward: -6.8402, time (sec): 31000.1604\n",
      "Ep. 4968 done, reward: -5.0, running_reward: -6.8234, time (sec): 31016.8312\n",
      "Ep. 4970 done, reward: -15.0, running_reward: -6.9168, time (sec): 31034.8889\n",
      "Ep. 4972 done, reward: -4.0, running_reward: -6.8884, time (sec): 31051.7471\n",
      "Ep. 4974 done, reward: -4.0, running_reward: -6.8903, time (sec): 31071.9594\n",
      "Ep. 4976 done, reward: -6.0, running_reward: -6.8825, time (sec): 31089.4017\n",
      "Ep. 4978 done, reward: 5.0, running_reward: -6.7352, time (sec): 31108.0355\n",
      "Ep. 4980 done, reward: -9.0, running_reward: -6.7604, time (sec): 31123.9953\n",
      "Ep. 4982 done, reward: -5.0, running_reward: -6.7848, time (sec): 31139.8267\n",
      "Ep. 4984 done, reward: -1.0, running_reward: -6.7786, time (sec): 31158.7365\n",
      "Ep. 4986 done, reward: -5.0, running_reward: -6.8323, time (sec): 31174.8818\n",
      "Ep. 4988 done, reward: -11.0, running_reward: -6.7568, time (sec): 31190.9225\n",
      "Ep. 4990 done, reward: -7.0, running_reward: -6.8409, time (sec): 31208.1667\n",
      "Ep. 4992 done, reward: -10.0, running_reward: -6.8542, time (sec): 31227.6677\n",
      "Ep. 4994 done, reward: -7.0, running_reward: -6.7482, time (sec): 31245.7374\n",
      "Ep. 4996 done, reward: -11.0, running_reward: -6.8031, time (sec): 31262.9832\n",
      "Ep. 4998 done, reward: -1.0, running_reward: -6.7471, time (sec): 31284.1836\n",
      "Ep. 5000 done, reward: -11.0, running_reward: -6.8812, time (sec): 31299.6804\n",
      "Whew! All done with 5000 episodes!\n"
     ]
    }
   ],
   "source": [
    "PG = PolicyGradient(D=80*80, H=400, learning_rate=5e-4)\n",
    "PG.train(environment=\"Pong-v0\", max_episodes=5000, print_every=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Pong running reward: -6.88119764398\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x105f577d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2QAAAK9CAYAAABLrq+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSZJUkP8Poofomc04HKIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114c000d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot results.\n",
    "print(\"Final Pong running reward: {}\".format(PG.running_rewards[-1]))\n",
    "plt.figure()\n",
    "plt.plot(PG.running_rewards)\n",
    "plt.title(\"Running Rewards for Pong\")\n",
    "plt.xlabel(\"Training Episodes\")\n",
    "plt.ylabel(\"Scores\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional\n",
    "\n",
    "Congratulations on implementing Policy Gradients! \n",
    "\n",
    "Consider doing the following extensions:\n",
    "\n",
    "1. Run the Pong code from the cells above and tune for best performance. Summarize your results. \n",
    "2. Introduce a baseline function for the rewards. This will also require refitting the baseline; we recommend using a linear function and Numpy's linear algebra solver. \n",
    "3. Try a neural network architecture which is substantially different from the current one we are using. Try using two hidden layers (instead of one) and/or using sigmoid non-linearity.\n",
    "4. Extend the model to control more than two actions. You should use a softmax output. Try it, e.g. on Pong with the default action (actions [0,2,3]). \n",
    "5. Try an environment other than CartPole or Pong and see how the same architecture works (you need to look up the documentation for OpenAI gym, and run get_action_meanings on the environment). You will need to check the following: (1) that the game can be reduced to two controls, or that you implemented part 4 above, (2) that the preprocessing procedure makes sense, and (3) that your reward discounting is appropriate - some environments restart each time a reward is returned. \n",
    "\n",
    "State which one of these you are doing in the following cell(s). Describe results/statistics, show at least one plot, and provide at least one conclusion in the following cell.\n",
    "\n",
    "These experiments will generally require you to write code outside of the areas you wrote earlier, so make sure you at least put in a code comment somewhere to explain what is new.\n",
    "\n",
    "If you do an extension, modify the names of the log files e.g. `PG.running_rewards` to keep them distinct. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO Report here with plots, etc.\n",
    "# I did the first optional extension:\n",
    "# I ran the Pong code with the following tunned parameters for 5000 episodes:\n",
    "# H = 400 , learning_rate = 1e-4\n",
    "# Final running reward is -6.88 (plot shown above)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
